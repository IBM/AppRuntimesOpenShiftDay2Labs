{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"App Runtimes OpenShift Day 2 Labs Welcome to the App Runtimes OpenShift Day 2 Labs. These labs will help familiarize you with OpenShift, Kubernetes, containers, and common \"Day 2\" operations and problem determination for WebSphere deployments. The phrase \u201cDay 2\" refers to ongoing operations and maintenance of deployed applications whereas \u201cDay 1\u201d refers to installation, configuration, and application deployment. There are a total of 9 labs that may be performed in sequence or independently as you prefer. Use the table of contents to choose a particular lab or click Next below to start all of the labs. Pre-requisites If you are using your own OpenShift cluster, review OpenShift Cluster Preparation If you do not have access to an OpenShift cluster: Speak with your IBM account team and ask them to reach out to our team through the IBM-internal link https://ibm.biz/app-platform-swat-team-request Otherwise, if your laptop has at least 4 free CPUs and 9GB of free RAM , you can install Red Hat OpenShift Local and then review OpenShift Cluster Preparation If you're running Windows, ensure you've installed curl and jq , or use a Cygwin shell instead of a command prompt. Support These labs are provided as is without any warranty or support; however, please report any issues through the GitHub repository and we'll try to resolve any issues as time permits.","title":"Home"},{"location":"#app-runtimes-openshift-day-2-labs","text":"Welcome to the App Runtimes OpenShift Day 2 Labs. These labs will help familiarize you with OpenShift, Kubernetes, containers, and common \"Day 2\" operations and problem determination for WebSphere deployments. The phrase \u201cDay 2\" refers to ongoing operations and maintenance of deployed applications whereas \u201cDay 1\u201d refers to installation, configuration, and application deployment. There are a total of 9 labs that may be performed in sequence or independently as you prefer. Use the table of contents to choose a particular lab or click Next below to start all of the labs.","title":"App Runtimes OpenShift Day 2 Labs"},{"location":"#pre-requisites","text":"If you are using your own OpenShift cluster, review OpenShift Cluster Preparation If you do not have access to an OpenShift cluster: Speak with your IBM account team and ask them to reach out to our team through the IBM-internal link https://ibm.biz/app-platform-swat-team-request Otherwise, if your laptop has at least 4 free CPUs and 9GB of free RAM , you can install Red Hat OpenShift Local and then review OpenShift Cluster Preparation If you're running Windows, ensure you've installed curl and jq , or use a Cygwin shell instead of a command prompt.","title":"Pre-requisites"},{"location":"#support","text":"These labs are provided as is without any warranty or support; however, please report any issues through the GitHub repository and we'll try to resolve any issues as time permits.","title":"Support"},{"location":"appendix/","text":"Appendix You have reached the end of the labs.","title":"End of labs"},{"location":"appendix/#appendix","text":"You have reached the end of the labs.","title":"Appendix"},{"location":"faq/","text":"Frequently Asked Questions (FAQ) What causes the error 'dial tcp: lookup api.... on ...: no such host - verify you have provided the correct host and port and that the server is currently running.' Internal test clusters may not publish their API endpoints to DNS. Replace the host name in the login command with the IP address of the API endpoint provided by your cluster administrator; for example, replace the following oc login --token=... --server=https://api... With: oc login --token=... --server=https://10.20.30... What causes the error 'The server uses a certificate signed by unknown authority. You may need to use the --certificate-authority flag to provide the path to a certificate file for the certificate authority, or --insecure-skip-tls-verify to bypass the certificate check and use insecure connections.'? Internal test clusters may have self-signed certificates. Add --insecure-skip-tls-verify to the login command; for example: oc login --insecure-skip-tls-verify --token=... --server=... What causes the 'x509: \u201ckube-apiserver-lb-signer\u201d certificate is not trusted' error? This is a known issue on macOS so upgrade your oc client: macOS on Intel On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* macOS on ARM/AArch On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* What causes the error \"cannot be opened because the developer cannot be verified\"? Executables you download from the internet such as oc , containerdiag.sh , etc. may fail to run on macOS with this error. To resolve it, open a Terminal , change directory to where the executable is and run the following command, replacing $FILE with the executable name: xattr -d com.apple.quarantine $FILE What causes unexpected EOF during oc cp ? This is an undiagnosed, transient error. Please simply retry. If it happens often, we'll need to debug it. What causes oc get route [...] .spec.host to return a truncated URL? This is an undiagnosed, transient error. Re-run. The URL should end with / . What causes must specify one of -f and -k and error: unknown command \"token prometheus-k8s\" ? The command oc create token prometheus-k8s is a new command in recent versions of oc so upgrade your oc client: macOS on Intel On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* macOS on ARM/AArch On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift*","title":"Frequently Asked Questions"},{"location":"faq/#frequently-asked-questions-faq","text":"","title":"Frequently Asked Questions (FAQ)"},{"location":"faq/#what-causes-the-error-dial-tcp-lookup-api-on-no-such-host-verify-you-have-provided-the-correct-host-and-port-and-that-the-server-is-currently-running","text":"Internal test clusters may not publish their API endpoints to DNS. Replace the host name in the login command with the IP address of the API endpoint provided by your cluster administrator; for example, replace the following oc login --token=... --server=https://api... With: oc login --token=... --server=https://10.20.30...","title":"What causes the error 'dial tcp: lookup api.... on ...: no such host - verify you have provided the correct host and port and that the server is currently running.'"},{"location":"faq/#what-causes-the-error-the-server-uses-a-certificate-signed-by-unknown-authority-you-may-need-to-use-the-certificate-authority-flag-to-provide-the-path-to-a-certificate-file-for-the-certificate-authority-or-insecure-skip-tls-verify-to-bypass-the-certificate-check-and-use-insecure-connections","text":"Internal test clusters may have self-signed certificates. Add --insecure-skip-tls-verify to the login command; for example: oc login --insecure-skip-tls-verify --token=... --server=...","title":"What causes the error 'The server uses a certificate signed by unknown authority. You may need to use the --certificate-authority flag to provide the path to a certificate file for the certificate authority, or --insecure-skip-tls-verify to bypass the certificate check and use insecure connections.'?"},{"location":"faq/#what-causes-the-x509-kube-apiserver-lb-signer-certificate-is-not-trusted-error","text":"This is a known issue on macOS so upgrade your oc client: macOS on Intel On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* macOS on ARM/AArch On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift*","title":"What causes the 'x509: \u201ckube-apiserver-lb-signer\u201d certificate is not trusted' error?"},{"location":"faq/#what-causes-the-error-cannot-be-opened-because-the-developer-cannot-be-verified","text":"Executables you download from the internet such as oc , containerdiag.sh , etc. may fail to run on macOS with this error. To resolve it, open a Terminal , change directory to where the executable is and run the following command, replacing $FILE with the executable name: xattr -d com.apple.quarantine $FILE","title":"What causes the error \"cannot be opened because the developer cannot be verified\"?"},{"location":"faq/#what-causes-unexpected-eof-during-oc-cp","text":"This is an undiagnosed, transient error. Please simply retry. If it happens often, we'll need to debug it.","title":"What causes unexpected EOF during oc cp?"},{"location":"faq/#what-causes-oc-get-route-spechost-to-return-a-truncated-url","text":"This is an undiagnosed, transient error. Re-run. The URL should end with / .","title":"What causes oc get route [...] .spec.host to return a truncated URL?"},{"location":"faq/#what-causes-must-specify-one-of-f-and-k-and-error-unknown-command-token-prometheus-k8s","text":"The command oc create token prometheus-k8s is a new command in recent versions of oc so upgrade your oc client: macOS on Intel On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* macOS on ARM/AArch On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift*","title":"What causes must specify one of -f and -k and error: unknown command \"token prometheus-k8s\"?"},{"location":"lab_administration/","text":"Lab Cluster Administration This page is for those that are installing or managing an OpenShift cluster for this lab. OpenShift Cluster Preparation These labs currently only support an x86_64/amd64 OpenShift cluster. Install the WebSphere Liberty Operator: Add the IBM operator catalog Install the operator with oc in AllNamespaces If you would like to support the labs that require cluster-admin permissions such as Health of the cluster , etc.: If you are just running the lab yourself, you can just use any user with cluster-admin authority (e.g. kubeadmin ) If you would like to create a set of administrator users, review the cluster-admin group configuration steps . If instead of cluster-admin users, you want normal users, review the normal users configuration steps . If you would like to create a namespace for each user to use which has quotas, review the namespaces with quotas configuration steps . The cluster is now ready for students to use the lab . Cluster-admin group configuration steps Log in as a user with cluster-admin access into the OpenShift web console Go to User Management } Groups Click Create Group Set name: admingroup Remove the users section as we will add users later: users: - user1 - user2 Click Create Click RoleBindings Click Create binding Select ClusterRoleBinding Set Name to admingroupclusteradminbinding Set Role name to cluster-admin Click Create Create one or more admin users: Generate a random password: cat /dev/random | LC_ALL=C tr -dc 'a-zA-Z0-9' | fold -w 22 | head -n 1 Create/update a user password file. Replace $PASSWORD with the output from the previous step and update adminuser1 with the user name you'd like. For all but the first user, remove the -c flag. htpasswd -c -B -b adminusers.htpasswd adminuser1 $PASSWORD Remember this user name and password combination somewhere. In the OpenShift web console, go to Administration } Cluster Settings } Configuration } OAuth Identity providers } Add } HTPasswd Name: Administrators Browser } adminusers.htpasswd file created above Click Add Click View authentication conditions for reconfiguration status. Wait until \"All is well\" Go to User Management } Groups Click admingroup Actions } Add Users Add all the users created above and click Save Normal users configuration steps Create one or more normal users: Generate a random password: cat /dev/random | LC_ALL=C tr -dc 'a-zA-Z0-9' | fold -w 22 | head -n 1 Create/update a user password file. Replace $PASSWORD with the output from the previous step and update normaluser1 with the user name you'd like. For all but the first user, remove the -c flag. htpasswd -c -B -b normalusers.htpasswd normaluser1 $PASSWORD Remember this user name and password combination somewhere. In the OpenShift web console, go to Administration } Cluster Settings } Configuration } OAuth Identity providers } Add } HTPasswd Name: Normal Users Browser } normalusers.htpasswd file created above Click Add Click View authentication conditions for reconfiguration status. Wait until \"All is well\" Namespaces with quotas configuration steps First, figure out your worker node capacity; for example: $ for i in $(seq 0 2); do echo \"worker${i}\"; oc describe node worker${i}.example.com | grep -A 6 Capacity:; done worker0 Capacity: cpu: 8 ephemeral-storage: 261608428Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16015788Ki pods: 250 worker1 Capacity: cpu: 8 ephemeral-storage: 261608428Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16015780Ki pods: 250 worker2 Capacity: cpu: 8 ephemeral-storage: 261608428Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16015788Ki pods: 250 Next, figure out baseline worker node resource usage; for example: $ for i in $(seq 0 2); do oc describe node worker${i}.example.com | grep -A 5 \"Allocated resources:\"; done Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 504m (6%) 0 (0%) memory 2400Mi (16%) 0 (0%) Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 417m (5%) 0 (0%) memory 2286Mi (15%) 0 (0%) Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 748m (9%) 400m (5%) memory 1718Mi (11%) 512Mi (3%) Subtract the baseline usage from the capacity and subtract some buffer space and that leaves you with an approximate amount of room on your worker nodes. Each student is expected to need no more than 1 CPUs and 2GB RAM. Based on this capacity planning, create up to the maximum number of users as described in the other sections. Finally, create the quotas: Create a namespace for a user; for example, replace adminuser1-namespace with the namespace name: oc create namespace adminuser1-namespace Create a ResourceQuota on the namespace; for example, replace adminuser1-resourcequota with a user-specific name, replace adminuser1-namespace with the namespace name, and replace the limits.cpu and limits.memory if needed: printf '{\"apiVersion\":\"v1\",\"kind\":\"ResourceQuota\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"hard\":{\"requests.cpu\":\"10m\",\"requests.memory\":\"10Ki\",\"limits.cpu\":\"1001m\",\"limits.memory\":\"2Gi\"}}}' adminuser1-resourcequota adminuser1-namespace | oc create -f - Create a LimitRange to control the quota for each pod that doesn't have specified limits; for example, replace adminuser1-limitrange with a user-specific name, replace adminuser1-namespace with the namespace name, and replace the limits in default if needed: printf '{\"apiVersion\":\"v1\",\"kind\":\"LimitRange\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"limits\":[{\"defaultRequest\":{\"cpu\":\"1m\",\"memory\":\"1Ki\"},\"default\":{\"cpu\":\"500m\",\"memory\":\"1Gi\"},\"type\":\"Container\"}]}}' adminuser1-limitrange adminuser1-namespace | oc create -f - Automating quota creation USERS=30 for USER in $(seq 1 $USERS); do oc create namespace adminuser${USER}-namespace && printf '{\"apiVersion\":\"v1\",\"kind\":\"ResourceQuota\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"hard\":{\"requests.cpu\":\"10m\",\"requests.memory\":\"10Ki\",\"limits.cpu\":\"1001m\",\"limits.memory\":\"2Gi\"}}}' adminuser${USER}-resourcequota adminuser${USER}-namespace | oc create -f - && printf '{\"apiVersion\":\"v1\",\"kind\":\"LimitRange\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"limits\":[{\"defaultRequest\":{\"cpu\":\"1m\",\"memory\":\"1Ki\"},\"default\":{\"cpu\":\"500m\",\"memory\":\"1Gi\"},\"type\":\"Container\"}]}}' adminuser${USER}-limitrange adminuser${USER}-namespace | oc create -f -; done Automating destroying namespaces USERS=30 for USER in $(seq 1 $USERS); do oc delete namespace adminuser${USER}-namespace; done Updating an htpasswd file In the OpenShift web console, go to Administration } Cluster Settings } Configuration } OAuth Click on the YAML tab Find the section with the target htpasswd name (e.g. Administrators , Normal Users , etc.); for example: - htpasswd: fileData: name: htpasswd-zxf8q mappingMethod: claim name: Administrators type: HTPasswd In the output above, under fileData , take the name field value. Replace $NAME both times in: oc get secret $NAME -ojsonpath={.data.htpasswd} -n openshift-config | base64 --decode > $NAME.htpasswd Add more users as describe in previous sections Update the htpasswd file, replacing $NAME as above: oc create secret generic $NAME --from-file=htpasswd=$NAME.htpasswd --dry-run=client -o yaml -n openshift-config | oc replace -f - If users should be in a group (e.g. Administrators ), add any new users to that group as per previous instructions. If users need a namespace with a quota, create a namesapce as per previous instructions. Clean up To start a lab from scratch, clean up a namespace as follows. Clean up current namespace oc delete wltrace libertytrace1 oc delete wldump libertydump1 oc delete webspherelibertyapplication --all oc delete deployment libertydiag oc delete serviceaccount privilegedserviceaccount Clean up a specific namespace Replace $NAMESPACE with the target namespace. Some of these commands will return errors if such resources no longer exist, and that is expected. oc delete wltrace libertytrace1 --namespace $NAMESPACE oc delete wldump libertydump1 --namespace $NAMESPACE oc delete webspherelibertyapplication --all --namespace $NAMESPACE oc delete deployment libertydiag --namespace $NAMESPACE oc delete serviceaccount privilegedserviceaccount --namespace $NAMESPACE Automating cleaning up namespaces oc delete wltrace --all --all-namespaces oc delete wldump --all --all-namespaces oc delete webspherelibertyapplication --all --all-namespaces USERS=30 for USER in $(seq 1 $USERS); do oc delete all --all --namespace adminuser${USER}-namespace; oc delete serviceaccount privilegedserviceaccount --namespace adminuser${USER}-namespace; done","title":"Lab cluster administration"},{"location":"lab_administration/#lab-cluster-administration","text":"This page is for those that are installing or managing an OpenShift cluster for this lab.","title":"Lab Cluster Administration"},{"location":"lab_administration/#openshift-cluster-preparation","text":"These labs currently only support an x86_64/amd64 OpenShift cluster. Install the WebSphere Liberty Operator: Add the IBM operator catalog Install the operator with oc in AllNamespaces If you would like to support the labs that require cluster-admin permissions such as Health of the cluster , etc.: If you are just running the lab yourself, you can just use any user with cluster-admin authority (e.g. kubeadmin ) If you would like to create a set of administrator users, review the cluster-admin group configuration steps . If instead of cluster-admin users, you want normal users, review the normal users configuration steps . If you would like to create a namespace for each user to use which has quotas, review the namespaces with quotas configuration steps . The cluster is now ready for students to use the lab .","title":"OpenShift Cluster Preparation"},{"location":"lab_administration/#cluster-admin-group-configuration-steps","text":"Log in as a user with cluster-admin access into the OpenShift web console Go to User Management } Groups Click Create Group Set name: admingroup Remove the users section as we will add users later: users: - user1 - user2 Click Create Click RoleBindings Click Create binding Select ClusterRoleBinding Set Name to admingroupclusteradminbinding Set Role name to cluster-admin Click Create Create one or more admin users: Generate a random password: cat /dev/random | LC_ALL=C tr -dc 'a-zA-Z0-9' | fold -w 22 | head -n 1 Create/update a user password file. Replace $PASSWORD with the output from the previous step and update adminuser1 with the user name you'd like. For all but the first user, remove the -c flag. htpasswd -c -B -b adminusers.htpasswd adminuser1 $PASSWORD Remember this user name and password combination somewhere. In the OpenShift web console, go to Administration } Cluster Settings } Configuration } OAuth Identity providers } Add } HTPasswd Name: Administrators Browser } adminusers.htpasswd file created above Click Add Click View authentication conditions for reconfiguration status. Wait until \"All is well\" Go to User Management } Groups Click admingroup Actions } Add Users Add all the users created above and click Save","title":"Cluster-admin group configuration steps"},{"location":"lab_administration/#normal-users-configuration-steps","text":"Create one or more normal users: Generate a random password: cat /dev/random | LC_ALL=C tr -dc 'a-zA-Z0-9' | fold -w 22 | head -n 1 Create/update a user password file. Replace $PASSWORD with the output from the previous step and update normaluser1 with the user name you'd like. For all but the first user, remove the -c flag. htpasswd -c -B -b normalusers.htpasswd normaluser1 $PASSWORD Remember this user name and password combination somewhere. In the OpenShift web console, go to Administration } Cluster Settings } Configuration } OAuth Identity providers } Add } HTPasswd Name: Normal Users Browser } normalusers.htpasswd file created above Click Add Click View authentication conditions for reconfiguration status. Wait until \"All is well\"","title":"Normal users configuration steps"},{"location":"lab_administration/#namespaces-with-quotas-configuration-steps","text":"First, figure out your worker node capacity; for example: $ for i in $(seq 0 2); do echo \"worker${i}\"; oc describe node worker${i}.example.com | grep -A 6 Capacity:; done worker0 Capacity: cpu: 8 ephemeral-storage: 261608428Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16015788Ki pods: 250 worker1 Capacity: cpu: 8 ephemeral-storage: 261608428Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16015780Ki pods: 250 worker2 Capacity: cpu: 8 ephemeral-storage: 261608428Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16015788Ki pods: 250 Next, figure out baseline worker node resource usage; for example: $ for i in $(seq 0 2); do oc describe node worker${i}.example.com | grep -A 5 \"Allocated resources:\"; done Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 504m (6%) 0 (0%) memory 2400Mi (16%) 0 (0%) Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 417m (5%) 0 (0%) memory 2286Mi (15%) 0 (0%) Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 748m (9%) 400m (5%) memory 1718Mi (11%) 512Mi (3%) Subtract the baseline usage from the capacity and subtract some buffer space and that leaves you with an approximate amount of room on your worker nodes. Each student is expected to need no more than 1 CPUs and 2GB RAM. Based on this capacity planning, create up to the maximum number of users as described in the other sections. Finally, create the quotas: Create a namespace for a user; for example, replace adminuser1-namespace with the namespace name: oc create namespace adminuser1-namespace Create a ResourceQuota on the namespace; for example, replace adminuser1-resourcequota with a user-specific name, replace adminuser1-namespace with the namespace name, and replace the limits.cpu and limits.memory if needed: printf '{\"apiVersion\":\"v1\",\"kind\":\"ResourceQuota\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"hard\":{\"requests.cpu\":\"10m\",\"requests.memory\":\"10Ki\",\"limits.cpu\":\"1001m\",\"limits.memory\":\"2Gi\"}}}' adminuser1-resourcequota adminuser1-namespace | oc create -f - Create a LimitRange to control the quota for each pod that doesn't have specified limits; for example, replace adminuser1-limitrange with a user-specific name, replace adminuser1-namespace with the namespace name, and replace the limits in default if needed: printf '{\"apiVersion\":\"v1\",\"kind\":\"LimitRange\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"limits\":[{\"defaultRequest\":{\"cpu\":\"1m\",\"memory\":\"1Ki\"},\"default\":{\"cpu\":\"500m\",\"memory\":\"1Gi\"},\"type\":\"Container\"}]}}' adminuser1-limitrange adminuser1-namespace | oc create -f -","title":"Namespaces with quotas configuration steps"},{"location":"lab_administration/#automating-quota-creation","text":"USERS=30 for USER in $(seq 1 $USERS); do oc create namespace adminuser${USER}-namespace && printf '{\"apiVersion\":\"v1\",\"kind\":\"ResourceQuota\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"hard\":{\"requests.cpu\":\"10m\",\"requests.memory\":\"10Ki\",\"limits.cpu\":\"1001m\",\"limits.memory\":\"2Gi\"}}}' adminuser${USER}-resourcequota adminuser${USER}-namespace | oc create -f - && printf '{\"apiVersion\":\"v1\",\"kind\":\"LimitRange\",\"metadata\":{\"name\":\"%s\",\"namespace\":\"%s\"},\"spec\":{\"limits\":[{\"defaultRequest\":{\"cpu\":\"1m\",\"memory\":\"1Ki\"},\"default\":{\"cpu\":\"500m\",\"memory\":\"1Gi\"},\"type\":\"Container\"}]}}' adminuser${USER}-limitrange adminuser${USER}-namespace | oc create -f -; done","title":"Automating quota creation"},{"location":"lab_administration/#automating-destroying-namespaces","text":"USERS=30 for USER in $(seq 1 $USERS); do oc delete namespace adminuser${USER}-namespace; done","title":"Automating destroying namespaces"},{"location":"lab_administration/#updating-an-htpasswd-file","text":"In the OpenShift web console, go to Administration } Cluster Settings } Configuration } OAuth Click on the YAML tab Find the section with the target htpasswd name (e.g. Administrators , Normal Users , etc.); for example: - htpasswd: fileData: name: htpasswd-zxf8q mappingMethod: claim name: Administrators type: HTPasswd In the output above, under fileData , take the name field value. Replace $NAME both times in: oc get secret $NAME -ojsonpath={.data.htpasswd} -n openshift-config | base64 --decode > $NAME.htpasswd Add more users as describe in previous sections Update the htpasswd file, replacing $NAME as above: oc create secret generic $NAME --from-file=htpasswd=$NAME.htpasswd --dry-run=client -o yaml -n openshift-config | oc replace -f - If users should be in a group (e.g. Administrators ), add any new users to that group as per previous instructions. If users need a namespace with a quota, create a namesapce as per previous instructions.","title":"Updating an htpasswd file"},{"location":"lab_administration/#clean-up","text":"To start a lab from scratch, clean up a namespace as follows.","title":"Clean up"},{"location":"lab_administration/#clean-up-current-namespace","text":"oc delete wltrace libertytrace1 oc delete wldump libertydump1 oc delete webspherelibertyapplication --all oc delete deployment libertydiag oc delete serviceaccount privilegedserviceaccount","title":"Clean up current namespace"},{"location":"lab_administration/#clean-up-a-specific-namespace","text":"Replace $NAMESPACE with the target namespace. Some of these commands will return errors if such resources no longer exist, and that is expected. oc delete wltrace libertytrace1 --namespace $NAMESPACE oc delete wldump libertydump1 --namespace $NAMESPACE oc delete webspherelibertyapplication --all --namespace $NAMESPACE oc delete deployment libertydiag --namespace $NAMESPACE oc delete serviceaccount privilegedserviceaccount --namespace $NAMESPACE","title":"Clean up a specific namespace"},{"location":"lab_administration/#automating-cleaning-up-namespaces","text":"oc delete wltrace --all --all-namespaces oc delete wldump --all --all-namespaces oc delete webspherelibertyapplication --all --all-namespaces USERS=30 for USER in $(seq 1 $USERS); do oc delete all --all --namespace adminuser${USER}-namespace; oc delete serviceaccount privilegedserviceaccount --namespace adminuser${USER}-namespace; done","title":"Automating cleaning up namespaces"},{"location":"lab_basics_containers/","text":"Kubernetes basics If you are familiar with the basics of containers and Kubernetes, you may skip these links and click Next below to go to the first lab. Containers and Docker Review the one hour course for an introduction to containers and docker . Kubernetes Review the one hour course for an introduction to Kubernetes .","title":"Kubernetes basics"},{"location":"lab_basics_containers/#kubernetes-basics","text":"If you are familiar with the basics of containers and Kubernetes, you may skip these links and click Next below to go to the first lab.","title":"Kubernetes basics"},{"location":"lab_basics_containers/#containers-and-docker","text":"Review the one hour course for an introduction to containers and docker .","title":"Containers and Docker"},{"location":"lab_basics_containers/#kubernetes","text":"Review the one hour course for an introduction to Kubernetes .","title":"Kubernetes"},{"location":"lab_basics_openshift_health/","text":"Lab: General OpenShift Health This lab covers how to check whether an OpenShift environment is generally healthy. Lab Requirements This lab requires that the user has cluster-admin permissions. If you do not, you must skip this lab. Labs Choose to perform the web console lab and/or the command line lab: Lab: Using the OpenShift Web Console to check cluster health Lab: Using the command line to check cluster health Lab: Using the OpenShift Web Console to check cluster health Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. After logging in, you should see the Administrator view: On the main Overview page, scroll down to the Status box and ensure that Cluster , Control Plane , and Operators all show a green check mark. If they do not, there may be a fundamental issue with the cluster worth investigating. There may be a warning for Insights which is okay as it's not required. If there is an issue, clicking the hyperlink will show failure details. On the main Overview page, scroll down to the Details box and review the OpenShift version , and then scroll down to the Cluster inventory box and review the number of pods. If there are any known problematic pods, this will show a small exclamation icon and you can click the hyperlink for details on the failing pods. Next, scroll down to the Cluster Utilization box. You can change the time frame in the top right, and it's often useful to use Filter by Node type next to that to filter down to just worker or master nodes. Each section shows the total available (for example, 43.19 available of 48 means there are 48 total CPUs and 43.19 are available). Note that the graph y-axis is not scaled to the total available. The dashed yellow lines in the CPU and Memory sections are the sum of CPU and Memory pod requests (if specified) and it's normal for utilization to be above these lines. This may be due to pods using more than requests (up to specified limits) or requests/limits not being specified. For each resource (e.g. CPU), click on the hyperlinked utilization number to get top consumers and switch to different groupings, e.g. By Node instead of By Project : If you want to investigate resources further, on the left side, click Observe (or Monitoring in older versions of OpenShift) } Dashboards } Then click the dropdown and select Node Exporter / USE Method / Cluster Next, review critical and warning alerts. On the left side, click Observe (or Monitoring in older versions of OpenShift) } Alerting } Then click Filter , and check Critical and Warning Next, review recent warning and error events: On the left side, click Home } Events } Then change All types to Warning Summary In summary, this lab demonstrated how to check basic OpenShift health including cluster health, resource utilization, alerts, and events. Optionally, you may perform the next lab to get similar information through the command line. Lab: Using the command line to check cluster health Review the overall cluster status and check if the STATUS column has any errors. oc get clusterversion Example output: NAME VERSION AVAILABLE PROGRESSING SINCE STATUS version 4.11.9 True False 39d Cluster version is 4.11.9 Get the status of cluster operators. oc get clusteroperators Example output: NAME VERSION AVAILABLE PROGRESSING DEGRADED SINCE MESSAGE authentication 4.11.9 True False False 3d6h If any are Degraded=True , then run oc describe clusteroperator $NAME . Review the status of nodes: oc get nodes Example output: NAME STATUS ROLES AGE VERSION master0.was-education-cluster Ready master 39d v1.24.0+dc5a2fd master1.was-education-cluster Ready master 39d v1.24.0+dc5a2fd master2.was-education-cluster Ready master 39d v1.24.0+dc5a2fd worker0.was-education-cluster Ready worker 39d v1.24.0+dc5a2fd worker1.was-education-cluster Ready worker 39d v1.24.0+dc5a2fd worker2.was-education-cluster Ready worker 39d v1.24.0+dc5a2fd If any are Status=NotReady , then you could oc describe node $NODE and check the Conditions for errors. Review node resource usage: oc adm top nodes Example output: NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% master0.was-education-cluster 1002m 13% 10931Mi 75% master1.was-education-cluster 873m 11% 8603Mi 59% master2.was-education-cluster 1659m 22% 9231Mi 63% worker0.was-education-cluster 765m 10% 4146Mi 28% worker1.was-education-cluster 694m 9% 4009Mi 27% worker2.was-education-cluster 263m 3% 2868Mi 19% Review top pod CPU utilization. oc adm top pods --sort-by=cpu --all-namespaces Example output: NAMESPACE NAME CPU(cores) MEMORY(bytes) openshift-monitoring prometheus-k8s-1 355m 1779Mi [...] Review top pod memory utilization: oc adm top pods --sort-by=memory --all-namespaces Example output: NAMESPACE NAME CPU(cores) MEMORY(bytes) openshift-kube-apiserver kube-apiserver-master0.was-education-cluster 318m 3137Mi [...] Review critical and warning alerts (on Windows, you'll need to install something like Cygwin , etc.): Critical alerts: curl -k -H \"Authorization: Bearer $(oc create token prometheus-k8s -n openshift-monitoring)\" \"https://$(oc -n openshift-monitoring get route alertmanager-main -o jsonpath='{.spec.host}')/api/v1/alerts?filter=severity=critical\" Warning alerts: curl -k -H \"Authorization: Bearer $(oc create token prometheus-k8s -n openshift-monitoring)\" \"https://$(oc -n openshift-monitoring get route alertmanager-main -o jsonpath='{.spec.host}')/api/v1/alerts?filter=severity=warning\" Review recent warning and error events. This is particularly useful to find if OpenShift is killing application pods for some reason, health check probes are failing, etc. oc get events --all-namespaces --sort-by='.lastTimestamp' --field-selector type=Warning -o custom-columns=FirstSeen:.firstTimestamp,LastSeen:.lastTimestamp,Count:.count,From:.source.component,Host:.source.host,Type:.type,Reason:.reason,ObjectKind:.involvedObject.kind,Object:.involvedObject.name,ObjectNamespace:.involvedObject.namespace,Message:.message Check a node for kernel errors or warnings (e.g. OOM killer): List all the nodes: oc get nodes Take a node name and start a debug pod. For example: oc debug node/master0.was-education-cluster -t Wait for the sh-4.4# prompt. Print the kernel log with a filter for errors: chroot /host journalctl -p err | cat exit List pods that have failed. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase==Failed Example output: NAMESPACE NAME READY STATUS RESTARTS AGE openshift-operator-lifecycle-manager collect-profiles-27859260-rxwq6 0/1 Error 0 29m List pods in a pending state. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase==Pending Example output: No resources found List pods in an unknown state. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase==Unknown Example output: No resources found Check for pods with a high restart count. Even if they are in a Running state, a high restart count might indicate underlying problems. The following example shows those with a restart count greater than 3. On Windows, you'll need to install something like Cygwin with the jq utility. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase=Running -o json | jq '.items[]|select(any( .status.containerStatuses[]; .restartCount > 3))|.metadata.name' Summary In summary, this lab demonstrated how to check basic OpenShift health including cluster health, resource utilization, alerts, and events.","title":"Health of the cluster"},{"location":"lab_basics_openshift_health/#lab-general-openshift-health","text":"This lab covers how to check whether an OpenShift environment is generally healthy.","title":"Lab: General OpenShift Health"},{"location":"lab_basics_openshift_health/#lab-requirements","text":"This lab requires that the user has cluster-admin permissions. If you do not, you must skip this lab.","title":"Lab Requirements"},{"location":"lab_basics_openshift_health/#labs","text":"Choose to perform the web console lab and/or the command line lab: Lab: Using the OpenShift Web Console to check cluster health Lab: Using the command line to check cluster health","title":"Labs"},{"location":"lab_basics_openshift_health/#lab-using-the-openshift-web-console-to-check-cluster-health","text":"Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. After logging in, you should see the Administrator view: On the main Overview page, scroll down to the Status box and ensure that Cluster , Control Plane , and Operators all show a green check mark. If they do not, there may be a fundamental issue with the cluster worth investigating. There may be a warning for Insights which is okay as it's not required. If there is an issue, clicking the hyperlink will show failure details. On the main Overview page, scroll down to the Details box and review the OpenShift version , and then scroll down to the Cluster inventory box and review the number of pods. If there are any known problematic pods, this will show a small exclamation icon and you can click the hyperlink for details on the failing pods. Next, scroll down to the Cluster Utilization box. You can change the time frame in the top right, and it's often useful to use Filter by Node type next to that to filter down to just worker or master nodes. Each section shows the total available (for example, 43.19 available of 48 means there are 48 total CPUs and 43.19 are available). Note that the graph y-axis is not scaled to the total available. The dashed yellow lines in the CPU and Memory sections are the sum of CPU and Memory pod requests (if specified) and it's normal for utilization to be above these lines. This may be due to pods using more than requests (up to specified limits) or requests/limits not being specified. For each resource (e.g. CPU), click on the hyperlinked utilization number to get top consumers and switch to different groupings, e.g. By Node instead of By Project : If you want to investigate resources further, on the left side, click Observe (or Monitoring in older versions of OpenShift) } Dashboards } Then click the dropdown and select Node Exporter / USE Method / Cluster Next, review critical and warning alerts. On the left side, click Observe (or Monitoring in older versions of OpenShift) } Alerting } Then click Filter , and check Critical and Warning Next, review recent warning and error events: On the left side, click Home } Events } Then change All types to Warning","title":"Lab: Using the OpenShift Web Console to check cluster health"},{"location":"lab_basics_openshift_health/#summary","text":"In summary, this lab demonstrated how to check basic OpenShift health including cluster health, resource utilization, alerts, and events. Optionally, you may perform the next lab to get similar information through the command line.","title":"Summary"},{"location":"lab_basics_openshift_health/#lab-using-the-command-line-to-check-cluster-health","text":"Review the overall cluster status and check if the STATUS column has any errors. oc get clusterversion Example output: NAME VERSION AVAILABLE PROGRESSING SINCE STATUS version 4.11.9 True False 39d Cluster version is 4.11.9 Get the status of cluster operators. oc get clusteroperators Example output: NAME VERSION AVAILABLE PROGRESSING DEGRADED SINCE MESSAGE authentication 4.11.9 True False False 3d6h If any are Degraded=True , then run oc describe clusteroperator $NAME . Review the status of nodes: oc get nodes Example output: NAME STATUS ROLES AGE VERSION master0.was-education-cluster Ready master 39d v1.24.0+dc5a2fd master1.was-education-cluster Ready master 39d v1.24.0+dc5a2fd master2.was-education-cluster Ready master 39d v1.24.0+dc5a2fd worker0.was-education-cluster Ready worker 39d v1.24.0+dc5a2fd worker1.was-education-cluster Ready worker 39d v1.24.0+dc5a2fd worker2.was-education-cluster Ready worker 39d v1.24.0+dc5a2fd If any are Status=NotReady , then you could oc describe node $NODE and check the Conditions for errors. Review node resource usage: oc adm top nodes Example output: NAME CPU(cores) CPU% MEMORY(bytes) MEMORY% master0.was-education-cluster 1002m 13% 10931Mi 75% master1.was-education-cluster 873m 11% 8603Mi 59% master2.was-education-cluster 1659m 22% 9231Mi 63% worker0.was-education-cluster 765m 10% 4146Mi 28% worker1.was-education-cluster 694m 9% 4009Mi 27% worker2.was-education-cluster 263m 3% 2868Mi 19% Review top pod CPU utilization. oc adm top pods --sort-by=cpu --all-namespaces Example output: NAMESPACE NAME CPU(cores) MEMORY(bytes) openshift-monitoring prometheus-k8s-1 355m 1779Mi [...] Review top pod memory utilization: oc adm top pods --sort-by=memory --all-namespaces Example output: NAMESPACE NAME CPU(cores) MEMORY(bytes) openshift-kube-apiserver kube-apiserver-master0.was-education-cluster 318m 3137Mi [...] Review critical and warning alerts (on Windows, you'll need to install something like Cygwin , etc.): Critical alerts: curl -k -H \"Authorization: Bearer $(oc create token prometheus-k8s -n openshift-monitoring)\" \"https://$(oc -n openshift-monitoring get route alertmanager-main -o jsonpath='{.spec.host}')/api/v1/alerts?filter=severity=critical\" Warning alerts: curl -k -H \"Authorization: Bearer $(oc create token prometheus-k8s -n openshift-monitoring)\" \"https://$(oc -n openshift-monitoring get route alertmanager-main -o jsonpath='{.spec.host}')/api/v1/alerts?filter=severity=warning\" Review recent warning and error events. This is particularly useful to find if OpenShift is killing application pods for some reason, health check probes are failing, etc. oc get events --all-namespaces --sort-by='.lastTimestamp' --field-selector type=Warning -o custom-columns=FirstSeen:.firstTimestamp,LastSeen:.lastTimestamp,Count:.count,From:.source.component,Host:.source.host,Type:.type,Reason:.reason,ObjectKind:.involvedObject.kind,Object:.involvedObject.name,ObjectNamespace:.involvedObject.namespace,Message:.message Check a node for kernel errors or warnings (e.g. OOM killer): List all the nodes: oc get nodes Take a node name and start a debug pod. For example: oc debug node/master0.was-education-cluster -t Wait for the sh-4.4# prompt. Print the kernel log with a filter for errors: chroot /host journalctl -p err | cat exit List pods that have failed. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase==Failed Example output: NAMESPACE NAME READY STATUS RESTARTS AGE openshift-operator-lifecycle-manager collect-profiles-27859260-rxwq6 0/1 Error 0 29m List pods in a pending state. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase==Pending Example output: No resources found List pods in an unknown state. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase==Unknown Example output: No resources found Check for pods with a high restart count. Even if they are in a Running state, a high restart count might indicate underlying problems. The following example shows those with a restart count greater than 3. On Windows, you'll need to install something like Cygwin with the jq utility. It's okay if this output is blank and only shows output if there are active problems. oc get pods --all-namespaces --field-selector=status.phase=Running -o json | jq '.items[]|select(any( .status.containerStatuses[]; .restartCount > 3))|.metadata.name'","title":"Lab: Using the command line to check cluster health"},{"location":"lab_basics_openshift_health/#summary_1","text":"In summary, this lab demonstrated how to check basic OpenShift health including cluster health, resource utilization, alerts, and events.","title":"Summary"},{"location":"lab_liberty_application_errors/","text":"Lab: Application Errors or Warnings This lab covers how to investigate application errors or warnings in Liberty applications in OpenShift. Lab This lab will take approximately 5 minutes. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Exercise error servlet Now you will use the libertydiag application to simulate errors. Using the command line Request the following web page from your terminal to simulate errors: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Exceptions\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Exceptions\" You should see an exception stack trace. If not, rerun the curl command with the -v option to investigate. Request the following web page from your terminal with additional parameters: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Exceptions?throwAllTheWay=true&throwmessage=errorEncountered&throwconstructor=message\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Exceptions?throwAllTheWay=true&throwmessage=errorEncountered&throwconstructor=message\" Using the browser Click on the Exceptions link from the libertydiag application homepage: You should see an exception stack trace in the browser. Now add the query parameters throwAllTheWay=true&throwmessage=errorEncountered to the end of the URL and press ENTER : [...]/servlet/Exceptions?throwAllTheWay=true&throwmessage=errorEncountered&throwconstructor=message You should see a different error page with an Error 500. Reload the page a couple of times. Step 3: Review log data Now you will review the logs to understand how to investigate exceptions. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command. The native logs are equivalent to the Liberty console.log in a non-cloud deployment. oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 The native logs are a bit hard to review since they're in JSON, so next we'll review the messages.log . Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log You should see an application exception in the logs such as: [1/11/23 20:01:10:780 UTC] 00000028 com.ibm.ws.webcontainer.util.ApplicationErrorUtils E SRVE0777E: Exception thrown by application class 'com.example.servlet.Exceptions.doWork:50' com.example.util.SkipCatchException: errorEncountered at com.example.servlet.Exceptions.doWork(Exceptions.java:50) at com.example.util.BaseServlet.service(BaseServlet.java:104) [...] Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running. The View logs output is equivalent to the Liberty console.log in a non-cloud deployment. Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log You should see an application exception in the logs such as: [1/11/23 20:01:10:780 UTC] 00000028 com.ibm.ws.webcontainer.util.ApplicationErrorUtils E SRVE0777E: Exception thrown by application class 'com.example.servlet.Exceptions.doWork:50' com.example.util.SkipCatchException: errorEncountered at com.example.servlet.Exceptions.doWork(Exceptions.java:50) at com.example.util.BaseServlet.service(BaseServlet.java:104) [...] Step 4: Download Liberty logs In many cases, you may want the full logs for review on your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the Liberty messages.log by replacing $POD with a pod name from the previous command oc cp $POD:/logs/messages.log messages.log For example: oc cp libertydiag-ddf5f95b6-wj6dm:/logs/messages.log messages.log Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser. Summary In summary, this lab demonstrated how to view Liberty logs in an OpenShift environment to investigate exceptions.","title":"Application errors"},{"location":"lab_liberty_application_errors/#lab-application-errors-or-warnings","text":"This lab covers how to investigate application errors or warnings in Liberty applications in OpenShift.","title":"Lab: Application Errors or Warnings"},{"location":"lab_liberty_application_errors/#lab","text":"This lab will take approximately 5 minutes.","title":"Lab"},{"location":"lab_liberty_application_errors/#step-1-install-example-application","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_application_errors/#step-2-exercise-error-servlet","text":"Now you will use the libertydiag application to simulate errors. Using the command line Request the following web page from your terminal to simulate errors: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Exceptions\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Exceptions\" You should see an exception stack trace. If not, rerun the curl command with the -v option to investigate. Request the following web page from your terminal with additional parameters: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Exceptions?throwAllTheWay=true&throwmessage=errorEncountered&throwconstructor=message\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Exceptions?throwAllTheWay=true&throwmessage=errorEncountered&throwconstructor=message\" Using the browser Click on the Exceptions link from the libertydiag application homepage: You should see an exception stack trace in the browser. Now add the query parameters throwAllTheWay=true&throwmessage=errorEncountered to the end of the URL and press ENTER : [...]/servlet/Exceptions?throwAllTheWay=true&throwmessage=errorEncountered&throwconstructor=message You should see a different error page with an Error 500. Reload the page a couple of times.","title":"Step 2: Exercise error servlet"},{"location":"lab_liberty_application_errors/#step-3-review-log-data","text":"Now you will review the logs to understand how to investigate exceptions. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command. The native logs are equivalent to the Liberty console.log in a non-cloud deployment. oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 The native logs are a bit hard to review since they're in JSON, so next we'll review the messages.log . Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log You should see an application exception in the logs such as: [1/11/23 20:01:10:780 UTC] 00000028 com.ibm.ws.webcontainer.util.ApplicationErrorUtils E SRVE0777E: Exception thrown by application class 'com.example.servlet.Exceptions.doWork:50' com.example.util.SkipCatchException: errorEncountered at com.example.servlet.Exceptions.doWork(Exceptions.java:50) at com.example.util.BaseServlet.service(BaseServlet.java:104) [...] Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running. The View logs output is equivalent to the Liberty console.log in a non-cloud deployment. Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log You should see an application exception in the logs such as: [1/11/23 20:01:10:780 UTC] 00000028 com.ibm.ws.webcontainer.util.ApplicationErrorUtils E SRVE0777E: Exception thrown by application class 'com.example.servlet.Exceptions.doWork:50' com.example.util.SkipCatchException: errorEncountered at com.example.servlet.Exceptions.doWork(Exceptions.java:50) at com.example.util.BaseServlet.service(BaseServlet.java:104) [...]","title":"Step 3: Review log data"},{"location":"lab_liberty_application_errors/#step-4-download-liberty-logs","text":"In many cases, you may want the full logs for review on your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the Liberty messages.log by replacing $POD with a pod name from the previous command oc cp $POD:/logs/messages.log messages.log For example: oc cp libertydiag-ddf5f95b6-wj6dm:/logs/messages.log messages.log Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser.","title":"Step 4: Download Liberty logs"},{"location":"lab_liberty_application_errors/#summary","text":"In summary, this lab demonstrated how to view Liberty logs in an OpenShift environment to investigate exceptions.","title":"Summary"},{"location":"lab_liberty_applogs/","text":"Lab: Reviewing OpenShift Application Logs This lab covers how to review application logs in an OpenShift environment. Theory There are multiple ways to review application logs in an OpenShift environment: Using the oc command line client: View the native logs of the pod through the oc logs command. View log files within a pod by starting a remote shell using the oc rsh command. Download log files from a pod using the oc cp command. Using the OpenShift web console: View and/or download the native logs of the pod through the Logs tab on a pod. View log files within a pod through the Terminal tab on a pod. Publish native logs of pods to OpenShift centralized logging using, most commonly, EFK , and then search logs in the Kibana log viewer. Optionally install sample Kibana dashboards created by the WebSphere team that summarize application log events and statistics. Gather a Liberty server dump using the WebSphere Liberty Operator that includes Liberty log files. Lab: Review logs with the command line client or the OpenShift web console pod page This lab will demonstrate how to review both application native logs (equivalent to the Liberty console.log ) and the Liberty messages.log using the oc command line client or the OpenShift web console pod page. This lab will take approximately 15 minutes. Step 1: Install example application Install the sample application . Step 2: Review Application Logs Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command. The native logs are equivalent to the Liberty console.log in a non-cloud deployment. oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 Open a shell into the pod by replacing $POD with the pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log Alternatively, if you want to download a file to your computer, exit out of the rsh session and download messages.log by replacing $POD with the pod name from the previous command: oc cp $POD:/logs/messages.log messages.log For example: oc cp libertydiag-b98748954-mgj64:/logs/messages.log messages.log Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running. The View logs output is equivalent to the Liberty console.log in a non-cloud deployment. You can also download the native logs using the Download button: Note that the browser can only download native logs; it cannot download arbitrary logs from the container filesystem. Instead, you can cat the logs through the Terminal . Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log Summary In summary, this lab demonstrated how to install a sample application and review its logs.","title":"Application logs"},{"location":"lab_liberty_applogs/#lab-reviewing-openshift-application-logs","text":"This lab covers how to review application logs in an OpenShift environment.","title":"Lab: Reviewing OpenShift Application Logs"},{"location":"lab_liberty_applogs/#theory","text":"There are multiple ways to review application logs in an OpenShift environment: Using the oc command line client: View the native logs of the pod through the oc logs command. View log files within a pod by starting a remote shell using the oc rsh command. Download log files from a pod using the oc cp command. Using the OpenShift web console: View and/or download the native logs of the pod through the Logs tab on a pod. View log files within a pod through the Terminal tab on a pod. Publish native logs of pods to OpenShift centralized logging using, most commonly, EFK , and then search logs in the Kibana log viewer. Optionally install sample Kibana dashboards created by the WebSphere team that summarize application log events and statistics. Gather a Liberty server dump using the WebSphere Liberty Operator that includes Liberty log files.","title":"Theory"},{"location":"lab_liberty_applogs/#lab-review-logs-with-the-command-line-client-or-the-openshift-web-console-pod-page","text":"This lab will demonstrate how to review both application native logs (equivalent to the Liberty console.log ) and the Liberty messages.log using the oc command line client or the OpenShift web console pod page. This lab will take approximately 15 minutes.","title":"Lab: Review logs with the command line client or the OpenShift web console pod page"},{"location":"lab_liberty_applogs/#step-1-install-example-application","text":"Install the sample application .","title":"Step 1: Install example application"},{"location":"lab_liberty_applogs/#step-2-review-application-logs","text":"Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command. The native logs are equivalent to the Liberty console.log in a non-cloud deployment. oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 Open a shell into the pod by replacing $POD with the pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log Alternatively, if you want to download a file to your computer, exit out of the rsh session and download messages.log by replacing $POD with the pod name from the previous command: oc cp $POD:/logs/messages.log messages.log For example: oc cp libertydiag-b98748954-mgj64:/logs/messages.log messages.log Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running. The View logs output is equivalent to the Liberty console.log in a non-cloud deployment. You can also download the native logs using the Download button: Note that the browser can only download native logs; it cannot download arbitrary logs from the container filesystem. Instead, you can cat the logs through the Terminal . Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter to print the full Liberty messages.log : cat /logs/messages.log","title":"Step 2: Review Application Logs"},{"location":"lab_liberty_applogs/#summary","text":"In summary, this lab demonstrated how to install a sample application and review its logs.","title":"Summary"},{"location":"lab_liberty_diagnostic_trace/","text":"Lab: Diagnostic Trace This lab covers how to enable and review diagnostic trace for a sample Liberty application in OpenShift. Theory There are multiple ways to enable diagnostic trace in Liberty in an OpenShift environment: Add a <logging traceSpecification=... /> section to server.xml or add a configuration drop-in. This only works if runtime configuration updates are enabled, as they are by default. If the application is installed using the WebSphere Liberty Operator, the WebSphereLibertyTrace custom resource may be used to enable and disable trace. This only works if runtime configuration updates are enabled, as they are by default, if the WebSphereLibertyApplication custom resource has the proper openliberty.io/day2operations annotation , and if the container has a /serviceability directory . An application image may be re-built and re-deployed with an additional <logging traceSpecification=... /> section in server.xml or using a configuration drop-in. There are various well-known diagnostic trace specifications for WebSphere Liberty . Labs Choose one or more labs: Lab: HTTP Diagnostic Trace by adding a configuration dropin Lab: HTTP Diagnostic Trace through the WebSphere Liberty Operator Lab: HTTP Diagnostic Trace by adding a configuration dropin This lab will enable HTTP diagnostic trace by adding a configuration dropin with a trace specification. This lab will take approximately 10 minutes. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Configure diagnostic trace Now that the application is installed and running, you will configure diagnostic trace. You will be modifying a running pod. In some real-world cases, this may be infeasible and the image will need to be re-built and re-deployed with the updated configuration. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server. echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><logging traceSpecification=\"*=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all\" maxFileSize=\"100\" maxFiles=\"10\" /></server>' > /config/configDropins/overrides/trace.xml Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server. echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><logging traceSpecification=\"*=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all\" maxFileSize=\"100\" maxFiles=\"10\" /></server>' > /config/configDropins/overrides/trace.xml Step 3: Exercise an HTTP request Now that HTTP diagnostic trace is configured, you will simulate an HTTP request to Liberty. Using the command line Request the following web page from your terminal to simulate an HTTP request: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Sleep\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Sleep\" Using the browser Click on the /servlet/Sleep link from the libertydiag application homepage: Step 4: Disable diagnostic trace Now that the diagnostic trace has been captured, you will learn how to disable the diagnostic trace. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server back to its original value. rm /config/configDropins/overrides/trace.xml Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server back to its original value. rm /config/configDropins/overrides/trace.xml Step 5: Download trace logs Download trace logs to your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the logs by replacing $POD with a pod name from above. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:/logs . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/logs . You should be able to find the Sleep request executed above; for example: [1/3/23 16:48:19:462 UTC] 0000006d id=00000000 com.ibm.ws.webcontainer.servlet.ServletWrapper > handleRequest ServletWrapper[com.example.servlet.Sleep:[/servlet/Sleep]] ,request-> com.ibm.ws.webcontainer40.srt.SRTServletRequest40@20a8494e ,response-> com.ibm.ws.webcontainer40.srt.SRTServletResponse40@86c16c72 ENTRY [1/3/23 16:48:19:473 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Invoking com.example.servlet.Sleep by anonymous (10.254.20.1)... [] [1/3/23 16:48:20:482 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Done com.example.servlet.Sleep [1/3/23 16:48:20:495 UTC] 0000006d id=7d221183 com.ibm.ws.webcontainer.osgi.DynamicVirtualHost 3 Webcontainer handleRequest complete for--> [/servlet/Sleep], mapped webApp context [com.ibm.ws.webcontainer40.osgi.webapp.WebApp40@35a6e71f[libertydiag#libertydiag.war]], inboundConnection --> [com.ibm.ws.http.dispatcher.internal.channel.HttpDispatcherLink@22dbf0bd], this --> com.ibm.ws.webcontainer.osgi.DynamicVirtualHost$2@7d221183 Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser. Summary In summary, this lab demonstrated how to configure HTTP diagnostic trace in Liberty, exercise a request, and download the trace logs. Lab: HTTP Diagnostic Trace through the WebSphere Liberty Operator This lab will enable HTTP diagnostic trace using the WebSphere Liberty Operator with an example application and review the output. This lab will take approximately 10 minutes. Step 1: Install example application If you haven't already, install the sample application using the WebSphere Liberty operator. If you installed it in a previous lab, you may continue using the previous installation. If you previously installed the sample using a basic Kubernetes deployment, then uninstall it and re-install using the WebSphere Liberty operator. Step 2: Configure diagnostic trace Now that the application is installed and running, you will configure diagnostic trace using the WebSphere Liberty Operator trace custom resource . Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Create a trace.yaml file, replacing $POD with the name of the pod from the previous command (e.g. libertydiag-b98748954-mgj64 ): apiVersion: liberty.websphere.ibm.com/v1 kind: WebSphereLibertyTrace metadata: name: libertytrace1 annotations: day2operation.openliberty.io/targetKinds: Pod spec: license: accept: true podName: $POD traceSpecification: \"*=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all\" maxFileSize: 100 maxFiles: 5 disable: false Apply the YAML: oc apply -f trace.yaml Using the browser Ensure the perspective is set to Developer in the top left: Set your current namespace/project to what you were provided. For example: In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then copy the name of the pod that's running: Click Operator Backed on the +Add page: Click WebSphereLibertyTrace and then click Create Expand License and check accept Paste the pod name from the step above into the podName text box. Set the traceSpecification to: *=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all Set maxFileSize to 100 Click Create Step 3: Exercise an HTTP request Now that HTTP diagnostic trace is configured, you will simulate an HTTP request to Liberty. Using the command line Request the following web page from your terminal to simulate an HTTP request: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Sleep\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Sleep\" Using the browser Click on the /servlet/Sleep link from the libertydiag application homepage: Step 4: Disable diagnostic trace Now that the diagnostic trace has been captured, you will learn how to disable the diagnostic trace. Using the command line List WebSphereLibertyTrace custom resources; for example: oc get wltrace Example output: NAME PODNAME TRACING libertytrace1 libertydiag-5fdf699f-sfwqn True Delete the custom resource you created earlier; for example: oc delete wltrace libertytrace1 Using the browser Click on Search , click the Resources drop down, search for trace , check WebSphereLibertyTrace , click the vertical ellipses next to the custom resource created earlier, click Delete WebSphereLibertyTrace , and click Delete : Step 5: Download trace logs Download trace logs to your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the logs by replacing $POD with a pod name from above and $NAMESPACE with your namespace. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:/serviceability/$NAMESPACE/$POD/ . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/serviceability/user15-namespace/libertydiag-ddf5f95b6-wj6dm/ . You should be able to find the Sleep request executed above; for example: [1/3/23 16:48:19:462 UTC] 0000006d id=00000000 com.ibm.ws.webcontainer.servlet.ServletWrapper > handleRequest ServletWrapper[com.example.servlet.Sleep:[/servlet/Sleep]] ,request-> com.ibm.ws.webcontainer40.srt.SRTServletRequest40@20a8494e ,response-> com.ibm.ws.webcontainer40.srt.SRTServletResponse40@86c16c72 ENTRY [1/3/23 16:48:19:473 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Invoking com.example.servlet.Sleep by anonymous (10.254.20.1)... [] [1/3/23 16:48:20:482 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Done com.example.servlet.Sleep [1/3/23 16:48:20:495 UTC] 0000006d id=7d221183 com.ibm.ws.webcontainer.osgi.DynamicVirtualHost 3 Webcontainer handleRequest complete for--> [/servlet/Sleep], mapped webApp context [com.ibm.ws.webcontainer40.osgi.webapp.WebApp40@35a6e71f[libertydiag#libertydiag.war]], inboundConnection --> [com.ibm.ws.http.dispatcher.internal.channel.HttpDispatcherLink@22dbf0bd], this --> com.ibm.ws.webcontainer.osgi.DynamicVirtualHost$2@7d221183 Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser. Summary In summary, this lab demonstrated how to configure HTTP diagnostic trace in Liberty using the WebSphere Liberty Operator, exercise a request, and download the trace logs.","title":"Diagnostic trace"},{"location":"lab_liberty_diagnostic_trace/#lab-diagnostic-trace","text":"This lab covers how to enable and review diagnostic trace for a sample Liberty application in OpenShift.","title":"Lab: Diagnostic Trace"},{"location":"lab_liberty_diagnostic_trace/#theory","text":"There are multiple ways to enable diagnostic trace in Liberty in an OpenShift environment: Add a <logging traceSpecification=... /> section to server.xml or add a configuration drop-in. This only works if runtime configuration updates are enabled, as they are by default. If the application is installed using the WebSphere Liberty Operator, the WebSphereLibertyTrace custom resource may be used to enable and disable trace. This only works if runtime configuration updates are enabled, as they are by default, if the WebSphereLibertyApplication custom resource has the proper openliberty.io/day2operations annotation , and if the container has a /serviceability directory . An application image may be re-built and re-deployed with an additional <logging traceSpecification=... /> section in server.xml or using a configuration drop-in. There are various well-known diagnostic trace specifications for WebSphere Liberty .","title":"Theory"},{"location":"lab_liberty_diagnostic_trace/#labs","text":"Choose one or more labs: Lab: HTTP Diagnostic Trace by adding a configuration dropin Lab: HTTP Diagnostic Trace through the WebSphere Liberty Operator","title":"Labs"},{"location":"lab_liberty_diagnostic_trace/#lab-http-diagnostic-trace-by-adding-a-configuration-dropin","text":"This lab will enable HTTP diagnostic trace by adding a configuration dropin with a trace specification. This lab will take approximately 10 minutes.","title":"Lab: HTTP Diagnostic Trace by adding a configuration dropin"},{"location":"lab_liberty_diagnostic_trace/#step-1-install-example-application","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_diagnostic_trace/#step-2-configure-diagnostic-trace","text":"Now that the application is installed and running, you will configure diagnostic trace. You will be modifying a running pod. In some real-world cases, this may be infeasible and the image will need to be re-built and re-deployed with the updated configuration. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server. echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><logging traceSpecification=\"*=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all\" maxFileSize=\"100\" maxFiles=\"10\" /></server>' > /config/configDropins/overrides/trace.xml Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server. echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><logging traceSpecification=\"*=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all\" maxFileSize=\"100\" maxFiles=\"10\" /></server>' > /config/configDropins/overrides/trace.xml","title":"Step 2: Configure diagnostic trace"},{"location":"lab_liberty_diagnostic_trace/#step-3-exercise-an-http-request","text":"Now that HTTP diagnostic trace is configured, you will simulate an HTTP request to Liberty. Using the command line Request the following web page from your terminal to simulate an HTTP request: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Sleep\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Sleep\" Using the browser Click on the /servlet/Sleep link from the libertydiag application homepage:","title":"Step 3: Exercise an HTTP request"},{"location":"lab_liberty_diagnostic_trace/#step-4-disable-diagnostic-trace","text":"Now that the diagnostic trace has been captured, you will learn how to disable the diagnostic trace. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server back to its original value. rm /config/configDropins/overrides/trace.xml Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter . Liberty will dynamically update the diagnostic trace configuration in the server back to its original value. rm /config/configDropins/overrides/trace.xml","title":"Step 4: Disable diagnostic trace"},{"location":"lab_liberty_diagnostic_trace/#step-5-download-trace-logs","text":"Download trace logs to your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the logs by replacing $POD with a pod name from above. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:/logs . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/logs . You should be able to find the Sleep request executed above; for example: [1/3/23 16:48:19:462 UTC] 0000006d id=00000000 com.ibm.ws.webcontainer.servlet.ServletWrapper > handleRequest ServletWrapper[com.example.servlet.Sleep:[/servlet/Sleep]] ,request-> com.ibm.ws.webcontainer40.srt.SRTServletRequest40@20a8494e ,response-> com.ibm.ws.webcontainer40.srt.SRTServletResponse40@86c16c72 ENTRY [1/3/23 16:48:19:473 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Invoking com.example.servlet.Sleep by anonymous (10.254.20.1)... [] [1/3/23 16:48:20:482 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Done com.example.servlet.Sleep [1/3/23 16:48:20:495 UTC] 0000006d id=7d221183 com.ibm.ws.webcontainer.osgi.DynamicVirtualHost 3 Webcontainer handleRequest complete for--> [/servlet/Sleep], mapped webApp context [com.ibm.ws.webcontainer40.osgi.webapp.WebApp40@35a6e71f[libertydiag#libertydiag.war]], inboundConnection --> [com.ibm.ws.http.dispatcher.internal.channel.HttpDispatcherLink@22dbf0bd], this --> com.ibm.ws.webcontainer.osgi.DynamicVirtualHost$2@7d221183 Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser.","title":"Step 5: Download trace logs"},{"location":"lab_liberty_diagnostic_trace/#summary","text":"In summary, this lab demonstrated how to configure HTTP diagnostic trace in Liberty, exercise a request, and download the trace logs.","title":"Summary"},{"location":"lab_liberty_diagnostic_trace/#lab-http-diagnostic-trace-through-the-websphere-liberty-operator","text":"This lab will enable HTTP diagnostic trace using the WebSphere Liberty Operator with an example application and review the output. This lab will take approximately 10 minutes.","title":"Lab: HTTP Diagnostic Trace through the WebSphere Liberty Operator"},{"location":"lab_liberty_diagnostic_trace/#step-1-install-example-application_1","text":"If you haven't already, install the sample application using the WebSphere Liberty operator. If you installed it in a previous lab, you may continue using the previous installation. If you previously installed the sample using a basic Kubernetes deployment, then uninstall it and re-install using the WebSphere Liberty operator.","title":"Step 1: Install example application"},{"location":"lab_liberty_diagnostic_trace/#step-2-configure-diagnostic-trace_1","text":"Now that the application is installed and running, you will configure diagnostic trace using the WebSphere Liberty Operator trace custom resource . Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Create a trace.yaml file, replacing $POD with the name of the pod from the previous command (e.g. libertydiag-b98748954-mgj64 ): apiVersion: liberty.websphere.ibm.com/v1 kind: WebSphereLibertyTrace metadata: name: libertytrace1 annotations: day2operation.openliberty.io/targetKinds: Pod spec: license: accept: true podName: $POD traceSpecification: \"*=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all\" maxFileSize: 100 maxFiles: 5 disable: false Apply the YAML: oc apply -f trace.yaml Using the browser Ensure the perspective is set to Developer in the top left: Set your current namespace/project to what you were provided. For example: In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then copy the name of the pod that's running: Click Operator Backed on the +Add page: Click WebSphereLibertyTrace and then click Create Expand License and check accept Paste the pod name from the step above into the podName text box. Set the traceSpecification to: *=info:com.ibm.ws.webcontainer*=all:com.ibm.wsspi.webcontainer*=all:HTTPChannel=all:GenericBNF=all:HTTPDispatcher=all Set maxFileSize to 100 Click Create","title":"Step 2: Configure diagnostic trace"},{"location":"lab_liberty_diagnostic_trace/#step-3-exercise-an-http-request_1","text":"Now that HTTP diagnostic trace is configured, you will simulate an HTTP request to Liberty. Using the command line Request the following web page from your terminal to simulate an HTTP request: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/Sleep\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/Sleep\" Using the browser Click on the /servlet/Sleep link from the libertydiag application homepage:","title":"Step 3: Exercise an HTTP request"},{"location":"lab_liberty_diagnostic_trace/#step-4-disable-diagnostic-trace_1","text":"Now that the diagnostic trace has been captured, you will learn how to disable the diagnostic trace. Using the command line List WebSphereLibertyTrace custom resources; for example: oc get wltrace Example output: NAME PODNAME TRACING libertytrace1 libertydiag-5fdf699f-sfwqn True Delete the custom resource you created earlier; for example: oc delete wltrace libertytrace1 Using the browser Click on Search , click the Resources drop down, search for trace , check WebSphereLibertyTrace , click the vertical ellipses next to the custom resource created earlier, click Delete WebSphereLibertyTrace , and click Delete :","title":"Step 4: Disable diagnostic trace"},{"location":"lab_liberty_diagnostic_trace/#step-5-download-trace-logs_1","text":"Download trace logs to your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the logs by replacing $POD with a pod name from above and $NAMESPACE with your namespace. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:/serviceability/$NAMESPACE/$POD/ . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/serviceability/user15-namespace/libertydiag-ddf5f95b6-wj6dm/ . You should be able to find the Sleep request executed above; for example: [1/3/23 16:48:19:462 UTC] 0000006d id=00000000 com.ibm.ws.webcontainer.servlet.ServletWrapper > handleRequest ServletWrapper[com.example.servlet.Sleep:[/servlet/Sleep]] ,request-> com.ibm.ws.webcontainer40.srt.SRTServletRequest40@20a8494e ,response-> com.ibm.ws.webcontainer40.srt.SRTServletResponse40@86c16c72 ENTRY [1/3/23 16:48:19:473 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Invoking com.example.servlet.Sleep by anonymous (10.254.20.1)... [] [1/3/23 16:48:20:482 UTC] 0000006d id=00000000 com.example.util.BaseServlet I libertydiag: Done com.example.servlet.Sleep [1/3/23 16:48:20:495 UTC] 0000006d id=7d221183 com.ibm.ws.webcontainer.osgi.DynamicVirtualHost 3 Webcontainer handleRequest complete for--> [/servlet/Sleep], mapped webApp context [com.ibm.ws.webcontainer40.osgi.webapp.WebApp40@35a6e71f[libertydiag#libertydiag.war]], inboundConnection --> [com.ibm.ws.http.dispatcher.internal.channel.HttpDispatcherLink@22dbf0bd], this --> com.ibm.ws.webcontainer.osgi.DynamicVirtualHost$2@7d221183 Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser.","title":"Step 5: Download trace logs"},{"location":"lab_liberty_diagnostic_trace/#summary_1","text":"In summary, this lab demonstrated how to configure HTTP diagnostic trace in Liberty using the WebSphere Liberty Operator, exercise a request, and download the trace logs.","title":"Summary"},{"location":"lab_liberty_high_cpu/","text":"Lab: High CPU This lab covers how to investigate high CPU for a sample Liberty application in OpenShift. Theory There are many ways to review high CPU for Liberty in an OpenShift environment: Review verbose garbage collection during the issue to check for a high proportion of time in garbage collection Manually gather thread dumps during the issue by opening a terminal in the container and executing kill -3 $PID If the application is installed using the WebSphere Liberty Operator, the WebSphereLibertyDump custom resource may be used to gather a Liberty server dump with a thread dump. This only works if the WebSphereLibertyApplication custom resource has the proper openliberty.io/day2operations annotation , and if the container has a /serviceability directory . If you have cluster-admin permissions, use the MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers during the issue and search for repeating patterns in thread dumps If running IBM Java 8, gather a headless mode HealthCenter Java sampling profiler collection If you have cluster-admin permissions, gather a Linux perf native sampling profiler collection Run top -H to review per-thread CPU utilization, if the container image includes the top utility Use third-party monitoring products such as Instana This lab will only cover some of the above methods. Labs Choose one or more labs: Lab: Manually gather thread dumps during the issue Lab: Use the performance/hang/high CPU MustGather on Linux on Containers You could also gather a server dump as done in the High response times lab Lab: Manually gather thread dumps during the issue This lab will gather thread dumps showing accumulated CPU by thread and associated stacks. Any statistical patterns in thread stacks associated with high CPU threads may be used to infer potential causes of high CPU. This method is generally used when there is persistently high CPU. If CPU spikes are infrequent, then this technique is more difficult unless you capture a lot of thread dumps. This lab will take approximately 10 minutes. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Exercise high CPU You will simulate 5 concurrent users sending HTTP requests that perform CPU intensive operations such as compiling regular expressions and performing mathematical operations. Using the command line Request the following web page from your terminal to exercise high CPU: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" This load will run indefinitely. Continue to the next step. Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/DoComplicatedStuff?moreiterations=true Scroll down and check Infinite (until manually stopped) Scroll to the bottom and click Start This load will run indefinitely. Continue to the next step. Step 3: Manually gather thread dumps Now you will gather a number of thread dumps. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Note that the remote shell might timeout after a short period of inactivity, so be aware that you might have been logged out and you'll need to oc rsh back in to continue where you left off. First, we need to find the process ID (PID) of Liberty. Most Liberty images do not have tools like ps or top pre-installed. However, most Liberty images only have a single process in the container which is the Java process running Liberty, and this has the PID of 1. Double check that this is the Liberty process by doing a full listing on PID 1: ls -l /proc/1/ If you see a Liberty current working directory ( cwd ) such as /opt/ol/wlp or /opt/ibm/wlp then you can assume that is the Liberty process. Otherwise, run ls -l /proc/[0-9]* and then explore each PID to find the Liberty process. ls -l /proc/1 Example output: [...] lrwxrwxrwx. 1 1000830000 root 0 Dec 6 17:45 cwd -> /opt/ol/wlp/output/defaultServer -r--------. 1 1000830000 root 0 Dec 6 17:45 environ lrwxrwxrwx. 1 1000830000 root 0 Dec 6 14:57 exe -> /opt/ibm/java/jre/bin/java [...] Create a thread dump by sending the SIGQUIT signal to the process using the kill -QUIT $PID command. Replace $PID with the process ID of Liberty that you found above. Note that, by default, Java handles the SIGQUIT signal, creates the thread dump, and the process continues, so the process is not killed, despite the names of the command and signal. kill -QUIT 1 It's common to wait about 30 seconds between thread dumps. Take another 1 or more thread dumps, waiting some time in between. kill -QUIT 1 Normally, thread dumps for IBM Java and Semeru will be produced as javacore*txt files in the cwd directory that you found above: ls -l /opt/ol/wlp/output/defaultServer/javacore*txt However, in the case of this sample application, this directory is overridden with an -Xdump configuration. You can check JVM configurations by printing the process cmdline and environ files and find the relevant configuration. For example: cat /proc/1/cmdline /proc/1/environ Example output: [...] -Xdump:directory=logs/diagnostics/ Therefore, for this application, javacores will go into logs/diagnostics/ relative to cwd : ls /opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*txt Example output: /opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore.20221206.175535.1.0001.txt /opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore.20221206.175626.1.0002.txt Note that overridding the -Xdump directory is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed. Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Follow the Using the command line steps above starting at step 4. Step 4: Download thread dumps Using the command line Download the thread dumps by replacing $POD with a pod name from above and $DIR with the directory of the javacores. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:$DIR . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/opt/ol/wlp/output/defaultServer/logs/diagnostics . Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser. Step 5: Analyze the thread dumps If you are familiar with analyzing thread dumps for high CPU, you may skip this step. Review thread dumps Open each thread dump and search for Thread Details : 1XMTHDINFO Thread Details Review each thread (starting with 3XMTHREADINFO ) and, in particular, the 3XMCPUTIME line: 3XMTHREADINFO \"Default Executor-thread-189\" J9VMThread:0x00000000002BA700, omrthread_t:0x00007F7FD0014240, java/lang/Thread:0x00000000E43D62C0, state:R, prio=5 [...] 3XMCPUTIME CPU usage total: 6.839021278 secs, current category=\"Application\" The CPU usage total is accumulated CPU usage since the beginning of that thread. Therefore, finding high users of CPU is most commonly done by comparing these values across thread dumps for particular threads. Note that if a thread is short-lived, then it may not be captured in the thread dumps, or may only exist in a subset of thread dumps. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU. In this case, there is a peristent pattern of application stacks in the DoComplicatedStuff.doWork method driving code such as mathematical operations, regular expression compilation, etc. For example: 3XMTHREADINFO3 Java callstack: 4XESTACKTRACE at java/math/BigInteger.cutOffLeadingZeroes(BigInteger.java:1505(Compiled Code)) 4XESTACKTRACE at java/math/Division.divideAndRemainderByInteger(Division.java:344(Compiled Code)) 4XESTACKTRACE at java/math/BigInteger.divideAndRemainder(BigInteger.java:1202(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.slScaledDivide(BigDecimal.java:3489(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2446(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2424(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2389(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.arctan(DoComplicatedStuff.java:141(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.computePi(DoComplicatedStuff.java:119(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.doWork(DoComplicatedStuff.java:60(Compiled Code)) Step 6: Clean-up The pod will be using a lot of CPU, so you will kill the pod. Kubernetes will automatically create a new replacement pod in preparation for the next lab. Using the command line List the pods; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Kill the running pod by replacing $POD with a pod name from the previous command: oc delete pod $POD For example: oc delete pod libertydiag-b98748954-mgj64 Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: In the top right, click Actions } Delete Pod Summary In summary, this lab demonstrated how to manually gather thread dumps for Liberty running in a container and review CPU utilization by thread over time. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU. Lab: Use the performance/hang/high CPU MustGather on Linux on Containers This lab will use IBM Support's MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers to gather thread dumps showing any requests being processed. Any statistical patterns in thread stacks may be used to infer potential causes of high CPU. This MustGather is publicly available and nearly the same as the standalone Linux performance/hang/high-CPU MustGather in that it gathers CPU, memory, disk, network information, thread dumps, etc., and customers should be encouraged to use it if they can accept that it requires cluster-admin permissions to execute. This lab will demonstrate how to execute the MustGather, download the diagnostics, and review them for potential causes of high CPU. Note : This lab requires that the user has cluster-admin permissions. A future version of the MustGather will not require administrator permissions. This lab will take approximately 10 minutes. Step 0: Check if you have cluster-admin permissions These steps will show if you have cluster-admin permissions. If you do not, you must skip this lab. Using the command line Check if you have authority for all verbs on all resources: oc auth can-i '*' '*' Example output: yes If the answer is no , then you do not have cluster-admin permissions. Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Administrator in the top left: Expand User Management . If you don't see a Users option, then you do not have cluster-admin permissions. If you do see it, click on it, and then click on your user name: Click on RoleBindings and check if any binding has a Role ref of cluster-admin . If there are none, then you do not have cluster-admin permissions. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Exercise high CPU You will simulate 5 concurrent users sending HTTP requests that perform CPU intensive operations such as compiling regular expressions and performing mathematical operations. Using the command line Request the following web page from your terminal to exercise high CPU: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" This load will run indefinitely. Continue to the next step. Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/DoComplicatedStuff?moreiterations=true Scroll down and check Infinite (until manually stopped) Scroll to the bottom and click Start This load will run indefinitely. Continue to the next step. Step 3: Execute the MustGather Now you will execute the MustGather. This takes approximately 6 minutes to run. Using the command line Download a helper script: macOS or Linux: containerdiag.sh Windows: containerdiag.bat Open a Terminal or Command Prompt and change directory to where you downloaded the script On macOS or Linux, make the script executable: chmod +x containerdiag.sh On macOS, remove the download quarantine: xattr -d com.apple.quarantine containerdiag.sh List the current deployments: oc get deployments Example output: NAME READY UP-TO-DATE AVAILABLE AGE libertydiag 1/1 1 1 13m Execute the MustGather. Normally, the -c option specifying the directory of the javacores is not needed; however, this sample application overrides the default javacore directory using -Xdump . This is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed. macOS or Linux: ./containerdiag.sh -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" Windows: containerdiag.bat -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" When the MustGather is complete, you will see a repeating message of the form: run.sh: Files are ready for download. Download with the following command in another window: oc cp [...] Open another Terminal or Command Prompt and copy & paste the oc cp line that you saw in the previous step. For example (your command will be different): $ oc cp worker4-debug:/tmp/containerdiag.SN9RbwVmfC.tar.gz containerdiag.SN9RbwVmfC.tar.gz --namespace=openshift-debug-node-g8dqbdfx5d tar: Removing leading `/' from member names Go back to the previous Terminal or Command Prompt , type ok , and press Enter to complete the MustGather: After the download is complete, type OK and press ENTER: ok [2022-11-08 19:01:03.670923238 UTC] run.sh: Processing finished. Deleting /tmp/containerdiag.SN9RbwVmfC.tar.gz [2022-11-08 19:01:03.674236286 UTC] run.sh: finished. Expand the containerdiag.*.tar.gz file that you downloaded. Using the browser The MustGather cannot be executed from the browser. You must use the command line steps above.browser. Step 4: Analyze the thread dumps If you are familiar with analyzing thread dumps for high CPU, you may skip this step. Review the MustGather data First, review the top -H output to see CPU utilization by thread. Expand linperf_RESULTS.tar.gz in the root directory and then review topdashH*.out . Open each thread dump under pods/libertydiag*/containers/libertydiag/ and search for Thread Details : 1XMTHDINFO Thread Details Review each thread (starting with 3XMTHREADINFO ) and, in particular, the 3XMCPUTIME line: 3XMTHREADINFO \"Default Executor-thread-189\" J9VMThread:0x00000000002BA700, omrthread_t:0x00007F7FD0014240, java/lang/Thread:0x00000000E43D62C0, state:R, prio=5 [...] 3XMCPUTIME CPU usage total: 6.839021278 secs, current category=\"Application\" The CPU usage total is accumulated CPU usage since the beginning of that thread. Therefore, finding high users of CPU is most commonly done by comparing these values across thread dumps for particular threads. Note that if a thread is short-lived, then it may not be captured in the thread dumps, or may only exist in a subset of thread dumps. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU. In this case, there is a peristent pattern of application stacks in the DoComplicatedStuff.doWork method driving code such as mathematical operations, regular expression compilation, etc. For example: 3XMTHREADINFO3 Java callstack: 4XESTACKTRACE at java/math/BigInteger.cutOffLeadingZeroes(BigInteger.java:1505(Compiled Code)) 4XESTACKTRACE at java/math/Division.divideAndRemainderByInteger(Division.java:344(Compiled Code)) 4XESTACKTRACE at java/math/BigInteger.divideAndRemainder(BigInteger.java:1202(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.slScaledDivide(BigDecimal.java:3489(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2446(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2424(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2389(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.arctan(DoComplicatedStuff.java:141(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.computePi(DoComplicatedStuff.java:119(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.doWork(DoComplicatedStuff.java:60(Compiled Code)) Step 5: Clean-up The pod will be using a lot of CPU, so you will kill the pod. Kubernetes will automatically create a new replacement pod in preparation for the next lab. Using the command line List the pods; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Kill the running pod by replacing $POD with a pod name from the previous command: oc delete pod $POD For example: oc delete pod libertydiag-b98748954-mgj64 Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: In the top right, click Actions } Delete Pod Summary In summary, this lab demonstrated how to execute the performance/hang/high CPU MustGather on Linux on Containers , download the diagnostics, and review them for high CPU usage. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU.","title":"High CPU"},{"location":"lab_liberty_high_cpu/#lab-high-cpu","text":"This lab covers how to investigate high CPU for a sample Liberty application in OpenShift.","title":"Lab: High CPU"},{"location":"lab_liberty_high_cpu/#theory","text":"There are many ways to review high CPU for Liberty in an OpenShift environment: Review verbose garbage collection during the issue to check for a high proportion of time in garbage collection Manually gather thread dumps during the issue by opening a terminal in the container and executing kill -3 $PID If the application is installed using the WebSphere Liberty Operator, the WebSphereLibertyDump custom resource may be used to gather a Liberty server dump with a thread dump. This only works if the WebSphereLibertyApplication custom resource has the proper openliberty.io/day2operations annotation , and if the container has a /serviceability directory . If you have cluster-admin permissions, use the MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers during the issue and search for repeating patterns in thread dumps If running IBM Java 8, gather a headless mode HealthCenter Java sampling profiler collection If you have cluster-admin permissions, gather a Linux perf native sampling profiler collection Run top -H to review per-thread CPU utilization, if the container image includes the top utility Use third-party monitoring products such as Instana This lab will only cover some of the above methods.","title":"Theory"},{"location":"lab_liberty_high_cpu/#labs","text":"Choose one or more labs: Lab: Manually gather thread dumps during the issue Lab: Use the performance/hang/high CPU MustGather on Linux on Containers You could also gather a server dump as done in the High response times lab","title":"Labs"},{"location":"lab_liberty_high_cpu/#lab-manually-gather-thread-dumps-during-the-issue","text":"This lab will gather thread dumps showing accumulated CPU by thread and associated stacks. Any statistical patterns in thread stacks associated with high CPU threads may be used to infer potential causes of high CPU. This method is generally used when there is persistently high CPU. If CPU spikes are infrequent, then this technique is more difficult unless you capture a lot of thread dumps. This lab will take approximately 10 minutes.","title":"Lab: Manually gather thread dumps during the issue"},{"location":"lab_liberty_high_cpu/#step-1-install-example-application","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_high_cpu/#step-2-exercise-high-cpu","text":"You will simulate 5 concurrent users sending HTTP requests that perform CPU intensive operations such as compiling regular expressions and performing mathematical operations. Using the command line Request the following web page from your terminal to exercise high CPU: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" This load will run indefinitely. Continue to the next step. Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/DoComplicatedStuff?moreiterations=true Scroll down and check Infinite (until manually stopped) Scroll to the bottom and click Start This load will run indefinitely. Continue to the next step.","title":"Step 2: Exercise high CPU"},{"location":"lab_liberty_high_cpu/#step-3-manually-gather-thread-dumps","text":"Now you will gather a number of thread dumps. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Note that the remote shell might timeout after a short period of inactivity, so be aware that you might have been logged out and you'll need to oc rsh back in to continue where you left off. First, we need to find the process ID (PID) of Liberty. Most Liberty images do not have tools like ps or top pre-installed. However, most Liberty images only have a single process in the container which is the Java process running Liberty, and this has the PID of 1. Double check that this is the Liberty process by doing a full listing on PID 1: ls -l /proc/1/ If you see a Liberty current working directory ( cwd ) such as /opt/ol/wlp or /opt/ibm/wlp then you can assume that is the Liberty process. Otherwise, run ls -l /proc/[0-9]* and then explore each PID to find the Liberty process. ls -l /proc/1 Example output: [...] lrwxrwxrwx. 1 1000830000 root 0 Dec 6 17:45 cwd -> /opt/ol/wlp/output/defaultServer -r--------. 1 1000830000 root 0 Dec 6 17:45 environ lrwxrwxrwx. 1 1000830000 root 0 Dec 6 14:57 exe -> /opt/ibm/java/jre/bin/java [...] Create a thread dump by sending the SIGQUIT signal to the process using the kill -QUIT $PID command. Replace $PID with the process ID of Liberty that you found above. Note that, by default, Java handles the SIGQUIT signal, creates the thread dump, and the process continues, so the process is not killed, despite the names of the command and signal. kill -QUIT 1 It's common to wait about 30 seconds between thread dumps. Take another 1 or more thread dumps, waiting some time in between. kill -QUIT 1 Normally, thread dumps for IBM Java and Semeru will be produced as javacore*txt files in the cwd directory that you found above: ls -l /opt/ol/wlp/output/defaultServer/javacore*txt However, in the case of this sample application, this directory is overridden with an -Xdump configuration. You can check JVM configurations by printing the process cmdline and environ files and find the relevant configuration. For example: cat /proc/1/cmdline /proc/1/environ Example output: [...] -Xdump:directory=logs/diagnostics/ Therefore, for this application, javacores will go into logs/diagnostics/ relative to cwd : ls /opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*txt Example output: /opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore.20221206.175535.1.0001.txt /opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore.20221206.175626.1.0002.txt Note that overridding the -Xdump directory is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed. Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Follow the Using the command line steps above starting at step 4.","title":"Step 3: Manually gather thread dumps"},{"location":"lab_liberty_high_cpu/#step-4-download-thread-dumps","text":"Using the command line Download the thread dumps by replacing $POD with a pod name from above and $DIR with the directory of the javacores. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:$DIR . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/opt/ol/wlp/output/defaultServer/logs/diagnostics . Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser.","title":"Step 4: Download thread dumps"},{"location":"lab_liberty_high_cpu/#step-5-analyze-the-thread-dumps","text":"If you are familiar with analyzing thread dumps for high CPU, you may skip this step. Review thread dumps Open each thread dump and search for Thread Details : 1XMTHDINFO Thread Details Review each thread (starting with 3XMTHREADINFO ) and, in particular, the 3XMCPUTIME line: 3XMTHREADINFO \"Default Executor-thread-189\" J9VMThread:0x00000000002BA700, omrthread_t:0x00007F7FD0014240, java/lang/Thread:0x00000000E43D62C0, state:R, prio=5 [...] 3XMCPUTIME CPU usage total: 6.839021278 secs, current category=\"Application\" The CPU usage total is accumulated CPU usage since the beginning of that thread. Therefore, finding high users of CPU is most commonly done by comparing these values across thread dumps for particular threads. Note that if a thread is short-lived, then it may not be captured in the thread dumps, or may only exist in a subset of thread dumps. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU. In this case, there is a peristent pattern of application stacks in the DoComplicatedStuff.doWork method driving code such as mathematical operations, regular expression compilation, etc. For example: 3XMTHREADINFO3 Java callstack: 4XESTACKTRACE at java/math/BigInteger.cutOffLeadingZeroes(BigInteger.java:1505(Compiled Code)) 4XESTACKTRACE at java/math/Division.divideAndRemainderByInteger(Division.java:344(Compiled Code)) 4XESTACKTRACE at java/math/BigInteger.divideAndRemainder(BigInteger.java:1202(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.slScaledDivide(BigDecimal.java:3489(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2446(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2424(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2389(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.arctan(DoComplicatedStuff.java:141(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.computePi(DoComplicatedStuff.java:119(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.doWork(DoComplicatedStuff.java:60(Compiled Code))","title":"Step 5: Analyze the thread dumps"},{"location":"lab_liberty_high_cpu/#step-6-clean-up","text":"The pod will be using a lot of CPU, so you will kill the pod. Kubernetes will automatically create a new replacement pod in preparation for the next lab. Using the command line List the pods; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Kill the running pod by replacing $POD with a pod name from the previous command: oc delete pod $POD For example: oc delete pod libertydiag-b98748954-mgj64 Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: In the top right, click Actions } Delete Pod","title":"Step 6: Clean-up"},{"location":"lab_liberty_high_cpu/#summary","text":"In summary, this lab demonstrated how to manually gather thread dumps for Liberty running in a container and review CPU utilization by thread over time. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU.","title":"Summary"},{"location":"lab_liberty_high_cpu/#lab-use-the-performancehanghigh-cpu-mustgather-on-linux-on-containers","text":"This lab will use IBM Support's MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers to gather thread dumps showing any requests being processed. Any statistical patterns in thread stacks may be used to infer potential causes of high CPU. This MustGather is publicly available and nearly the same as the standalone Linux performance/hang/high-CPU MustGather in that it gathers CPU, memory, disk, network information, thread dumps, etc., and customers should be encouraged to use it if they can accept that it requires cluster-admin permissions to execute. This lab will demonstrate how to execute the MustGather, download the diagnostics, and review them for potential causes of high CPU. Note : This lab requires that the user has cluster-admin permissions. A future version of the MustGather will not require administrator permissions. This lab will take approximately 10 minutes.","title":"Lab: Use the performance/hang/high CPU MustGather on Linux on Containers"},{"location":"lab_liberty_high_cpu/#step-0-check-if-you-have-cluster-admin-permissions","text":"These steps will show if you have cluster-admin permissions. If you do not, you must skip this lab. Using the command line Check if you have authority for all verbs on all resources: oc auth can-i '*' '*' Example output: yes If the answer is no , then you do not have cluster-admin permissions. Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Administrator in the top left: Expand User Management . If you don't see a Users option, then you do not have cluster-admin permissions. If you do see it, click on it, and then click on your user name: Click on RoleBindings and check if any binding has a Role ref of cluster-admin . If there are none, then you do not have cluster-admin permissions.","title":"Step 0: Check if you have cluster-admin permissions"},{"location":"lab_liberty_high_cpu/#step-1-install-example-application_1","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_high_cpu/#step-2-exercise-high-cpu_1","text":"You will simulate 5 concurrent users sending HTTP requests that perform CPU intensive operations such as compiling regular expressions and performing mathematical operations. Using the command line Request the following web page from your terminal to exercise high CPU: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FDoComplicatedStuff%3Fmoreiterations%3Dtrue&method=get&entity=&concurrentusers=5&totalrequests=0&user=&password=&infinite=on\" This load will run indefinitely. Continue to the next step. Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/DoComplicatedStuff?moreiterations=true Scroll down and check Infinite (until manually stopped) Scroll to the bottom and click Start This load will run indefinitely. Continue to the next step.","title":"Step 2: Exercise high CPU"},{"location":"lab_liberty_high_cpu/#step-3-execute-the-mustgather","text":"Now you will execute the MustGather. This takes approximately 6 minutes to run. Using the command line Download a helper script: macOS or Linux: containerdiag.sh Windows: containerdiag.bat Open a Terminal or Command Prompt and change directory to where you downloaded the script On macOS or Linux, make the script executable: chmod +x containerdiag.sh On macOS, remove the download quarantine: xattr -d com.apple.quarantine containerdiag.sh List the current deployments: oc get deployments Example output: NAME READY UP-TO-DATE AVAILABLE AGE libertydiag 1/1 1 1 13m Execute the MustGather. Normally, the -c option specifying the directory of the javacores is not needed; however, this sample application overrides the default javacore directory using -Xdump . This is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed. macOS or Linux: ./containerdiag.sh -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" Windows: containerdiag.bat -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" When the MustGather is complete, you will see a repeating message of the form: run.sh: Files are ready for download. Download with the following command in another window: oc cp [...] Open another Terminal or Command Prompt and copy & paste the oc cp line that you saw in the previous step. For example (your command will be different): $ oc cp worker4-debug:/tmp/containerdiag.SN9RbwVmfC.tar.gz containerdiag.SN9RbwVmfC.tar.gz --namespace=openshift-debug-node-g8dqbdfx5d tar: Removing leading `/' from member names Go back to the previous Terminal or Command Prompt , type ok , and press Enter to complete the MustGather: After the download is complete, type OK and press ENTER: ok [2022-11-08 19:01:03.670923238 UTC] run.sh: Processing finished. Deleting /tmp/containerdiag.SN9RbwVmfC.tar.gz [2022-11-08 19:01:03.674236286 UTC] run.sh: finished. Expand the containerdiag.*.tar.gz file that you downloaded. Using the browser The MustGather cannot be executed from the browser. You must use the command line steps above.browser.","title":"Step 3: Execute the MustGather"},{"location":"lab_liberty_high_cpu/#step-4-analyze-the-thread-dumps","text":"If you are familiar with analyzing thread dumps for high CPU, you may skip this step. Review the MustGather data First, review the top -H output to see CPU utilization by thread. Expand linperf_RESULTS.tar.gz in the root directory and then review topdashH*.out . Open each thread dump under pods/libertydiag*/containers/libertydiag/ and search for Thread Details : 1XMTHDINFO Thread Details Review each thread (starting with 3XMTHREADINFO ) and, in particular, the 3XMCPUTIME line: 3XMTHREADINFO \"Default Executor-thread-189\" J9VMThread:0x00000000002BA700, omrthread_t:0x00007F7FD0014240, java/lang/Thread:0x00000000E43D62C0, state:R, prio=5 [...] 3XMCPUTIME CPU usage total: 6.839021278 secs, current category=\"Application\" The CPU usage total is accumulated CPU usage since the beginning of that thread. Therefore, finding high users of CPU is most commonly done by comparing these values across thread dumps for particular threads. Note that if a thread is short-lived, then it may not be captured in the thread dumps, or may only exist in a subset of thread dumps. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU. In this case, there is a peristent pattern of application stacks in the DoComplicatedStuff.doWork method driving code such as mathematical operations, regular expression compilation, etc. For example: 3XMTHREADINFO3 Java callstack: 4XESTACKTRACE at java/math/BigInteger.cutOffLeadingZeroes(BigInteger.java:1505(Compiled Code)) 4XESTACKTRACE at java/math/Division.divideAndRemainderByInteger(Division.java:344(Compiled Code)) 4XESTACKTRACE at java/math/BigInteger.divideAndRemainder(BigInteger.java:1202(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.slScaledDivide(BigDecimal.java:3489(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2446(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2424(Compiled Code)) 4XESTACKTRACE at java/math/BigDecimal.divide(BigDecimal.java:2389(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.arctan(DoComplicatedStuff.java:141(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.computePi(DoComplicatedStuff.java:119(Compiled Code)) 4XESTACKTRACE at com/example/servlet/DoComplicatedStuff.doWork(DoComplicatedStuff.java:60(Compiled Code))","title":"Step 4: Analyze the thread dumps"},{"location":"lab_liberty_high_cpu/#step-5-clean-up","text":"The pod will be using a lot of CPU, so you will kill the pod. Kubernetes will automatically create a new replacement pod in preparation for the next lab. Using the command line List the pods; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Kill the running pod by replacing $POD with a pod name from the previous command: oc delete pod $POD For example: oc delete pod libertydiag-b98748954-mgj64 Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: In the top right, click Actions } Delete Pod","title":"Step 5: Clean-up"},{"location":"lab_liberty_high_cpu/#summary_1","text":"In summary, this lab demonstrated how to execute the performance/hang/high CPU MustGather on Linux on Containers , download the diagnostics, and review them for high CPU usage. With a sufficient number of thread dumps and a persistent pattern of stack tops for high CPU threads, this may be used to hypothesize likely causes of high CPU.","title":"Summary"},{"location":"lab_liberty_high_http_response_times/","text":"Lab: High Response Times This lab covers how to investigate high HTTP response times for a sample Liberty application in OpenShift. Theory There are many ways to track and review HTTP response times for Liberty in an OpenShift environment: Review response times exceeding a configured threshold using Liberty's slow and hung request detection Manually gather thread dumps during the issue by opening a terminal in the container and executing kill -3 $PID If the application is installed using the WebSphere Liberty Operator, the WebSphereLibertyDump custom resource may be used to gather a Liberty server dump with a thread dump. This only works if the WebSphereLibertyApplication custom resource has the proper openliberty.io/day2operations annotation , and if the container has a /serviceability directory . If you have cluster-admin permissions, use the MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers during the issue and search for repeating patterns in thread dumps Review individual HTTP response times with Liberty's HTTP access logging , although this will not discover stack traces driving slow response times Review average and maximum response times with Eclipse MicroProfile Metrics in Liberty (or in an OpenShift Service ) integrated with Prometheus and Grafana in OpenShift or direct queries with a ServiceMonitor , although these techniques will not discover stack traces driving slow response times Review individual JAX-RS microservice response times with Eclipse MicroProfile OpenTelemetry (formerly OpenTracing) with Jaeger or Zipkin, although this will not discover stack traces driving slow response times Use third-party monitoring products such as Instana This lab will only cover some of the above methods. Labs Choose one or more labs: Lab: Response times exceeding a configured threshold Lab: Gather a Liberty server dump through the WebSphere Liberty Operator Lab: Use the performance/hang/high CPU MustGather on Linux on Containers You could also gather thread dumps using kill -3 as done in the High CPU lab . Lab: Response times exceeding a configured threshold This lab will use Liberty's slow and hung request detection to print information about HTTP requests that exceed a configured threshold to logs. This method is generally used when there are intermittent HTTP response time spikes. For example, if the average response time is 5 seconds but users are experiencing intermittent response time spikes of 10 seconds that are unacceptable, then the threshold may be set to 9 seconds to investigate the spikes. This lab will demonstrate how to configure Liberty's requestTiming feature , trigger it with an example application, and review the output. The major downside to this approach is that the performance overhead of requestTiming is non-constant. The overhead is proportional to the volume and complexity of requests which should be determined in a performance test environment before configuring requestTiming in production. The main way to reduce the performance overhead is to increase the sampleRate although any value greater than 1 creates a chance of missing some slow requests. In this lab, you will be using the slowRequestThreshold to trigger the details to the log. There is also a hungRequestThreshold that may be configured although it won't be covered in this lab. When hungRequestThreshold is breached, in addition to the same log message as with slowRequestThreshold , Liberty will take 3 thread dumps, one minute apart. This lab will take approximately 10 minutes. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Configure requestTiming Now that the application is installed and running, you will configure requestTiming to trigger if an HTTP request takes longer than 9 seconds. You will be modifying a running pod. In some real-world cases, this may be infeasible and the image will need to be re-built and re-deployed with the updated configuration. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter . Liberty will dynamically update the requestTiming configuration in the server (assuming the feature is installed, which it usually is). echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><featureManager><feature>requestTiming-1.0</feature></featureManager><requestTiming slowRequestThreshold=\"9s\" hungRequestThreshold=\"300s\" sampleRate=\"1\" /></server>' > /config/configDropins/overrides/requestTiming.xml Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter . Liberty will dynamically update the requestTiming configuration in the server (assuming the feature is installed, which it usually is). echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><featureManager><feature>requestTiming-1.0</feature></featureManager><requestTiming slowRequestThreshold=\"9s\" hungRequestThreshold=\"300s\" sampleRate=\"1\" /></server>' > /config/configDropins/overrides/requestTiming.xml Step 3: Exercise long HTTP requests Now that requestTiming is configured, you will simulate HTTP requests to Liberty and some of them will exceed 9 seconds. This will be done by executing 5 concurrent users that sleep a random amount of time with an average of 5 seconds and a standard deviation of 4 seconds. This means that approximately 68% of requests will be between 1-9 seconds, and the remaining will be either below 1 seconds or above 9 seconds, thus simulating a situation where most requests are fine but a minority exceed the defined threshold. Using the command line Request the following web page from your terminal to exercise long requests: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Request the following web page from your terminal to check on the status of the run: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/loadrunner.jsp\" | grep 'li>Run' Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/loadrunner.jsp\" | findstr 'li>Run' Keep executing the above command until you see that the max execution value exceeds 9000 . This means at least one request took more than 9 seconds. (In the statistically rare chance that this doesn't happen, start again at step 1). Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/Sleep?mean=5000&stddev=4000 Scroll to the bottom and click Start You may refresh this page to check on the status of the run. Note that refreshing does not start a new run. Keep refreshing until you see that the max execution value exceeds 9000 . This means at least one request took more than 9 seconds. (In the statistically rare chance that this doesn't happen, Start the load again.) Step 4: Review data on long HTTP requests Now you will review the logs to understand how to investigate slow HTTP requests. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter : cat /logs/messages.log Scroll up until you find the TRAS0112W warning message signifying that an HTTP request exceeded the requestTiming configured threshold. For example: [11/1/22 20:02:12:053 UTC] 00000074 com.ibm.ws.request.timing.manager.SlowRequestManager W TRAS0112W: Request AAPj5+4YXW3_AAAAAAAAAB5 has been running on thread 00000071 for at least 9000.263ms. The following stack trace shows what this thread is currently running. at java.lang.Thread.sleepImpl(Native Method) at java.lang.Thread.sleep(Thread.java:977) at java.lang.Thread.sleep(Thread.java:960) at com.example.servlet.Sleep.doSleep(Sleep.java:79) at com.example.servlet.Sleep.doWork(Sleep.java:40) at com.example.util.BaseServlet.service(BaseServlet.java:104) at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:587) [...] The following table shows the events that have run during this request. Duration Operation 9001.583ms + websphere.servlet.service | libertydiag | com.example.servlet.Sleep?mean=5000&stddev=4000 The warning message notes how long the request had been running at the time of the warning ( 9000.263ms ) followed by a stack trace of what the thread was doing. The stack trace is the main symptom that suggests where the slow-down may be. In this example, the application ( com.example[...] ) is calling Thread.sleep which is causing the delay. Below the stack trace, Liberty prints a table showing any events leading up to the time the threshold was exceeded. In this case, the only event is the HTTP request itself which shows the servlet and its parameters. If the application performed other work such as database queries, these would be shown along with their SQLs. Using the browser Open the Terminal for the application pod in the OpenShift web console as you did in Step 2 above. Copy and paste the following command and press Enter : cat /logs/messages.log Scroll up until you find the TRAS0112W warning message signifying that an HTTP request exceeded the requestTiming configured threshold. For example: [11/1/22 20:02:12:053 UTC] 00000074 com.ibm.ws.request.timing.manager.SlowRequestManager W TRAS0112W: Request AAPj5+4YXW3_AAAAAAAAAB5 has been running on thread 00000071 for at least 9000.263ms. The following stack trace shows what this thread is currently running. at java.lang.Thread.sleepImpl(Native Method) at java.lang.Thread.sleep(Thread.java:977) at java.lang.Thread.sleep(Thread.java:960) at com.example.servlet.Sleep.doSleep(Sleep.java:79) at com.example.servlet.Sleep.doWork(Sleep.java:40) at com.example.util.BaseServlet.service(BaseServlet.java:104) at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:587) [...] The following table shows the events that have run during this request. Duration Operation 9001.583ms + websphere.servlet.service | libertydiag | com.example.servlet.Sleep?mean=5000&stddev=4000 The warning message notes how long the request had been running at the time of the warning ( 9000.263ms ) followed by a stack trace of what the thread was doing. The stack trace is the main symptom that suggests where the slow-down may be. In this example, the application ( com.example[...] ) is calling Thread.sleep which is causing the delay. Below the stack trace, Liberty prints a table showing any events leading up to the time the threshold was exceeded. In this case, the only event is the HTTP request itself which shows the servlet and its parameters. If the application performed other work such as database queries, these would be shown along with their SQLs. Step 5: Download Liberty logs In many cases, you may want the full logs for review on your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the Liberty messages.log by replacing $POD with a pod name from the previous command oc cp $POD:/logs/messages.log messages.log For example: oc cp libertydiag-ddf5f95b6-wj6dm:/logs/messages.log messages.log Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser. Summary In summary, this lab demonstrated how to configure Liberty's requestTiming to investigate HTTP requests that exceed a configured threshold. When this happens, Liberty prints a TRAS0112W warning to its logs with details about why the request may have been slow. When configuring requestTiming , it's advisable to use a monitoring tool to watch for this warning and send out alerts. The main drawback of requestTiming is that it has a non-constant overhead so it's generally advisable to performance test requestTiming in an environment with simulated load that mimics production to gauge the likely overhead before putting it into production, or increasing sampleRate to reduce the overhead. Lab: Gather a Liberty server dump through the WebSphere Liberty Operator This lab will show how to gather a Liberty server dump through the WebSphere Liberty Operator during a high response time issue. This lab will take approximately 10 minutes. Step 1: Install example application If you haven't already, install the sample application using the WebSphere Liberty operator. If you installed it in a previous lab, you may continue using the previous installation. If you previously installed the sample using a basic Kubernetes deployment, then uninstall it and re-install using the WebSphere Liberty operator. Step 2: Exercise long HTTP requests Now you will simulate HTTP requests to Liberty and some of them will be long. This will be done by executing 5 concurrent users that sleep a random amount of time with an average of 5 seconds and a standard deviation of 25 seconds. This means that approximately 68% of requests will be less than 30 seconds, and the remaining will be above 30 seconds, thus simulating long requests. Using the command line Request the following web page from your terminal to exercise long requests: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Request the following web page from your terminal to check on the status of the run: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/loadrunner.jsp\" | grep 'li>Run' Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/loadrunner.jsp\" | findstr 'li>Run' Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/Sleep?mean=5000&stddev=25000 Scroll to the bottom and click Start Step 2: Request a Liberty server dump You will gather a Liberty server dump using the WebSphere Liberty Operator dump custom resource . Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Create a dump.yaml file, replacing $POD with the name of the pod from the previous command (e.g. libertydiag-b98748954-mgj64 ): apiVersion: liberty.websphere.ibm.com/v1 kind: WebSphereLibertyDump metadata: name: libertydump1 annotations: day2operation.openliberty.io/targetKinds: Pod spec: license: accept: true podName: $POD include: - thread Apply the YAML: oc apply -f dump.yaml Using the browser Ensure the perspective is set to Developer in the top left: Set your current namespace/project to what you were provided. For example: In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then copy the name of the pod that's running: Click Operator Backed on the +Add page: Click WebSphereLibertyDump and then click Create Expand License and check accept Paste the pod name from the step above into the podName text box. Expand include and since we only want a thread dump, click Remove include for the second, Value=heap section Click Create Step 3: Wait for the server dump to complete Now that the server dump has been requested, you will check when the server dump has completed. Using the command line Use the wait command to wait for the dump to complete: oc wait wldump libertydump1 --for condition=completed --timeout=5m Example output: webspherelibertydump.liberty.websphere.ibm.com/libertydump1 condition met List WebSphereLibertyDump custom resources to get the final dump path: oc get wldump Example output: NAME STARTED COMPLETED DUMP FILE libertydump1 True True /serviceability/user15-namespace/libertydiag-b98748954-mgj64/2023-01-23_18:30:56.zip Using the browser Click on Search , click the Resources drop down, search for dump , check WebSphereLibertyDump , click on the resource name created earlier, and wait until there is a Completed=True line in the Conditions section at the bottom: Click on the YAML tab and scroll down to find the dumpFile location: Step 4: Download the server dump Download the server dump to your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the dump by replacing $POD with a pod name from above and $DUMP with the dump path from the previous step. oc cp $POD:$DUMP dump.zip For example: oc cp libertydiag-ddf5f95b6-wj6dm:/serviceability/user15-namespace/libertydiag-ddf5f95b6-wj6dm/2023-01-23_18:30:56.zip dump.zip Expand the zip file and you should find lots of diagnostics including a javacore*.txt file in the root of the zip which will show thread stacks at the time of the dump. This should include simulated high response time threads; for example: 3XMTHREADINFO \"Default Executor-thread-1421\" J9VMThread:0x00000000002BA800, omrthread_t:0x00007F8000006D50, java/lang/Thread:0x00000000FF943260, state:CW, prio=5 3XMJAVALTHREAD (java/lang/Thread getId:0x5D2, isDaemon:true) 3XMJAVALTHRCCL com/ibm/ws/classloading/internal/ThreadContextClassLoader(0x00000000E2169578) 3XMTHREADINFO1 (native thread ID:0x71C, native priority:0x5, native policy:UNKNOWN, vmstate:CW, vm thread flags:0x00000481) 3XMTHREADINFO2 (native stack address range from:0x00007F80424C1000, to:0x00007F8042501000, size:0x40000) 3XMCPUTIME CPU usage total: 0.015525339 secs, current category=\"Application\" 3XMHEAPALLOC Heap bytes allocated since last GC cycle=0 (0x0) 3XMTHREADINFO3 Java callstack: 4XESTACKTRACE at java/lang/Thread.sleepImpl(Native Method) 4XESTACKTRACE at java/lang/Thread.sleep(Thread.java:977) 4XESTACKTRACE at java/lang/Thread.sleep(Thread.java:960) 4XESTACKTRACE at com/example/servlet/Sleep.doSleep(Sleep.java:79) [...] Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Step 5: Clean-up Clean-up the server dump resource. Using the command line Delete the WebSphereLibertyDump custom resource: oc delete wldump libertydump1 Using the browser Click on Search , click the Resources drop down, search for dump , check WebSphereLibertyDump , click the vertical ellipses next to the custom resource created earlier, click Delete WebSphereLibertyDump , and click Delete . Summary In summary, this lab demonstrated how to gather a Liberty server dump for a WebSphere Liberty Operator-based application deployment during a simulated high response time issue. Lab: Use the performance/hang/high CPU MustGather on Linux on Containers This lab will use IBM Support's MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers to gather thread dumps showing any HTTP requests being processed. Any statistical patterns in thread stacks may be used to infer potential causes of high HTTP response times. This MustGather is publicly available and nearly the same as the standalone Linux performance/hang/high-CPU MustGather in that it gathers CPU, memory, disk, network information, thread dumps, etc., and customers should be encouraged to use it if they can accept that it requires cluster-admin permissions to execute. This lab will demonstrate how to execute the MustGather, download the diagnostics, and review them in the free IBM Thread and Monitor Dump Analyzer (TMDA) tool for potential causes of high HTTP response times. Note : This lab requires that the user has cluster-admin permissions. A future version of the MustGather will not require administrator permissions. This lab will take approximately 15 minutes. Step 0: Check if you have cluster-admin permissions These steps will show if you have cluster-admin permissions. If you do not, you must skip this lab. Using the command line Check if you have authority for all verbs on all resources: oc auth can-i '*' '*' Example output: yes If the answer is no , then you do not have cluster-admin permissions. Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Administrator in the top left: Expand User Management . If you don't see a Users option, then you do not have cluster-admin permissions. If you do see it, click on it, and then click on your user name: Click on RoleBindings and check if any binding has a Role ref of cluster-admin . If there are none, then you do not have cluster-admin permissions. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Exercise long HTTP requests Now you will simulate HTTP requests to Liberty and some of them will be long. This will be done by executing 5 concurrent users that sleep a random amount of time with an average of 5 seconds and a standard deviation of 25 seconds. This means that approximately 68% of requests will be less than 30 seconds, and the remaining will be above 30 seconds, thus simulating long requests. Using the command line Request the following web page from your terminal to exercise long requests: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D25000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D25000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Request the following web page from your terminal to check on the status of the run: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/loadrunner.jsp\" | grep 'li>Run' Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/loadrunner.jsp\" | findstr 'li>Run' Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/Sleep?mean=5000&stddev=25000 Scroll to the bottom and click Start Step 3: Execute the MustGather Now you will execute the MustGather. This takes approximately 6 minutes to run. Using the command line Download a helper script: macOS or Linux: containerdiag.sh Windows: containerdiag.bat Open a Terminal or Command Prompt and change directory to where you downloaded the script On macOS or Linux, make the script executable: chmod +x containerdiag.sh On macOS, remove the download quarantine: xattr -d com.apple.quarantine containerdiag.sh List the current deployments: oc get deployments Example output: NAME READY UP-TO-DATE AVAILABLE AGE libertydiag 1/1 1 1 13m Execute the MustGather. Normally, the -c option specifying the directory of the javacores is not needed; however, this sample application overrides the default javacore directory using -Xdump . This is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed. macOS or Linux: ./containerdiag.sh -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" Windows: containerdiag.bat -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" When the MustGather is complete, you will see a repeating message of the form: run.sh: Files are ready for download. Download with the following command in another window: oc cp [...] Open another Terminal or Command Prompt and copy & paste the oc cp line that you saw in the previous step. For example (your command will be different): $ oc cp worker4-debug:/tmp/containerdiag.SN9RbwVmfC.tar.gz containerdiag.SN9RbwVmfC.tar.gz --namespace=openshift-debug-node-g8dqbdfx5d tar: Removing leading `/' from member names Go back to the previous Terminal or Command Prompt , type ok , and press Enter to complete the MustGather: After the download is complete, type OK and press ENTER: ok [2022-11-08 19:01:03.670923238 UTC] run.sh: Processing finished. Deleting /tmp/containerdiag.SN9RbwVmfC.tar.gz [2022-11-08 19:01:03.674236286 UTC] run.sh: finished. Expand the containerdiag.*.tar.gz file that you downloaded. Using the browser The MustGather cannot be executed from the browser. You must use the command line steps above. Step 4: Analyze the thread dumps If you are familiar with analyzing thread dumps, you may skip this step. Using the TMDA tool Go to https://www.ibm.com/support/pages/ibm-thread-and-monitor-dump-analyzer-java-tmda Download the JAR file Double click to launch TMDA Click File } Open Thread Dumps Go to where you expanded containerdiag.*.tar.gz in the previous step } pods } libertydiag } containers } libertydiag } Multi-select all javacore .txt files and click Open Multi-select all the thread dumps and click the Compare Threads button Expand the left pane of threads. The default sort is by average stack depth for a thread which tends to correlate with activity. Each row is a thread and each column is a thread dump. Click on a cell to show a thread stack on the right. Explore the various stacks and look for patterns. You should notice two distinct patterns: Stacks in Thread.sleepImpl . These are the simulated long-running requests. at java/lang/Thread.sleepImpl(Native Method) at java/lang/Thread.sleep(Thread.java:977) at java/lang/Thread.sleep(Thread.java:960) at com/example/servlet/Sleep.doSleep(Sleep.java:79) [...] Stacks in SocketInputStream.socketRead0 . These are the load runner users. at java/net/SocketInputStream.socketRead0(Native Method) [...] at com/example/loadrunner/SimulatedUser.call(SimulatedUser.java:113) [...] With a sufficient number of thread dumps and a persistent pattern of stack tops, this may be used to hypothesize likely causes of slow HTTP requests. Summary In summary, this lab demonstrated how to execute the performance/hang/high CPU MustGather on Linux on Containers , download the diagnostics, and review them in the free IBM Thread and Monitor Dump Analyzer (TMDA) tool. With a sufficient number of thread dumps and a persistent pattern of stack tops during a time of slow HTTP requests, this data may be used to hypothesize likely causes of slow HTTP requests.","title":"High response times"},{"location":"lab_liberty_high_http_response_times/#lab-high-response-times","text":"This lab covers how to investigate high HTTP response times for a sample Liberty application in OpenShift.","title":"Lab: High Response Times"},{"location":"lab_liberty_high_http_response_times/#theory","text":"There are many ways to track and review HTTP response times for Liberty in an OpenShift environment: Review response times exceeding a configured threshold using Liberty's slow and hung request detection Manually gather thread dumps during the issue by opening a terminal in the container and executing kill -3 $PID If the application is installed using the WebSphere Liberty Operator, the WebSphereLibertyDump custom resource may be used to gather a Liberty server dump with a thread dump. This only works if the WebSphereLibertyApplication custom resource has the proper openliberty.io/day2operations annotation , and if the container has a /serviceability directory . If you have cluster-admin permissions, use the MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers during the issue and search for repeating patterns in thread dumps Review individual HTTP response times with Liberty's HTTP access logging , although this will not discover stack traces driving slow response times Review average and maximum response times with Eclipse MicroProfile Metrics in Liberty (or in an OpenShift Service ) integrated with Prometheus and Grafana in OpenShift or direct queries with a ServiceMonitor , although these techniques will not discover stack traces driving slow response times Review individual JAX-RS microservice response times with Eclipse MicroProfile OpenTelemetry (formerly OpenTracing) with Jaeger or Zipkin, although this will not discover stack traces driving slow response times Use third-party monitoring products such as Instana This lab will only cover some of the above methods.","title":"Theory"},{"location":"lab_liberty_high_http_response_times/#labs","text":"Choose one or more labs: Lab: Response times exceeding a configured threshold Lab: Gather a Liberty server dump through the WebSphere Liberty Operator Lab: Use the performance/hang/high CPU MustGather on Linux on Containers You could also gather thread dumps using kill -3 as done in the High CPU lab .","title":"Labs"},{"location":"lab_liberty_high_http_response_times/#lab-response-times-exceeding-a-configured-threshold","text":"This lab will use Liberty's slow and hung request detection to print information about HTTP requests that exceed a configured threshold to logs. This method is generally used when there are intermittent HTTP response time spikes. For example, if the average response time is 5 seconds but users are experiencing intermittent response time spikes of 10 seconds that are unacceptable, then the threshold may be set to 9 seconds to investigate the spikes. This lab will demonstrate how to configure Liberty's requestTiming feature , trigger it with an example application, and review the output. The major downside to this approach is that the performance overhead of requestTiming is non-constant. The overhead is proportional to the volume and complexity of requests which should be determined in a performance test environment before configuring requestTiming in production. The main way to reduce the performance overhead is to increase the sampleRate although any value greater than 1 creates a chance of missing some slow requests. In this lab, you will be using the slowRequestThreshold to trigger the details to the log. There is also a hungRequestThreshold that may be configured although it won't be covered in this lab. When hungRequestThreshold is breached, in addition to the same log message as with slowRequestThreshold , Liberty will take 3 thread dumps, one minute apart. This lab will take approximately 10 minutes.","title":"Lab: Response times exceeding a configured threshold"},{"location":"lab_liberty_high_http_response_times/#step-1-install-example-application","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_high_http_response_times/#step-2-configure-requesttiming","text":"Now that the application is installed and running, you will configure requestTiming to trigger if an HTTP request takes longer than 9 seconds. You will be modifying a running pod. In some real-world cases, this may be infeasible and the image will need to be re-built and re-deployed with the updated configuration. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter . Liberty will dynamically update the requestTiming configuration in the server (assuming the feature is installed, which it usually is). echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><featureManager><feature>requestTiming-1.0</feature></featureManager><requestTiming slowRequestThreshold=\"9s\" hungRequestThreshold=\"300s\" sampleRate=\"1\" /></server>' > /config/configDropins/overrides/requestTiming.xml Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on the one pod that's running: Click on the Terminal tab to open a remote shell into the running container in the pod: Copy and paste the following command and press Enter . Liberty will dynamically update the requestTiming configuration in the server (assuming the feature is installed, which it usually is). echo '<?xml version=\"1.0\" encoding=\"UTF-8\"?><server><featureManager><feature>requestTiming-1.0</feature></featureManager><requestTiming slowRequestThreshold=\"9s\" hungRequestThreshold=\"300s\" sampleRate=\"1\" /></server>' > /config/configDropins/overrides/requestTiming.xml","title":"Step 2: Configure requestTiming"},{"location":"lab_liberty_high_http_response_times/#step-3-exercise-long-http-requests","text":"Now that requestTiming is configured, you will simulate HTTP requests to Liberty and some of them will exceed 9 seconds. This will be done by executing 5 concurrent users that sleep a random amount of time with an average of 5 seconds and a standard deviation of 4 seconds. This means that approximately 68% of requests will be between 1-9 seconds, and the remaining will be either below 1 seconds or above 9 seconds, thus simulating a situation where most requests are fine but a minority exceed the defined threshold. Using the command line Request the following web page from your terminal to exercise long requests: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Request the following web page from your terminal to check on the status of the run: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/loadrunner.jsp\" | grep 'li>Run' Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/loadrunner.jsp\" | findstr 'li>Run' Keep executing the above command until you see that the max execution value exceeds 9000 . This means at least one request took more than 9 seconds. (In the statistically rare chance that this doesn't happen, start again at step 1). Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/Sleep?mean=5000&stddev=4000 Scroll to the bottom and click Start You may refresh this page to check on the status of the run. Note that refreshing does not start a new run. Keep refreshing until you see that the max execution value exceeds 9000 . This means at least one request took more than 9 seconds. (In the statistically rare chance that this doesn't happen, Start the load again.)","title":"Step 3: Exercise long HTTP requests"},{"location":"lab_liberty_high_http_response_times/#step-4-review-data-on-long-http-requests","text":"Now you will review the logs to understand how to investigate slow HTTP requests. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Copy and paste the following command and press Enter : cat /logs/messages.log Scroll up until you find the TRAS0112W warning message signifying that an HTTP request exceeded the requestTiming configured threshold. For example: [11/1/22 20:02:12:053 UTC] 00000074 com.ibm.ws.request.timing.manager.SlowRequestManager W TRAS0112W: Request AAPj5+4YXW3_AAAAAAAAAB5 has been running on thread 00000071 for at least 9000.263ms. The following stack trace shows what this thread is currently running. at java.lang.Thread.sleepImpl(Native Method) at java.lang.Thread.sleep(Thread.java:977) at java.lang.Thread.sleep(Thread.java:960) at com.example.servlet.Sleep.doSleep(Sleep.java:79) at com.example.servlet.Sleep.doWork(Sleep.java:40) at com.example.util.BaseServlet.service(BaseServlet.java:104) at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:587) [...] The following table shows the events that have run during this request. Duration Operation 9001.583ms + websphere.servlet.service | libertydiag | com.example.servlet.Sleep?mean=5000&stddev=4000 The warning message notes how long the request had been running at the time of the warning ( 9000.263ms ) followed by a stack trace of what the thread was doing. The stack trace is the main symptom that suggests where the slow-down may be. In this example, the application ( com.example[...] ) is calling Thread.sleep which is causing the delay. Below the stack trace, Liberty prints a table showing any events leading up to the time the threshold was exceeded. In this case, the only event is the HTTP request itself which shows the servlet and its parameters. If the application performed other work such as database queries, these would be shown along with their SQLs. Using the browser Open the Terminal for the application pod in the OpenShift web console as you did in Step 2 above. Copy and paste the following command and press Enter : cat /logs/messages.log Scroll up until you find the TRAS0112W warning message signifying that an HTTP request exceeded the requestTiming configured threshold. For example: [11/1/22 20:02:12:053 UTC] 00000074 com.ibm.ws.request.timing.manager.SlowRequestManager W TRAS0112W: Request AAPj5+4YXW3_AAAAAAAAAB5 has been running on thread 00000071 for at least 9000.263ms. The following stack trace shows what this thread is currently running. at java.lang.Thread.sleepImpl(Native Method) at java.lang.Thread.sleep(Thread.java:977) at java.lang.Thread.sleep(Thread.java:960) at com.example.servlet.Sleep.doSleep(Sleep.java:79) at com.example.servlet.Sleep.doWork(Sleep.java:40) at com.example.util.BaseServlet.service(BaseServlet.java:104) at jakarta.servlet.http.HttpServlet.service(HttpServlet.java:587) [...] The following table shows the events that have run during this request. Duration Operation 9001.583ms + websphere.servlet.service | libertydiag | com.example.servlet.Sleep?mean=5000&stddev=4000 The warning message notes how long the request had been running at the time of the warning ( 9000.263ms ) followed by a stack trace of what the thread was doing. The stack trace is the main symptom that suggests where the slow-down may be. In this example, the application ( com.example[...] ) is calling Thread.sleep which is causing the delay. Below the stack trace, Liberty prints a table showing any events leading up to the time the threshold was exceeded. In this case, the only event is the HTTP request itself which shows the servlet and its parameters. If the application performed other work such as database queries, these would be shown along with their SQLs.","title":"Step 4: Review data on long HTTP requests"},{"location":"lab_liberty_high_http_response_times/#step-5-download-liberty-logs","text":"In many cases, you may want the full logs for review on your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the Liberty messages.log by replacing $POD with a pod name from the previous command oc cp $POD:/logs/messages.log messages.log For example: oc cp libertydiag-ddf5f95b6-wj6dm:/logs/messages.log messages.log Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Alternatively, you may use the Terminal tab of the pod and cat the file in the browser.","title":"Step 5: Download Liberty logs"},{"location":"lab_liberty_high_http_response_times/#summary","text":"In summary, this lab demonstrated how to configure Liberty's requestTiming to investigate HTTP requests that exceed a configured threshold. When this happens, Liberty prints a TRAS0112W warning to its logs with details about why the request may have been slow. When configuring requestTiming , it's advisable to use a monitoring tool to watch for this warning and send out alerts. The main drawback of requestTiming is that it has a non-constant overhead so it's generally advisable to performance test requestTiming in an environment with simulated load that mimics production to gauge the likely overhead before putting it into production, or increasing sampleRate to reduce the overhead.","title":"Summary"},{"location":"lab_liberty_high_http_response_times/#lab-gather-a-liberty-server-dump-through-the-websphere-liberty-operator","text":"This lab will show how to gather a Liberty server dump through the WebSphere Liberty Operator during a high response time issue. This lab will take approximately 10 minutes.","title":"Lab: Gather a Liberty server dump through the WebSphere Liberty Operator"},{"location":"lab_liberty_high_http_response_times/#step-1-install-example-application_1","text":"If you haven't already, install the sample application using the WebSphere Liberty operator. If you installed it in a previous lab, you may continue using the previous installation. If you previously installed the sample using a basic Kubernetes deployment, then uninstall it and re-install using the WebSphere Liberty operator.","title":"Step 1: Install example application"},{"location":"lab_liberty_high_http_response_times/#step-2-exercise-long-http-requests","text":"Now you will simulate HTTP requests to Liberty and some of them will be long. This will be done by executing 5 concurrent users that sleep a random amount of time with an average of 5 seconds and a standard deviation of 25 seconds. This means that approximately 68% of requests will be less than 30 seconds, and the remaining will be above 30 seconds, thus simulating long requests. Using the command line Request the following web page from your terminal to exercise long requests: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D4000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Request the following web page from your terminal to check on the status of the run: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/loadrunner.jsp\" | grep 'li>Run' Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/loadrunner.jsp\" | findstr 'li>Run' Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/Sleep?mean=5000&stddev=25000 Scroll to the bottom and click Start","title":"Step 2: Exercise long HTTP requests"},{"location":"lab_liberty_high_http_response_times/#step-2-request-a-liberty-server-dump","text":"You will gather a Liberty server dump using the WebSphere Liberty Operator dump custom resource . Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Create a dump.yaml file, replacing $POD with the name of the pod from the previous command (e.g. libertydiag-b98748954-mgj64 ): apiVersion: liberty.websphere.ibm.com/v1 kind: WebSphereLibertyDump metadata: name: libertydump1 annotations: day2operation.openliberty.io/targetKinds: Pod spec: license: accept: true podName: $POD include: - thread Apply the YAML: oc apply -f dump.yaml Using the browser Ensure the perspective is set to Developer in the top left: Set your current namespace/project to what you were provided. For example: In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then copy the name of the pod that's running: Click Operator Backed on the +Add page: Click WebSphereLibertyDump and then click Create Expand License and check accept Paste the pod name from the step above into the podName text box. Expand include and since we only want a thread dump, click Remove include for the second, Value=heap section Click Create","title":"Step 2: Request a Liberty server dump"},{"location":"lab_liberty_high_http_response_times/#step-3-wait-for-the-server-dump-to-complete","text":"Now that the server dump has been requested, you will check when the server dump has completed. Using the command line Use the wait command to wait for the dump to complete: oc wait wldump libertydump1 --for condition=completed --timeout=5m Example output: webspherelibertydump.liberty.websphere.ibm.com/libertydump1 condition met List WebSphereLibertyDump custom resources to get the final dump path: oc get wldump Example output: NAME STARTED COMPLETED DUMP FILE libertydump1 True True /serviceability/user15-namespace/libertydiag-b98748954-mgj64/2023-01-23_18:30:56.zip Using the browser Click on Search , click the Resources drop down, search for dump , check WebSphereLibertyDump , click on the resource name created earlier, and wait until there is a Completed=True line in the Conditions section at the bottom: Click on the YAML tab and scroll down to find the dumpFile location:","title":"Step 3: Wait for the server dump to complete"},{"location":"lab_liberty_high_http_response_times/#step-4-download-the-server-dump","text":"Download the server dump to your workstation. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-ddf5f95b6-wj6dm 1/1 Running 0 97s Download the dump by replacing $POD with a pod name from above and $DUMP with the dump path from the previous step. oc cp $POD:$DUMP dump.zip For example: oc cp libertydiag-ddf5f95b6-wj6dm:/serviceability/user15-namespace/libertydiag-ddf5f95b6-wj6dm/2023-01-23_18:30:56.zip dump.zip Expand the zip file and you should find lots of diagnostics including a javacore*.txt file in the root of the zip which will show thread stacks at the time of the dump. This should include simulated high response time threads; for example: 3XMTHREADINFO \"Default Executor-thread-1421\" J9VMThread:0x00000000002BA800, omrthread_t:0x00007F8000006D50, java/lang/Thread:0x00000000FF943260, state:CW, prio=5 3XMJAVALTHREAD (java/lang/Thread getId:0x5D2, isDaemon:true) 3XMJAVALTHRCCL com/ibm/ws/classloading/internal/ThreadContextClassLoader(0x00000000E2169578) 3XMTHREADINFO1 (native thread ID:0x71C, native priority:0x5, native policy:UNKNOWN, vmstate:CW, vm thread flags:0x00000481) 3XMTHREADINFO2 (native stack address range from:0x00007F80424C1000, to:0x00007F8042501000, size:0x40000) 3XMCPUTIME CPU usage total: 0.015525339 secs, current category=\"Application\" 3XMHEAPALLOC Heap bytes allocated since last GC cycle=0 (0x0) 3XMTHREADINFO3 Java callstack: 4XESTACKTRACE at java/lang/Thread.sleepImpl(Native Method) 4XESTACKTRACE at java/lang/Thread.sleep(Thread.java:977) 4XESTACKTRACE at java/lang/Thread.sleep(Thread.java:960) 4XESTACKTRACE at com/example/servlet/Sleep.doSleep(Sleep.java:79) [...] Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above.","title":"Step 4: Download the server dump"},{"location":"lab_liberty_high_http_response_times/#step-5-clean-up","text":"Clean-up the server dump resource. Using the command line Delete the WebSphereLibertyDump custom resource: oc delete wldump libertydump1 Using the browser Click on Search , click the Resources drop down, search for dump , check WebSphereLibertyDump , click the vertical ellipses next to the custom resource created earlier, click Delete WebSphereLibertyDump , and click Delete .","title":"Step 5: Clean-up"},{"location":"lab_liberty_high_http_response_times/#summary_1","text":"In summary, this lab demonstrated how to gather a Liberty server dump for a WebSphere Liberty Operator-based application deployment during a simulated high response time issue.","title":"Summary"},{"location":"lab_liberty_high_http_response_times/#lab-use-the-performancehanghigh-cpu-mustgather-on-linux-on-containers","text":"This lab will use IBM Support's MustGather: Performance, hang, or high CPU issues with WebSphere Application Server on Linux on Containers to gather thread dumps showing any HTTP requests being processed. Any statistical patterns in thread stacks may be used to infer potential causes of high HTTP response times. This MustGather is publicly available and nearly the same as the standalone Linux performance/hang/high-CPU MustGather in that it gathers CPU, memory, disk, network information, thread dumps, etc., and customers should be encouraged to use it if they can accept that it requires cluster-admin permissions to execute. This lab will demonstrate how to execute the MustGather, download the diagnostics, and review them in the free IBM Thread and Monitor Dump Analyzer (TMDA) tool for potential causes of high HTTP response times. Note : This lab requires that the user has cluster-admin permissions. A future version of the MustGather will not require administrator permissions. This lab will take approximately 15 minutes.","title":"Lab: Use the performance/hang/high CPU MustGather on Linux on Containers"},{"location":"lab_liberty_high_http_response_times/#step-0-check-if-you-have-cluster-admin-permissions","text":"These steps will show if you have cluster-admin permissions. If you do not, you must skip this lab. Using the command line Check if you have authority for all verbs on all resources: oc auth can-i '*' '*' Example output: yes If the answer is no , then you do not have cluster-admin permissions. Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Administrator in the top left: Expand User Management . If you don't see a Users option, then you do not have cluster-admin permissions. If you do see it, click on it, and then click on your user name: Click on RoleBindings and check if any binding has a Role ref of cluster-admin . If there are none, then you do not have cluster-admin permissions.","title":"Step 0: Check if you have cluster-admin permissions"},{"location":"lab_liberty_high_http_response_times/#step-1-install-example-application_2","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_high_http_response_times/#step-2-exercise-long-http-requests_1","text":"Now you will simulate HTTP requests to Liberty and some of them will be long. This will be done by executing 5 concurrent users that sleep a random amount of time with an average of 5 seconds and a standard deviation of 25 seconds. This means that approximately 68% of requests will be less than 30 seconds, and the remaining will be above 30 seconds, thus simulating long requests. Using the command line Request the following web page from your terminal to exercise long requests: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D25000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/LoadRunner?url=http%3A%2F%2Flocalhost%3A9080%2Fservlet%2FSleep%3Fmean%3D5000%26stddev%3D25000&method=get&entity=&concurrentusers=5&totalrequests=100&user=&password=\" Request the following web page from your terminal to check on the status of the run: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/loadrunner.jsp\" | grep 'li>Run' Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/loadrunner.jsp\" | findstr 'li>Run' Using the browser Click on the Load Runner link from the libertydiag application homepage: In the Target URL , copy and paste the following: http://localhost:9080/servlet/Sleep?mean=5000&stddev=25000 Scroll to the bottom and click Start","title":"Step 2: Exercise long HTTP requests"},{"location":"lab_liberty_high_http_response_times/#step-3-execute-the-mustgather","text":"Now you will execute the MustGather. This takes approximately 6 minutes to run. Using the command line Download a helper script: macOS or Linux: containerdiag.sh Windows: containerdiag.bat Open a Terminal or Command Prompt and change directory to where you downloaded the script On macOS or Linux, make the script executable: chmod +x containerdiag.sh On macOS, remove the download quarantine: xattr -d com.apple.quarantine containerdiag.sh List the current deployments: oc get deployments Example output: NAME READY UP-TO-DATE AVAILABLE AGE libertydiag 1/1 1 1 13m Execute the MustGather. Normally, the -c option specifying the directory of the javacores is not needed; however, this sample application overrides the default javacore directory using -Xdump . This is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed. macOS or Linux: ./containerdiag.sh -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" Windows: containerdiag.bat -d libertydiag libertyperf.sh -c \"/opt/ol/wlp/output/defaultServer/logs/diagnostics/javacore*\" When the MustGather is complete, you will see a repeating message of the form: run.sh: Files are ready for download. Download with the following command in another window: oc cp [...] Open another Terminal or Command Prompt and copy & paste the oc cp line that you saw in the previous step. For example (your command will be different): $ oc cp worker4-debug:/tmp/containerdiag.SN9RbwVmfC.tar.gz containerdiag.SN9RbwVmfC.tar.gz --namespace=openshift-debug-node-g8dqbdfx5d tar: Removing leading `/' from member names Go back to the previous Terminal or Command Prompt , type ok , and press Enter to complete the MustGather: After the download is complete, type OK and press ENTER: ok [2022-11-08 19:01:03.670923238 UTC] run.sh: Processing finished. Deleting /tmp/containerdiag.SN9RbwVmfC.tar.gz [2022-11-08 19:01:03.674236286 UTC] run.sh: finished. Expand the containerdiag.*.tar.gz file that you downloaded. Using the browser The MustGather cannot be executed from the browser. You must use the command line steps above.","title":"Step 3: Execute the MustGather"},{"location":"lab_liberty_high_http_response_times/#step-4-analyze-the-thread-dumps","text":"If you are familiar with analyzing thread dumps, you may skip this step. Using the TMDA tool Go to https://www.ibm.com/support/pages/ibm-thread-and-monitor-dump-analyzer-java-tmda Download the JAR file Double click to launch TMDA Click File } Open Thread Dumps Go to where you expanded containerdiag.*.tar.gz in the previous step } pods } libertydiag } containers } libertydiag } Multi-select all javacore .txt files and click Open Multi-select all the thread dumps and click the Compare Threads button Expand the left pane of threads. The default sort is by average stack depth for a thread which tends to correlate with activity. Each row is a thread and each column is a thread dump. Click on a cell to show a thread stack on the right. Explore the various stacks and look for patterns. You should notice two distinct patterns: Stacks in Thread.sleepImpl . These are the simulated long-running requests. at java/lang/Thread.sleepImpl(Native Method) at java/lang/Thread.sleep(Thread.java:977) at java/lang/Thread.sleep(Thread.java:960) at com/example/servlet/Sleep.doSleep(Sleep.java:79) [...] Stacks in SocketInputStream.socketRead0 . These are the load runner users. at java/net/SocketInputStream.socketRead0(Native Method) [...] at com/example/loadrunner/SimulatedUser.call(SimulatedUser.java:113) [...] With a sufficient number of thread dumps and a persistent pattern of stack tops, this may be used to hypothesize likely causes of slow HTTP requests.","title":"Step 4: Analyze the thread dumps"},{"location":"lab_liberty_high_http_response_times/#summary_2","text":"In summary, this lab demonstrated how to execute the performance/hang/high CPU MustGather on Linux on Containers , download the diagnostics, and review them in the free IBM Thread and Monitor Dump Analyzer (TMDA) tool. With a sufficient number of thread dumps and a persistent pattern of stack tops during a time of slow HTTP requests, this data may be used to hypothesize likely causes of slow HTTP requests.","title":"Summary"},{"location":"lab_liberty_install_app/","text":"Install Sample WebSphere Liberty Application You will install an example application called libertydiag . Note that this link is just for reference as the application image will be pulled by OpenShift. Choose to perform the installation either using the WebSphere Liberty Operator or a basic Kubernetes Deployment. If you're not sure, use the WebSphere Liberty Operator. The WebSphere Liberty Operator is essentially a wrapper around a basic Kubernetes Deployment with various additional features and conveniences . Some of the labs require the use of the WebSphere Liberty Operator, so if you choose a basic Kubernetes Deployment, you will need to uninstall and recreate a WebSphere Liberty Operator deployment for those labs or skip them. We encourage you to test both the WebSphere Liberty Operator and basic Kubernetes Deployments as both are commonly used in the field. Choose to use either the command line or the browser. In general, we suggest using the command line. Knowing how to do the same in the browser is optional. You may use the same installation for all of the WebSphere Liberty labs, except where otherwise indicated at the beginning of a lab; however, if you decide to do so, some of the labs end with pods in a bad state and you will need to destroy them which will be mentioned in the cleanup steps of such labs. If you previously installed this application and you would like to try a different method, then first uninstall the sample application . Install using the WebSphere Liberty Operator Using the command line If you haven't already, download the oc executable and log into your OpenShift console through the command line If you have been provided a namespace that you should use, then set your current namespace/project by replacing $NAMESPACE in the following command: oc config set-context --current --namespace $NAMESPACE Create a file in your current directory named libertydiag.yaml and paste the following contents: apiVersion: liberty.websphere.ibm.com/v1 kind: WebSphereLibertyApplication metadata: name: libertydiag annotations: openliberty.io/day2operations: WebSphereLibertyTrace,WebSphereLibertyDump spec: license: accept: true edition: IBM WebSphere Application Server metric: Virtual Processor Core (VPC) productEntitlementSource: Standalone applicationImage: quay.io/ibm/libertydiag probes: readiness: initialDelaySeconds: 1 failureThreshold: 1 manageTLS: true expose: true pullPolicy: Always Deploy the YAML: oc apply -f libertydiag.yaml Run the following command which will wait until the deployment is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: oc wait deployment libertydiag --for condition=available --timeout=5m List the route's URL: oc get route libertydiag \"--output=jsonpath={'https://'}{.spec.host}{'/\\n'}\" Open the URL in your browser and accept the certificate warning You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Developer in the top left: If you have been provided a namespace that you should use, then set your current namespace/project to what you were provided. For example: Click Operator Backed on the +Add page: Click WebSphereLibertyApplication : Click Create : Scroll to the top and set the fields: Name = libertydiag Application Image = quay.io/ibm/libertydiag Click on License and check accept Change the Expose toggle to enabled Expand Probes and click on Readiness Probe : Set initialDelaySeconds to 1 and set failureThreshold to 1 : Scroll to the bottom and click Create You will be taken back to the Topology view and you'll see the new application. While the application is initializing, there will be a light blue circle around it: Wait until the circle turns into a dark blue, signifying the application is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: Click the Open URL button on the resulting Topology view to open the application (and accept the certificate warning) You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab Install using a basic Kubernetes Deployment Using the command line If you haven't already, download the oc executable and log into your OpenShift console through the command line If you have been provided a namespace that you should use, then set your current namespace/project by replacing $NAMESPACE in the following command with the namespace/project you were provided: oc config set-context --current --namespace $NAMESPACE Create a file name libertydiag.yaml in the same directory where you are running the oc commands: apiVersion: apps/v1 kind: Deployment metadata: name: libertydiag labels: app: libertydiag spec: selector: matchLabels: app: libertydiag template: metadata: labels: app: libertydiag spec: containers: - name: libertydiag image: quay.io/ibm/libertydiag imagePullPolicy: Always readinessProbe: httpGet: path: /health/ready port: 9080 scheme: HTTP initialDelaySeconds: 1 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 1 Create the deployment (a warning about would violate PodSecurity is expected in development clusters): oc apply -f libertydiag.yaml Run the following command which will wait until the deployment is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: oc wait deployment libertydiag --for condition=available --timeout=5m Create a service for the application to create a load balancer to the deployment: oc expose deployment libertydiag --port=80 --target-port=9080 Create a route for the application to expose the service externally: oc create route edge --service=libertydiag List the route's URL: oc get route libertydiag \"--output=jsonpath={'https://'}{.spec.host}{'/\\n'}\" Open the URL in your browser and accept the certificate warning You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Developer in the top left: If you have been provided a namespace that you should use, then set your current namespace/project to what you were provided. For example: Click Container Images on the +Add page: Set Image name from external registry to quay.io/ibm/libertydiag Scroll down to the bottom and click on Health checks : Click on Add Readiness probe : Fill in the following information (in particular, Path = /health/ready and Port = 9080 ) and click the small checkbox in the bottom right: You should see Readiness probe added . Click on the Create button: You will be taken back to the Topology view and you'll see the new application. While the application is initializing, there will be a light blue circle around it: Wait until the circle turns into a dark blue, signifying the application is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: Click the Open URL button to open the application (and accept the certificate warning): You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab Learn More WebSphere Liberty Operator Basic Kubernetes Deployments","title":"Install Sample Liberty Application"},{"location":"lab_liberty_install_app/#install-sample-websphere-liberty-application","text":"You will install an example application called libertydiag . Note that this link is just for reference as the application image will be pulled by OpenShift. Choose to perform the installation either using the WebSphere Liberty Operator or a basic Kubernetes Deployment. If you're not sure, use the WebSphere Liberty Operator. The WebSphere Liberty Operator is essentially a wrapper around a basic Kubernetes Deployment with various additional features and conveniences . Some of the labs require the use of the WebSphere Liberty Operator, so if you choose a basic Kubernetes Deployment, you will need to uninstall and recreate a WebSphere Liberty Operator deployment for those labs or skip them. We encourage you to test both the WebSphere Liberty Operator and basic Kubernetes Deployments as both are commonly used in the field. Choose to use either the command line or the browser. In general, we suggest using the command line. Knowing how to do the same in the browser is optional. You may use the same installation for all of the WebSphere Liberty labs, except where otherwise indicated at the beginning of a lab; however, if you decide to do so, some of the labs end with pods in a bad state and you will need to destroy them which will be mentioned in the cleanup steps of such labs. If you previously installed this application and you would like to try a different method, then first uninstall the sample application .","title":"Install Sample WebSphere Liberty Application"},{"location":"lab_liberty_install_app/#install-using-the-websphere-liberty-operator","text":"Using the command line If you haven't already, download the oc executable and log into your OpenShift console through the command line If you have been provided a namespace that you should use, then set your current namespace/project by replacing $NAMESPACE in the following command: oc config set-context --current --namespace $NAMESPACE Create a file in your current directory named libertydiag.yaml and paste the following contents: apiVersion: liberty.websphere.ibm.com/v1 kind: WebSphereLibertyApplication metadata: name: libertydiag annotations: openliberty.io/day2operations: WebSphereLibertyTrace,WebSphereLibertyDump spec: license: accept: true edition: IBM WebSphere Application Server metric: Virtual Processor Core (VPC) productEntitlementSource: Standalone applicationImage: quay.io/ibm/libertydiag probes: readiness: initialDelaySeconds: 1 failureThreshold: 1 manageTLS: true expose: true pullPolicy: Always Deploy the YAML: oc apply -f libertydiag.yaml Run the following command which will wait until the deployment is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: oc wait deployment libertydiag --for condition=available --timeout=5m List the route's URL: oc get route libertydiag \"--output=jsonpath={'https://'}{.spec.host}{'/\\n'}\" Open the URL in your browser and accept the certificate warning You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Developer in the top left: If you have been provided a namespace that you should use, then set your current namespace/project to what you were provided. For example: Click Operator Backed on the +Add page: Click WebSphereLibertyApplication : Click Create : Scroll to the top and set the fields: Name = libertydiag Application Image = quay.io/ibm/libertydiag Click on License and check accept Change the Expose toggle to enabled Expand Probes and click on Readiness Probe : Set initialDelaySeconds to 1 and set failureThreshold to 1 : Scroll to the bottom and click Create You will be taken back to the Topology view and you'll see the new application. While the application is initializing, there will be a light blue circle around it: Wait until the circle turns into a dark blue, signifying the application is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: Click the Open URL button on the resulting Topology view to open the application (and accept the certificate warning) You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab","title":"Install using the WebSphere Liberty Operator"},{"location":"lab_liberty_install_app/#install-using-a-basic-kubernetes-deployment","text":"Using the command line If you haven't already, download the oc executable and log into your OpenShift console through the command line If you have been provided a namespace that you should use, then set your current namespace/project by replacing $NAMESPACE in the following command with the namespace/project you were provided: oc config set-context --current --namespace $NAMESPACE Create a file name libertydiag.yaml in the same directory where you are running the oc commands: apiVersion: apps/v1 kind: Deployment metadata: name: libertydiag labels: app: libertydiag spec: selector: matchLabels: app: libertydiag template: metadata: labels: app: libertydiag spec: containers: - name: libertydiag image: quay.io/ibm/libertydiag imagePullPolicy: Always readinessProbe: httpGet: path: /health/ready port: 9080 scheme: HTTP initialDelaySeconds: 1 periodSeconds: 10 timeoutSeconds: 3 failureThreshold: 1 Create the deployment (a warning about would violate PodSecurity is expected in development clusters): oc apply -f libertydiag.yaml Run the following command which will wait until the deployment is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: oc wait deployment libertydiag --for condition=available --timeout=5m Create a service for the application to create a load balancer to the deployment: oc expose deployment libertydiag --port=80 --target-port=9080 Create a route for the application to expose the service externally: oc create route edge --service=libertydiag List the route's URL: oc get route libertydiag \"--output=jsonpath={'https://'}{.spec.host}{'/\\n'}\" Open the URL in your browser and accept the certificate warning You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Developer in the top left: If you have been provided a namespace that you should use, then set your current namespace/project to what you were provided. For example: Click Container Images on the +Add page: Set Image name from external registry to quay.io/ibm/libertydiag Scroll down to the bottom and click on Health checks : Click on Add Readiness probe : Fill in the following information (in particular, Path = /health/ready and Port = 9080 ) and click the small checkbox in the bottom right: You should see Readiness probe added . Click on the Create button: You will be taken back to the Topology view and you'll see the new application. While the application is initializing, there will be a light blue circle around it: Wait until the circle turns into a dark blue, signifying the application is ready. This may take up to 2 minutes or more depending on available cluster resources and namespace limits: Click the Open URL button to open the application (and accept the certificate warning): You should see the libertydiag application home page: Go back to the previous page in the lab and continue to the next step of the lab","title":"Install using a basic Kubernetes Deployment"},{"location":"lab_liberty_install_app/#learn-more","text":"WebSphere Liberty Operator Basic Kubernetes Deployments","title":"Learn More"},{"location":"lab_liberty_instanton/","text":"Lab: InstantOn This lab covers how to run a Liberty InstantOn container and investigate issues with InstantOn. Theory Liberty InstantOn is a capability of Liberty (along with technology in IBM Semeru Java and Linux) to dramatically reduce Liberty start-up time by up to 10-20 times . In the example you'll see below, startup time goes from 30-60 seconds to less than 1 second. The technology is currently in beta. InstantOn is useful for serverless applications (where Liberty is spawned to handle a single unit of work and then destroyed) but it's also useful for traditional, long-running application scenarios. For example, Kubernetes deployments can be configured to auto-scale based on workload, both down to 0 pods during periods of inactivity (e.g. at night when there may be no users) as well as increasing the number of pods during unexpected spikes of activity. In both of these cases, when a new pod is created, startup time and various caches may affect the requests during the period when new pods are being created and initialized. With InstantOn, start up time can be nearly instantaneous and thus solve those issues with cold starts. The way InstantOn generally works in a cloud environment is that the application developer builds the application container, starts the container, and then takes a checkpoint, most often after applications have finished starting, and this checkpoint is saved into a container image. This checkpoint represents all of the memory and state of Liberty in its ready-to-serve state. Then, when a pod is started based off of this image, Liberty works with IBM Semeru Java and Linux to restore this checkpoint and prepare it for serving requests. The most common issue with InstantOn is that a security misconfiguration causes the checkpoint restore to fail. In this case, Liberty falls back to a normal, slow start-up. Therefore, you'll go through two labs. First, we'll show InstantOn in action with everything succeeding, and then we'll show InstantOn failing the checkpoint restore and how to review the logs for what went wrong. InstantOn in OpenShift has two different ways of running: fully privileged mode (i.e. essentially \"root\" mode) and non-fully privileged but increased privilege mode. For obvious reasons, it's generally more recommended to run in the latter mode because giving a container root privileges means that security risks are higher. However, running in this lower privileges mode requires either a Linux kernel that supports the clone3 system call with the set_tid argument, or runc version 1.1.3 or higher. Such environments are not yet often available, so this first version of these labs will run in fully privileged mode. Labs Lab: InstantOn successfully working in privileged mode Lab: InstantOn failing Lab: InstantOn successfully working in privileged mode Step 1: Create a ServiceAccount We will run the pod under the authority of a ServiceAccount to which we will associate elevated privileges. Using the command line If you haven't already, download the oc executable and log into your OpenShift console through the command line Create the service account: oc create serviceaccount privilegedserviceaccount Associate the service account with the privileged security context constraint (SCC): oc adm policy add-scc-to-user privileged -z privilegedserviceaccount Step 2: Install example application Uninstall any previously installed sample application. Re-install the sample application using a basic Kubernetes Deployment . Step 3: Test InstantOn First you will see how long it took to start a non-InstantOn application. Then you will delete that and install an InstantOn application for comparison. Using the command line List the pods; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Execute a remote search in the pod for the CWWKZ0001I: Application libertydiag started message by replacing $POD with a pod name from the previous command: oc exec $POD -- grep CWWKZ0001I /logs/messages.log For example: $ oc exec libertydiag-59d59c5dbc-sghwt -- grep CWWKZ0001I /logs/messages.log [12/12/22, 20:00:55:275 UTC] 0000002e com.ibm.ws.app.manager.AppMessageHelper A CWWKZ0001I: Application libertydiag started in 39.409 seconds. Notice that the application took many dozens of seconds to start. In the above example, it took about 40 seconds. Next, we'll delete this deployment and create an InstantOn deployment. Delete the current deployment. oc delete deployment libertydiag Wait about 5 seconds for the deployment to finish deleting. Confirm it's not in the resulting list of all deployments: oc get deployments Example output: No resources found in user1-namespace namespace. Create a libertydiaginstanton.yaml file with the following contents: apiVersion: apps/v1 kind: Deployment metadata: name: libertydiag spec: replicas: 1 selector: matchLabels: name: libertydiag template: metadata: labels: name: libertydiag spec: serviceAccountName: privilegedserviceaccount containers: - name: libertydiag image: quay.io/ibm/libertydiag:instanton imagePullPolicy: Always securityContext: privileged: true Run the YAML file: oc apply -f libertydiaginstanton.yaml Run the following command which will wait until the deployment is ready: oc wait deployment libertydiag --for condition=available --timeout=5m List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-59d59c5dbc-dbz8m 1/1 Running 0 97s Execute a remote search in the pod for the CWWKZ0001I: Application libertydiag started message by replacing $POD with a pod name from the previous command: oc exec $POD -- grep CWWKZ0001I /logs/messages.log For example: $ oc exec libertydiag-59d59c5dbc-dbz8m -- grep CWWKZ0001I /logs/messages.log [12/12/22, 20:13:26:761 UTC] 0000002e com.ibm.ws.app.manager.AppMessageHelper A CWWKZ0001I: Application libertydiag started in 0.684 seconds. This time, notice that the application started in much less time. In the above example, about half a second. Step 4: Clean-up Clean-up the resources. Using the command line Delete the deployment: oc delete deployment libertydiag Delete the ServiceAccount: oc delete serviceaccount privilegedserviceaccount Summary In summary, this lab demonstrated how to run a Liberty InstantOn image in privileged mode. It showed that Liberty startup time compared to a normal deployment was more than a magnitude faster. Lab: InstantOn failing This lab will demonstrate how to investigate why InstantOn failed to work. We will deliberately skip steps to mark the deployment as privileged and observe InstantOn errors. This lab will take approximately 15 minutes. Step 1: Install example application Install using a basic Kubernetes deployment Using the command line Install the InstantOn application but without the proper privileges: oc create deployment libertydiag --image=quay.io/ibm/libertydiag:instanton Wait two minutes for the application to initialize (the namespace may have limited CPU, so startup can take a while) List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-596cc64bdd-rdj62 1/1 Running 0 97s Print the logs of the pod by replacing $POD with a pod name from the previous command: oc logs $POD For example: oc logs libertydiag-596cc64bdd-rdj62 Scroll to the top of the output and observe various errors. In particular, the CWWKE0957I message confirms that InstantOn failed to load and that Liberty will load without InstantOn. /opt/ol/wlp/bin/server: line 1458: /opt/ol/wlp/output/defaultServer/workarea/checkpoint/restoreTime: Permission denied /opt/ol/wlp/bin/server: line 1474: /opt/ol/wlp/output/defaultServer/workarea/checkpoint/.env.properties: Permission denied /opt/ol/wlp/bin/server: line 1413: /usr/sbin/criu: Operation not permitted CWWKE0957I: Restoring the checkpoint server process failed. Check the /logs/checkpoint/restore.log log to determine why the checkpoint process was not restored. Launching the server without using the checkpoint image. Step 2: Clean-up Clean-up the resources. Using the command line Delete the deployment: oc delete deployment libertydiag Delete the ServiceAccount: oc delete serviceaccount privilegedserviceaccount Summary In summary, this lab demonstrated what to look for if InstantOn fails to load. Most commonly, this means that privileges are missing.","title":"InstantOn"},{"location":"lab_liberty_instanton/#lab-instanton","text":"This lab covers how to run a Liberty InstantOn container and investigate issues with InstantOn.","title":"Lab: InstantOn"},{"location":"lab_liberty_instanton/#theory","text":"Liberty InstantOn is a capability of Liberty (along with technology in IBM Semeru Java and Linux) to dramatically reduce Liberty start-up time by up to 10-20 times . In the example you'll see below, startup time goes from 30-60 seconds to less than 1 second. The technology is currently in beta. InstantOn is useful for serverless applications (where Liberty is spawned to handle a single unit of work and then destroyed) but it's also useful for traditional, long-running application scenarios. For example, Kubernetes deployments can be configured to auto-scale based on workload, both down to 0 pods during periods of inactivity (e.g. at night when there may be no users) as well as increasing the number of pods during unexpected spikes of activity. In both of these cases, when a new pod is created, startup time and various caches may affect the requests during the period when new pods are being created and initialized. With InstantOn, start up time can be nearly instantaneous and thus solve those issues with cold starts. The way InstantOn generally works in a cloud environment is that the application developer builds the application container, starts the container, and then takes a checkpoint, most often after applications have finished starting, and this checkpoint is saved into a container image. This checkpoint represents all of the memory and state of Liberty in its ready-to-serve state. Then, when a pod is started based off of this image, Liberty works with IBM Semeru Java and Linux to restore this checkpoint and prepare it for serving requests. The most common issue with InstantOn is that a security misconfiguration causes the checkpoint restore to fail. In this case, Liberty falls back to a normal, slow start-up. Therefore, you'll go through two labs. First, we'll show InstantOn in action with everything succeeding, and then we'll show InstantOn failing the checkpoint restore and how to review the logs for what went wrong. InstantOn in OpenShift has two different ways of running: fully privileged mode (i.e. essentially \"root\" mode) and non-fully privileged but increased privilege mode. For obvious reasons, it's generally more recommended to run in the latter mode because giving a container root privileges means that security risks are higher. However, running in this lower privileges mode requires either a Linux kernel that supports the clone3 system call with the set_tid argument, or runc version 1.1.3 or higher. Such environments are not yet often available, so this first version of these labs will run in fully privileged mode.","title":"Theory"},{"location":"lab_liberty_instanton/#labs","text":"Lab: InstantOn successfully working in privileged mode Lab: InstantOn failing","title":"Labs"},{"location":"lab_liberty_instanton/#lab-instanton-successfully-working-in-privileged-mode","text":"","title":"Lab: InstantOn successfully working in privileged mode"},{"location":"lab_liberty_instanton/#step-1-create-a-serviceaccount","text":"We will run the pod under the authority of a ServiceAccount to which we will associate elevated privileges. Using the command line If you haven't already, download the oc executable and log into your OpenShift console through the command line Create the service account: oc create serviceaccount privilegedserviceaccount Associate the service account with the privileged security context constraint (SCC): oc adm policy add-scc-to-user privileged -z privilegedserviceaccount","title":"Step 1: Create a ServiceAccount"},{"location":"lab_liberty_instanton/#step-2-install-example-application","text":"Uninstall any previously installed sample application. Re-install the sample application using a basic Kubernetes Deployment .","title":"Step 2: Install example application"},{"location":"lab_liberty_instanton/#step-3-test-instanton","text":"First you will see how long it took to start a non-InstantOn application. Then you will delete that and install an InstantOn application for comparison. Using the command line List the pods; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Execute a remote search in the pod for the CWWKZ0001I: Application libertydiag started message by replacing $POD with a pod name from the previous command: oc exec $POD -- grep CWWKZ0001I /logs/messages.log For example: $ oc exec libertydiag-59d59c5dbc-sghwt -- grep CWWKZ0001I /logs/messages.log [12/12/22, 20:00:55:275 UTC] 0000002e com.ibm.ws.app.manager.AppMessageHelper A CWWKZ0001I: Application libertydiag started in 39.409 seconds. Notice that the application took many dozens of seconds to start. In the above example, it took about 40 seconds. Next, we'll delete this deployment and create an InstantOn deployment. Delete the current deployment. oc delete deployment libertydiag Wait about 5 seconds for the deployment to finish deleting. Confirm it's not in the resulting list of all deployments: oc get deployments Example output: No resources found in user1-namespace namespace. Create a libertydiaginstanton.yaml file with the following contents: apiVersion: apps/v1 kind: Deployment metadata: name: libertydiag spec: replicas: 1 selector: matchLabels: name: libertydiag template: metadata: labels: name: libertydiag spec: serviceAccountName: privilegedserviceaccount containers: - name: libertydiag image: quay.io/ibm/libertydiag:instanton imagePullPolicy: Always securityContext: privileged: true Run the YAML file: oc apply -f libertydiaginstanton.yaml Run the following command which will wait until the deployment is ready: oc wait deployment libertydiag --for condition=available --timeout=5m List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-59d59c5dbc-dbz8m 1/1 Running 0 97s Execute a remote search in the pod for the CWWKZ0001I: Application libertydiag started message by replacing $POD with a pod name from the previous command: oc exec $POD -- grep CWWKZ0001I /logs/messages.log For example: $ oc exec libertydiag-59d59c5dbc-dbz8m -- grep CWWKZ0001I /logs/messages.log [12/12/22, 20:13:26:761 UTC] 0000002e com.ibm.ws.app.manager.AppMessageHelper A CWWKZ0001I: Application libertydiag started in 0.684 seconds. This time, notice that the application started in much less time. In the above example, about half a second.","title":"Step 3: Test InstantOn"},{"location":"lab_liberty_instanton/#step-4-clean-up","text":"Clean-up the resources. Using the command line Delete the deployment: oc delete deployment libertydiag Delete the ServiceAccount: oc delete serviceaccount privilegedserviceaccount","title":"Step 4: Clean-up"},{"location":"lab_liberty_instanton/#summary","text":"In summary, this lab demonstrated how to run a Liberty InstantOn image in privileged mode. It showed that Liberty startup time compared to a normal deployment was more than a magnitude faster.","title":"Summary"},{"location":"lab_liberty_instanton/#lab-instanton-failing","text":"This lab will demonstrate how to investigate why InstantOn failed to work. We will deliberately skip steps to mark the deployment as privileged and observe InstantOn errors. This lab will take approximately 15 minutes.","title":"Lab: InstantOn failing"},{"location":"lab_liberty_instanton/#step-1-install-example-application","text":"","title":"Step 1: Install example application"},{"location":"lab_liberty_instanton/#install-using-a-basic-kubernetes-deployment","text":"Using the command line Install the InstantOn application but without the proper privileges: oc create deployment libertydiag --image=quay.io/ibm/libertydiag:instanton Wait two minutes for the application to initialize (the namespace may have limited CPU, so startup can take a while) List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-596cc64bdd-rdj62 1/1 Running 0 97s Print the logs of the pod by replacing $POD with a pod name from the previous command: oc logs $POD For example: oc logs libertydiag-596cc64bdd-rdj62 Scroll to the top of the output and observe various errors. In particular, the CWWKE0957I message confirms that InstantOn failed to load and that Liberty will load without InstantOn. /opt/ol/wlp/bin/server: line 1458: /opt/ol/wlp/output/defaultServer/workarea/checkpoint/restoreTime: Permission denied /opt/ol/wlp/bin/server: line 1474: /opt/ol/wlp/output/defaultServer/workarea/checkpoint/.env.properties: Permission denied /opt/ol/wlp/bin/server: line 1413: /usr/sbin/criu: Operation not permitted CWWKE0957I: Restoring the checkpoint server process failed. Check the /logs/checkpoint/restore.log log to determine why the checkpoint process was not restored. Launching the server without using the checkpoint image.","title":"Install using a basic Kubernetes deployment"},{"location":"lab_liberty_instanton/#step-2-clean-up","text":"Clean-up the resources. Using the command line Delete the deployment: oc delete deployment libertydiag Delete the ServiceAccount: oc delete serviceaccount privilegedserviceaccount","title":"Step 2: Clean-up"},{"location":"lab_liberty_instanton/#summary_1","text":"In summary, this lab demonstrated what to look for if InstantOn fails to load. Most commonly, this means that privileges are missing.","title":"Summary"},{"location":"lab_liberty_java_oome/","text":"Lab: Java OutOfMemoryErrors This lab covers how to investigate Java OutOfMemoryErrors for a sample Liberty application in OpenShift. Theory There are multiple ways to review a Java OutOfMemoryError (OOME) in an OpenShift environment: Gather and review a heapdump ( *.phd ) produced by the OOME Gather and review a system coredump ( *.dmp ) produced by the OOME Labs Choose one or more labs: Lab: Gather and review a heapdump ( *.phd ) produced by the OOME Lab: Gather and review a system coredump ( *.dmp ) produced by the OOME Lab: Gather and review a heapdump ( *.phd ) produced by the OOME This lab will simulate a Java OutOfMemoryError and show how to download the resulting heapdump ( *.phd ) for analysis using the Eclipse Memory Analyzer Tool . This lab will take approximately 10 minutes. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Exercise a Java OutOfMemoryError You will simulate a Java OutOfMemoryError by sending an HTTP request which allocates 1MB arrays until the Java heap is exhausted. Using the command line Request the following web page from your terminal to simulate an OutOfMemoryError: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Using the browser Craft the following link, replacing $HOST with the hostname of the application from the installation step above when you opened the libertydiag application in your browser (e.g. libertydiag-user1-namespace.apps.was-education-cluster.example.com ): http://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false Open this link in the browser Step 3: Confirm the OutOfMemoryError has occurred When an OutOfMemoryError occurs, a message is written by the JVM into standard error ( stderr ). Standard error and standard output ( stdout ) are what are referred to in Kubernetes as the \"logs\" of a container. These logs are the \"native\" logs of the process and they are different than WebSphere logs. For WebSphere Liberty, the container logs are equivalent to console.log when running Liberty outside of containers. You may or may not find evidence of the OutOfMemoryError in WebSphere logs (e.g. messages.log ) depending on whether the application handles the exception. You will review the container logs to confirm that the OutOfMemoryError occurred. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command: oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time and print the logs again. JVMDUMP039I Processing dump event \"systhrow\", detail \"java/lang/OutOfMemoryError\" at 2022/12/07 16:43:38 - please wait. Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running: You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time by watching the bottom of the logs. Step 4: Gather the heapdumps and javacores Now you will gather the heapdumps and javacores produced by the OOME. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Note that the remote shell might timeout after a short period of inactivity, so be aware that you might have been logged out and you'll need to oc rsh back in to continue where you left off. First, we need to find the process ID (PID) of Liberty. Most Liberty images do not have tools like ps or top pre-installed. However, most Liberty images only have a single process in the container which is the Java process running Liberty, and this has the PID of 1. Double check that this is the Liberty process by doing a full listing on PID 1: ls -l /proc/1/ If you see a Liberty current working directory ( cwd ) such as /opt/ol/wlp or /opt/ibm/wlp then you can assume that is the Liberty process. Otherwise, run ls -l /proc/[0-9]* and then explore each PID to find the Liberty process. ls -l /proc/1 Example output: [...] lrwxrwxrwx. 1 1000830000 root 0 Dec 6 17:45 cwd -> /opt/ol/wlp/output/defaultServer -r--------. 1 1000830000 root 0 Dec 6 17:45 environ lrwxrwxrwx. 1 1000830000 root 0 Dec 6 14:57 exe -> /opt/ibm/java/jre/bin/java [...] Normally, heapdumps for IBM Java and Semeru will be produced as heapdump*phd files in the cwd directory that you found above: ls -l /opt/ol/wlp/output/defaultServer/heapdump*phd However, in the case of this sample application, this directory is overridden with an -Xdump configuration. You can check JVM configurations by printing the process cmdline and environ files and find the relevant configuration. For example: cat /proc/1/cmdline /proc/1/environ Example output: [...] -Xdump:directory=logs/diagnostics/ Therefore, for this application, heapdumps will go into logs/diagnostics/ relative to cwd : ls /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump*phd Example output: /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172449.1.0002.phd /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172502.1.0005.phd /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172504.1.0008.phd /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172504.1.0009.phd Note that overridding the -Xdump directory is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed. Step 5: Download heapdumps Using the command line Download the heaps dumps by replacing $POD with a pod name from above and $DIR with the directory of the heapdumps. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:$DIR . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/opt/ol/wlp/output/defaultServer/logs/diagnostics . Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Step 6: Analyze the heap dumps If you are familiar with analyzing heaps dumps, you may skip this step. Review heap dumps Go to https://www.ibm.com/support/pages/eclipse-memory-analyzer-tool-dtfj-and-ibm-extensions Follow the instructions to download and launch MAT. These dumps are produced by IBM Java 8, so choose that download. Click File } Open Heap Dump... Open the first phd file that was downloaded. In the Getting Started Wizard , choose Leak Suspects Report and click Finish Review the leak suspects report which will highlight the cause of the OOME. For example: The class com.example.servlet.AllocateObject occupies 426,783,880 (91.14%) bytes. The memory is accumulated in one instance of java.lang.Object[] which occupies 426,779,160 (91.14%) bytes. Summary In summary, this lab demonstrated how to simulate a Java OutOfMemoryError, detect an OOME occurred in container logs, download the heapdump and javacore diagnostics, and review them in the Eclipse Memory Analyzer Tool. Lab: Gather and review a system coredump ( *.dmp ) produced by the OOME This lab will simulate a Java OutOfMemoryError and show how to download the resulting system coredump ( *.dmp ) for analysis using the Eclipse Memory Analyzer Tool . Note : This lab requires that the user has cluster-admin permissions to access the system coredump on the worker node. This lab will take approximately 20 minutes. Step 0: Check if you have cluster-admin permissions These steps will show if you have cluster-admin permissions. If you do not, you must skip this lab. Using the command line Check if you have authority for all verbs on all resources: oc auth can-i '*' '*' Example output: yes If the answer is no , then you do not have cluster-admin permissions. Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Administrator in the top left: Expand User Management . If you don't see a Users option, then you do not have cluster-admin permissions. If you do see it, click on it, and then click on your user name: Click on RoleBindings and check if any binding has a Role ref of cluster-admin . If there are none, then you do not have cluster-admin permissions. Step 1: Install example application If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation. Step 2: Exercise a Java OutOfMemoryError If you completed the previous lab above and generated an OOM already, skip down to Step 4: Gather the system coredump . Using the command line Request the following web page from your terminal to simulate an OutOfMemoryError: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Using the browser Craft the following link, replacing $HOST with the hostname of the application from the installation step above when you opened the libertydiag application in your browser (e.g. libertydiag-user1-namespace.apps.was-education-cluster.example.com ): http://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false Open this link in the browser Step 3: Confirm the OutOfMemoryError has occurred When an OutOfMemoryError occurs, a message is written by the JVM into standard error ( stderr ). Standard error and standard output ( stdout ) are what are referred to in Kubernetes as the \"logs\" of a container. These logs are the \"native\" logs of the process and they are different than WebSphere logs. For WebSphere Liberty, the container logs are equivalent to console.log when running Liberty outside of containers. You may or may not find evidence of the OutOfMemoryError in WebSphere logs (e.g. messages.log ) depending on whether the application handles the exception. You will review the container logs to confirm that the OutOfMemoryError occurred. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command: oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time and print the logs again. JVMDUMP039I Processing dump event \"systhrow\", detail \"java/lang/OutOfMemoryError\" at 2022/12/07 16:43:38 - please wait. Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running: You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time by watching the bottom of the logs. Step 4: Gather the system coredump Now you will gather the system coredump produced by the JVM. Unlike heapdumps and javacores, in many OpenShift environments, a system coredump is produced on the worker node rather than inside the container. Therefore, a user with cluster-admin authority must be used to download the coredump. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Find the worker node of the pod by replacing $POD with the pod name from the previous command: oc get pod --output \"jsonpath={.spec.nodeName}{'\\n'}\" $POD For example: oc get pod --output \"jsonpath={.spec.nodeName}{'\\n'}\" libertydiag-b98748954-mgj64 Start a debug pod on that worker node by replacing $NODE with the node name from the previous command: oc debug node/$NODE -t For example: oc debug node/worker0.was-education-cluster.example.com -t Note that the remote shell might timeout after a short period of inactivity, so be aware that you might have been logged out and you'll need to re-run oc debug node to continue where you left off. These systems use systemd-coredump which places core dumps in /var/lib/systemd/coredump/ (other systems may use other locations ). To see them through the debug pod, prepend /host : sh-4.4# ls -l /host/var/lib/systemd/coredump/ total 115824 -rw-r-----+ 1 root root 118596950 Feb 28 16:25 'core.Default\\x20Executo.1001210000.06a2f2e0997c46b2b50bdac3c25ab072.831941.1677601537000000.lz4' Confirm the matching timestamp when the OutOfMemoryError occurred. Now we'll use this debug pod to download the file. First start a looping output so that the debug pod doesn't timeout by executing: while true; do echo 'Sleeping'; sleep 8; done Next, open a new terminal and find the debug pod and namespace. For example: oc get pods --field-selector=status.phase==Running --all-namespaces | grep debug Example output: openshift-debug-node-4whw7mhb8j worker0was-education-clusterexamplecom-debug 1/1 Running 0 2m46s Use the above namespace (first column) and pod name (second column) to download the core dump from the worker node. Unfortunately, there is an open issue with escape characters so we must download the entire dumps directory: oc cp --namespace openshift-debug-node-4whw7mhb8j \"worker0was-education-clusterexample.com-debug:/host/var/lib/systemd/coredump/\" coredumps Change directory into coredumps and any subdirectory that was created and then uncompress the core dump: Install the lz4 utility: macOS: brew install lz4 Windows: Download lz4 (under Assets at the bottom) Linux: Install the lz4 program Decompress the file (replacing $FILE with the file name): lz4 -dc $FILE.lz4 > core.dmp Go back to the previous terminal window and type Ctrl^C to stop the while loop, and then exit the debug node. Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above. Step 5: Analyze the system coredump If you are familiar with analyzing system coredumps, you may skip this step. Review core dump Go to https://www.ibm.com/support/pages/eclipse-memory-analyzer-tool-dtfj-and-ibm-extensions Follow the instructions to download and launch MAT. These dumps are produced by IBM Java 8, so choose that download. Click File } Open Heap Dump... Open the *.dmp file that was downloaded. In the Getting Started Wizard , choose Leak Suspects Report and click Finish Review the leak suspects report which will highlight the cause of the OOME. For example: The class com.example.servlet.AllocateObject occupies 426,783,880 (91.14%) bytes. The memory is accumulated in one instance of java.lang.Object[] which occupies 426,779,160 (91.14%) bytes. Summary In summary, this lab demonstrated how to simulate a Java OutOfMemoryError, detect an OOME occurred in container logs, download the system coredump diagnostic, and review it in the Eclipse Memory Analyzer Tool.","title":"Java OutOfMemoryErrors"},{"location":"lab_liberty_java_oome/#lab-java-outofmemoryerrors","text":"This lab covers how to investigate Java OutOfMemoryErrors for a sample Liberty application in OpenShift.","title":"Lab: Java OutOfMemoryErrors"},{"location":"lab_liberty_java_oome/#theory","text":"There are multiple ways to review a Java OutOfMemoryError (OOME) in an OpenShift environment: Gather and review a heapdump ( *.phd ) produced by the OOME Gather and review a system coredump ( *.dmp ) produced by the OOME","title":"Theory"},{"location":"lab_liberty_java_oome/#labs","text":"Choose one or more labs: Lab: Gather and review a heapdump ( *.phd ) produced by the OOME Lab: Gather and review a system coredump ( *.dmp ) produced by the OOME","title":"Labs"},{"location":"lab_liberty_java_oome/#lab-gather-and-review-a-heapdump-phd-produced-by-the-oome","text":"This lab will simulate a Java OutOfMemoryError and show how to download the resulting heapdump ( *.phd ) for analysis using the Eclipse Memory Analyzer Tool . This lab will take approximately 10 minutes.","title":"Lab: Gather and review a heapdump (*.phd) produced by the OOME"},{"location":"lab_liberty_java_oome/#step-1-install-example-application","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_java_oome/#step-2-exercise-a-java-outofmemoryerror","text":"You will simulate a Java OutOfMemoryError by sending an HTTP request which allocates 1MB arrays until the Java heap is exhausted. Using the command line Request the following web page from your terminal to simulate an OutOfMemoryError: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Using the browser Craft the following link, replacing $HOST with the hostname of the application from the installation step above when you opened the libertydiag application in your browser (e.g. libertydiag-user1-namespace.apps.was-education-cluster.example.com ): http://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false Open this link in the browser","title":"Step 2: Exercise a Java OutOfMemoryError"},{"location":"lab_liberty_java_oome/#step-3-confirm-the-outofmemoryerror-has-occurred","text":"When an OutOfMemoryError occurs, a message is written by the JVM into standard error ( stderr ). Standard error and standard output ( stdout ) are what are referred to in Kubernetes as the \"logs\" of a container. These logs are the \"native\" logs of the process and they are different than WebSphere logs. For WebSphere Liberty, the container logs are equivalent to console.log when running Liberty outside of containers. You may or may not find evidence of the OutOfMemoryError in WebSphere logs (e.g. messages.log ) depending on whether the application handles the exception. You will review the container logs to confirm that the OutOfMemoryError occurred. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command: oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time and print the logs again. JVMDUMP039I Processing dump event \"systhrow\", detail \"java/lang/OutOfMemoryError\" at 2022/12/07 16:43:38 - please wait. Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running: You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time by watching the bottom of the logs.","title":"Step 3: Confirm the OutOfMemoryError has occurred"},{"location":"lab_liberty_java_oome/#step-4-gather-the-heapdumps-and-javacores","text":"Now you will gather the heapdumps and javacores produced by the OOME. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Open a shell into the pod by replacing $POD with a pod name from the previous command: oc rsh -t $POD For example: oc rsh -t libertydiag-b98748954-mgj64 Note that the remote shell might timeout after a short period of inactivity, so be aware that you might have been logged out and you'll need to oc rsh back in to continue where you left off. First, we need to find the process ID (PID) of Liberty. Most Liberty images do not have tools like ps or top pre-installed. However, most Liberty images only have a single process in the container which is the Java process running Liberty, and this has the PID of 1. Double check that this is the Liberty process by doing a full listing on PID 1: ls -l /proc/1/ If you see a Liberty current working directory ( cwd ) such as /opt/ol/wlp or /opt/ibm/wlp then you can assume that is the Liberty process. Otherwise, run ls -l /proc/[0-9]* and then explore each PID to find the Liberty process. ls -l /proc/1 Example output: [...] lrwxrwxrwx. 1 1000830000 root 0 Dec 6 17:45 cwd -> /opt/ol/wlp/output/defaultServer -r--------. 1 1000830000 root 0 Dec 6 17:45 environ lrwxrwxrwx. 1 1000830000 root 0 Dec 6 14:57 exe -> /opt/ibm/java/jre/bin/java [...] Normally, heapdumps for IBM Java and Semeru will be produced as heapdump*phd files in the cwd directory that you found above: ls -l /opt/ol/wlp/output/defaultServer/heapdump*phd However, in the case of this sample application, this directory is overridden with an -Xdump configuration. You can check JVM configurations by printing the process cmdline and environ files and find the relevant configuration. For example: cat /proc/1/cmdline /proc/1/environ Example output: [...] -Xdump:directory=logs/diagnostics/ Therefore, for this application, heapdumps will go into logs/diagnostics/ relative to cwd : ls /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump*phd Example output: /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172449.1.0002.phd /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172502.1.0005.phd /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172504.1.0008.phd /opt/ol/wlp/output/defaultServer/logs/diagnostics/heapdump.20221207.172504.1.0009.phd Note that overridding the -Xdump directory is common in container deployments so that a directory may be used that's mounted on a permanent disk so that diagnostics are still available if a pod is killed.","title":"Step 4: Gather the heapdumps and javacores"},{"location":"lab_liberty_java_oome/#step-5-download-heapdumps","text":"Using the command line Download the heaps dumps by replacing $POD with a pod name from above and $DIR with the directory of the heapdumps. Note that oc cp does not support wildcards so the whole directory (or a single file) must be downloaded. oc cp $POD:$DIR . For example: oc cp libertydiag-ddf5f95b6-wj6dm:/opt/ol/wlp/output/defaultServer/logs/diagnostics . Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above.","title":"Step 5: Download heapdumps"},{"location":"lab_liberty_java_oome/#step-6-analyze-the-heap-dumps","text":"If you are familiar with analyzing heaps dumps, you may skip this step. Review heap dumps Go to https://www.ibm.com/support/pages/eclipse-memory-analyzer-tool-dtfj-and-ibm-extensions Follow the instructions to download and launch MAT. These dumps are produced by IBM Java 8, so choose that download. Click File } Open Heap Dump... Open the first phd file that was downloaded. In the Getting Started Wizard , choose Leak Suspects Report and click Finish Review the leak suspects report which will highlight the cause of the OOME. For example: The class com.example.servlet.AllocateObject occupies 426,783,880 (91.14%) bytes. The memory is accumulated in one instance of java.lang.Object[] which occupies 426,779,160 (91.14%) bytes.","title":"Step 6: Analyze the heap dumps"},{"location":"lab_liberty_java_oome/#summary","text":"In summary, this lab demonstrated how to simulate a Java OutOfMemoryError, detect an OOME occurred in container logs, download the heapdump and javacore diagnostics, and review them in the Eclipse Memory Analyzer Tool.","title":"Summary"},{"location":"lab_liberty_java_oome/#lab-gather-and-review-a-system-coredump-dmp-produced-by-the-oome","text":"This lab will simulate a Java OutOfMemoryError and show how to download the resulting system coredump ( *.dmp ) for analysis using the Eclipse Memory Analyzer Tool . Note : This lab requires that the user has cluster-admin permissions to access the system coredump on the worker node. This lab will take approximately 20 minutes.","title":"Lab: Gather and review a system coredump (*.dmp) produced by the OOME"},{"location":"lab_liberty_java_oome/#step-0-check-if-you-have-cluster-admin-permissions","text":"These steps will show if you have cluster-admin permissions. If you do not, you must skip this lab. Using the command line Check if you have authority for all verbs on all resources: oc auth can-i '*' '*' Example output: yes If the answer is no , then you do not have cluster-admin permissions. Using the browser Access your OpenShift web console at https://console-openshift-console.$CLUSTER/ . Replace $CLUSTER with your OpenShift cluster domain. Ensure the perspective is set to Administrator in the top left: Expand User Management . If you don't see a Users option, then you do not have cluster-admin permissions. If you do see it, click on it, and then click on your user name: Click on RoleBindings and check if any binding has a Role ref of cluster-admin . If there are none, then you do not have cluster-admin permissions.","title":"Step 0: Check if you have cluster-admin permissions"},{"location":"lab_liberty_java_oome/#step-1-install-example-application_1","text":"If you haven't already, install the sample application . If you installed it in a previous lab, you may continue using the previous installation.","title":"Step 1: Install example application"},{"location":"lab_liberty_java_oome/#step-2-exercise-a-java-outofmemoryerror_1","text":"If you completed the previous lab above and generated an OOM already, skip down to Step 4: Gather the system coredump . Using the command line Request the following web page from your terminal to simulate an OutOfMemoryError: macOS, Linux, or Windows with Cygwin: curl -k -s \"https://$(oc get route libertydiag \"--output=jsonpath={.spec.host}\")/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Windows with Command Prompt: Ensure you have curl for Windows installed List the application's URL: oc get route libertydiag \"--output=jsonpath={.spec.host}{'\\n'}\" Execute the following command, replacing $HOST with the output of the previous command: curl -k -s \"https://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false\" Using the browser Craft the following link, replacing $HOST with the hostname of the application from the installation step above when you opened the libertydiag application in your browser (e.g. libertydiag-user1-namespace.apps.was-education-cluster.example.com ): http://$HOST/servlet/AllocateObject?size=1048576&iterations=10000&waittime=10&retainData=false Open this link in the browser","title":"Step 2: Exercise a Java OutOfMemoryError"},{"location":"lab_liberty_java_oome/#step-3-confirm-the-outofmemoryerror-has-occurred_1","text":"When an OutOfMemoryError occurs, a message is written by the JVM into standard error ( stderr ). Standard error and standard output ( stdout ) are what are referred to in Kubernetes as the \"logs\" of a container. These logs are the \"native\" logs of the process and they are different than WebSphere logs. For WebSphere Liberty, the container logs are equivalent to console.log when running Liberty outside of containers. You may or may not find evidence of the OutOfMemoryError in WebSphere logs (e.g. messages.log ) depending on whether the application handles the exception. You will review the container logs to confirm that the OutOfMemoryError occurred. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Print the native logs of the pod by replacing $POD with the pod name from the previous command: oc logs $POD For example: oc logs libertydiag-b98748954-mgj64 You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time and print the logs again. JVMDUMP039I Processing dump event \"systhrow\", detail \"java/lang/OutOfMemoryError\" at 2022/12/07 16:43:38 - please wait. Using the browser In the Topology view of the Developer perspective , click on the libertydiag circle, then click the Resources tab in the drawer on the right, and then click on View logs for the one pod that's running: You should see OutOfMemoryError lines such as the following. If you don't see them, give it some time by watching the bottom of the logs.","title":"Step 3: Confirm the OutOfMemoryError has occurred"},{"location":"lab_liberty_java_oome/#step-4-gather-the-system-coredump","text":"Now you will gather the system coredump produced by the JVM. Unlike heapdumps and javacores, in many OpenShift environments, a system coredump is produced on the worker node rather than inside the container. Therefore, a user with cluster-admin authority must be used to download the coredump. Using the command line List the pods for the example application deployment; for example: oc get pods Example output: NAME READY STATUS RESTARTS AGE libertydiag-b98748954-mgj64 1/1 Running 0 97s Find the worker node of the pod by replacing $POD with the pod name from the previous command: oc get pod --output \"jsonpath={.spec.nodeName}{'\\n'}\" $POD For example: oc get pod --output \"jsonpath={.spec.nodeName}{'\\n'}\" libertydiag-b98748954-mgj64 Start a debug pod on that worker node by replacing $NODE with the node name from the previous command: oc debug node/$NODE -t For example: oc debug node/worker0.was-education-cluster.example.com -t Note that the remote shell might timeout after a short period of inactivity, so be aware that you might have been logged out and you'll need to re-run oc debug node to continue where you left off. These systems use systemd-coredump which places core dumps in /var/lib/systemd/coredump/ (other systems may use other locations ). To see them through the debug pod, prepend /host : sh-4.4# ls -l /host/var/lib/systemd/coredump/ total 115824 -rw-r-----+ 1 root root 118596950 Feb 28 16:25 'core.Default\\x20Executo.1001210000.06a2f2e0997c46b2b50bdac3c25ab072.831941.1677601537000000.lz4' Confirm the matching timestamp when the OutOfMemoryError occurred. Now we'll use this debug pod to download the file. First start a looping output so that the debug pod doesn't timeout by executing: while true; do echo 'Sleeping'; sleep 8; done Next, open a new terminal and find the debug pod and namespace. For example: oc get pods --field-selector=status.phase==Running --all-namespaces | grep debug Example output: openshift-debug-node-4whw7mhb8j worker0was-education-clusterexamplecom-debug 1/1 Running 0 2m46s Use the above namespace (first column) and pod name (second column) to download the core dump from the worker node. Unfortunately, there is an open issue with escape characters so we must download the entire dumps directory: oc cp --namespace openshift-debug-node-4whw7mhb8j \"worker0was-education-clusterexample.com-debug:/host/var/lib/systemd/coredump/\" coredumps Change directory into coredumps and any subdirectory that was created and then uncompress the core dump: Install the lz4 utility: macOS: brew install lz4 Windows: Download lz4 (under Assets at the bottom) Linux: Install the lz4 program Decompress the file (replacing $FILE with the file name): lz4 -dc $FILE.lz4 > core.dmp Go back to the previous terminal window and type Ctrl^C to stop the while loop, and then exit the debug node. Using the browser Files other than native logs (equivalent to Liberty's console.log ) cannot be downloaded through the browser. You must use the command line steps above.","title":"Step 4: Gather the system coredump"},{"location":"lab_liberty_java_oome/#step-5-analyze-the-system-coredump","text":"If you are familiar with analyzing system coredumps, you may skip this step. Review core dump Go to https://www.ibm.com/support/pages/eclipse-memory-analyzer-tool-dtfj-and-ibm-extensions Follow the instructions to download and launch MAT. These dumps are produced by IBM Java 8, so choose that download. Click File } Open Heap Dump... Open the *.dmp file that was downloaded. In the Getting Started Wizard , choose Leak Suspects Report and click Finish Review the leak suspects report which will highlight the cause of the OOME. For example: The class com.example.servlet.AllocateObject occupies 426,783,880 (91.14%) bytes. The memory is accumulated in one instance of java.lang.Object[] which occupies 426,779,160 (91.14%) bytes.","title":"Step 5: Analyze the system coredump"},{"location":"lab_liberty_java_oome/#summary_1","text":"In summary, this lab demonstrated how to simulate a Java OutOfMemoryError, detect an OOME occurred in container logs, download the system coredump diagnostic, and review it in the Eclipse Memory Analyzer Tool.","title":"Summary"},{"location":"lab_liberty_uninstall_app/","text":"Uninstall Sample WebSphere Liberty Application You may uninstall the sample application either to clean up your environment or prepare to install it again using a different method. Using the command line If you created the application using the WebSphere Liberty Operator, then run: oc delete webspherelibertyapplication libertydiag If you created the application using a basic Kubernetes Deployment, then run: oc delete deployment libertydiag Using the browser If you created the application using the WebSphere Liberty Operator, then go to the Developer } Topology view, click on the ellipses on the WSLA line and click Delete WebSphereLibertyApplication and then click Delete : If you created the application using a basic Kubernetes Deployment, then go to the Developer } Topology view, click on the ellipses on the libertydiag line and click Delete Deployment and then click Delete : If you need to re-install the application, go to the install page .","title":"Uninstall Sample Liberty Application"},{"location":"lab_liberty_uninstall_app/#uninstall-sample-websphere-liberty-application","text":"You may uninstall the sample application either to clean up your environment or prepare to install it again using a different method. Using the command line If you created the application using the WebSphere Liberty Operator, then run: oc delete webspherelibertyapplication libertydiag If you created the application using a basic Kubernetes Deployment, then run: oc delete deployment libertydiag Using the browser If you created the application using the WebSphere Liberty Operator, then go to the Developer } Topology view, click on the ellipses on the WSLA line and click Delete WebSphereLibertyApplication and then click Delete : If you created the application using a basic Kubernetes Deployment, then go to the Developer } Topology view, click on the ellipses on the libertydiag line and click Delete Deployment and then click Delete : If you need to re-install the application, go to the install page .","title":"Uninstall Sample WebSphere Liberty Application"},{"location":"lab_pipelines/","text":"OpenShift Pipelines OpenShift pipelines is a continuous integration and delivery (CI/CD) solution based on the Tekton open source project. Installing Openshift Pipelines OpenShift Pipelines is provided as an add-on on top of OpenShift that can be installed via an operator available in the OpenShift OperatorHub. Install the OpenShift Pipelines Operator from Operator Hub If the operator is not already available, it can be installed via OperatorHub. In the OpenShift Console, expand 'Operators' and select 'Installed Operators': Check that 'OpenShift Pipelines' is included in the list of installed operators: If the operator is not installed, click on OperatorHub. In the search box, enter 'pipelines' Click on 'RedHat OpenShift Pipelines' Click the 'Install' button OpenShift Pipelines/Tekton concepts Tekton defines a number of Kubernetes custom resources as building blocks in order to standardize pipeline concepts and provide a terminology that is consistent across CI/CD solutions. These custom resources are an extension of the Kubernetes API that let users create and interact with these objects using kubectl and other Kubernetes tools. The custom resources needed to define a pipeline are listed below: Task: a reusable, loosely coupled number of steps that perform a specific task (e.g. building a container image) Pipeline: the definition of the pipeline and the Tasks that it should perform PipelineResource: inputs (e.g. git repository) and outputs (e.g. image registry) to and out of a pipeline or task TaskRun: the execution and result of running an instance of task PipelineRun: the execution and result of running an instance of pipeline, which includes a number of TaskRuns In short, in order to create a pipeline, one does the following: Create custom Tasks Create a Pipeline and PipelineResources to define application delivery pipeline Create a PipelineRun to instantiate and invoke the pipeline Creating a simple pipeline In this lab, we will create a simple pipeline to explore Tekton concepts. A pipeline would normally contain tasks to gather code from a source repository, build it, containerize it, and push it to the container registry. In this case, we will only create tasks that produce logs. Create some tasks For each task you have the option of creating it manually in the OpenShift console or using the command line to apply an existing yaml file. To create a task manually, expand 'Pipelines' in the OpenShift console and click on 'Tasks'. In the upper right hand corner, click 'Create' and select 'Task'. Edit the yaml for the task to match the values in the provided files, or experiment with different values. The tasks do not have to exactly match the provided tasks for the purposes of this lab. Create a task named 'hello' that will echo a parameter value to the logs. If using the command line, download the file hello.yaml and run oc apply -f hello.yaml . If using the console, enter the contents of hello.yaml into the Create Task editor. Create a task named 'goobye' that will echo 'Goodbye' to the logs. If using the command line, download the file file goodbye.yaml and run oc apply -f goodbye.yaml . If using the console, enter the contents of goodbye.yaml into the Create Task editor. Create a task named 'failing-task' that will always fail. Again, either download the file fail.yaml and run oc apply -f fail.yaml or enter the contents into the console's Create Task editor. In the OpenShift console, expand 'Pipelines' and select 'Tasks'. You should see the three tasks you created. Click on each one and examine the yaml definition. If using the command line, run oc get task to view the created tasks. labs % oc get task NAME AGE failing-task 53s goodbye 109s hello 3m4s Create a pipeline For this part of the lab we will use the OpenShift console to create a pipeline consisting of the tasks we just created. In the console, expand 'Pipelines' and click on 'Pipelines'. In the upper right hand corner, click on 'Create' and select 'Pipeline' You should now see the 'Pipeline Builder' view which we will use to create a new pipeline. Enter a name for the pipeline such as 'lab-pipeline'. In the 'Tasks' section, click on 'Add Task'. In the search box, enter 'hello'. As you are typing, notice that there are many other predefined tasks that are also available. When you find the 'hello' task, click the 'Add' button to add it to the pipeline. The 'hello' task is now in the pipeline. Hover over the task in the builder and notice that there is a '+' symbol at the left, right, and bottom of the task bubble. We want to have our next task run after the 'hello' task, so click the '+' to the right of the bubble. A new 'Add Task' bubble is now available to the right of the 'hello' bubble. Click on it and add the 'goodbye' task. Click 'Create' to create the pipeline Running the pipeline After clicking 'Create' you are shown an overview of the pipeline. You can click on 'yaml' to examine the details of the pipeline that was created. Run the pipeline by clicking on 'Actions' in the upper right hand corner and selecting 'Start'. You can see the progress of the pipeline run in the 'PipelineRun details' section of the resulting screen. After a short amount of time, both 'hello' and 'goodbye' should have green check marks indicating that they have finished. Click on 'logs' and click on either 'Hello' or 'Goodbye'. You should see the output for the task you created. Navigate back to the list of pipelines (Pipelines->Pipelines in the console). You should now see a green bar next to your pipeline indicating that the run was succesful. Editing the pipeline Navigate to the details page for the pipeline by clicking on it. Select Actions->Edit Pipeline. This will bring you back tot he pipeline builder screen. Add a new task between the 'Hello' and 'Goobye' tasks by clicking the '+' symbol either to the right of 'Hello' or to the left of 'Goodbye'. Click on the resulting 'Add Task' bubble and add a task for 'failing-task'. There should be a red exclamation mark on the newly created task. Hover over it to see what the problem is. Before we can save the new pipeline, we have to provide parameters for the 'failing-task' task. Click on the task bubble and a details panel will appear to the right of the screen. In the 'Parameters' section, enter a value for 'appName'. The red exclamation mark should go away, and saving the pipeline is now enabled. Save the pipeline by clicking the 'Save' button. Rerunning the pipeline Start a new run by selecting Actions->Start. This time, the pipeline details should show a green check mark for 'Hello', and a red exclamation mark for 'failing-task'. The 'Goodbye' task does not run. Click on the 'Events' tab. It should show that 'failing-task' exited with exit code 2, and that the Pipeline Run had one failed task and one skipped task. Navigate back to the list of Pipelines. You should now have a green, red, and gray bar next to the pipeline that shows the completed, failed, and skipped tasks in the pipeline. Adding 'finally' tasks Now edit the pipeline again. This time, add several 'Finally' tasks by clicking on the '+' next to 'Add finally task'. Repeat the procedure a few times, adding the hello and goodbye tasks. Notice that all of the tasks run in parallel. Save the pipeline and run it again. Notice that the 'Goodbye' task still doesn't run, but all of the 'Finally' tasks you added are executed. Note that the 'Finally' tasks may appear to run sequentially in the order they are defined because there aren't enough system resources to handle them at once, but they are actually run in parallel. Install Tekton dashboard The Tekton dashboard provides a more detailed overview of OpenShift pipelines than the OpenShift console. Use the following steps to install the dashboard: Run curl -L -O https://github.com/tektoncd/dashboard/releases/download/v0.32.0/release-full.yaml from a terminal. If you're working on a system that doesn't have curl installed, just download the file using a browser. The downloaded yaml file uses the namespace tekton-pipelines by default, but we need to install it in openshift-pipelines . To fix this, replace all instances of tekton-pipelines in release-full.yaml with openshift-pipelines (linux command: sed -i 's/tekton-pipelines/openshift-pipelines/g' release-full.yaml mac command: sed -i.bak 's/tekton-pipelines/openshift-pipelines/g' release-full.yaml ) Run oc apply -f release-full.yaml Run oc get pods -n openshift-pipelines . The dashboard will be installed when all pods are in 'Running' state. Run oc expose svc/tekton-dashboard -n openshift-pipelines to create a route to the dashboard Run oc get route tekton-dashboard -n openshift-pipelines to get the URL for the dashboard Learn More OpenShift Pipelines Tutorial Knative Deployment using Tekton Pipelines","title":"Pipelines"},{"location":"lab_pipelines/#openshift-pipelines","text":"OpenShift pipelines is a continuous integration and delivery (CI/CD) solution based on the Tekton open source project.","title":"OpenShift Pipelines"},{"location":"lab_pipelines/#installing-openshift-pipelines","text":"OpenShift Pipelines is provided as an add-on on top of OpenShift that can be installed via an operator available in the OpenShift OperatorHub.","title":"Installing Openshift Pipelines"},{"location":"lab_pipelines/#install-the-openshift-pipelines-operator-from-operator-hub","text":"If the operator is not already available, it can be installed via OperatorHub. In the OpenShift Console, expand 'Operators' and select 'Installed Operators': Check that 'OpenShift Pipelines' is included in the list of installed operators: If the operator is not installed, click on OperatorHub. In the search box, enter 'pipelines' Click on 'RedHat OpenShift Pipelines' Click the 'Install' button","title":"Install the OpenShift Pipelines Operator from Operator Hub"},{"location":"lab_pipelines/#openshift-pipelinestekton-concepts","text":"Tekton defines a number of Kubernetes custom resources as building blocks in order to standardize pipeline concepts and provide a terminology that is consistent across CI/CD solutions. These custom resources are an extension of the Kubernetes API that let users create and interact with these objects using kubectl and other Kubernetes tools. The custom resources needed to define a pipeline are listed below: Task: a reusable, loosely coupled number of steps that perform a specific task (e.g. building a container image) Pipeline: the definition of the pipeline and the Tasks that it should perform PipelineResource: inputs (e.g. git repository) and outputs (e.g. image registry) to and out of a pipeline or task TaskRun: the execution and result of running an instance of task PipelineRun: the execution and result of running an instance of pipeline, which includes a number of TaskRuns In short, in order to create a pipeline, one does the following: Create custom Tasks Create a Pipeline and PipelineResources to define application delivery pipeline Create a PipelineRun to instantiate and invoke the pipeline","title":"OpenShift Pipelines/Tekton concepts"},{"location":"lab_pipelines/#creating-a-simple-pipeline","text":"In this lab, we will create a simple pipeline to explore Tekton concepts. A pipeline would normally contain tasks to gather code from a source repository, build it, containerize it, and push it to the container registry. In this case, we will only create tasks that produce logs.","title":"Creating a simple pipeline"},{"location":"lab_pipelines/#create-some-tasks","text":"For each task you have the option of creating it manually in the OpenShift console or using the command line to apply an existing yaml file. To create a task manually, expand 'Pipelines' in the OpenShift console and click on 'Tasks'. In the upper right hand corner, click 'Create' and select 'Task'. Edit the yaml for the task to match the values in the provided files, or experiment with different values. The tasks do not have to exactly match the provided tasks for the purposes of this lab. Create a task named 'hello' that will echo a parameter value to the logs. If using the command line, download the file hello.yaml and run oc apply -f hello.yaml . If using the console, enter the contents of hello.yaml into the Create Task editor. Create a task named 'goobye' that will echo 'Goodbye' to the logs. If using the command line, download the file file goodbye.yaml and run oc apply -f goodbye.yaml . If using the console, enter the contents of goodbye.yaml into the Create Task editor. Create a task named 'failing-task' that will always fail. Again, either download the file fail.yaml and run oc apply -f fail.yaml or enter the contents into the console's Create Task editor. In the OpenShift console, expand 'Pipelines' and select 'Tasks'. You should see the three tasks you created. Click on each one and examine the yaml definition. If using the command line, run oc get task to view the created tasks. labs % oc get task NAME AGE failing-task 53s goodbye 109s hello 3m4s","title":"Create some tasks"},{"location":"lab_pipelines/#create-a-pipeline","text":"For this part of the lab we will use the OpenShift console to create a pipeline consisting of the tasks we just created. In the console, expand 'Pipelines' and click on 'Pipelines'. In the upper right hand corner, click on 'Create' and select 'Pipeline' You should now see the 'Pipeline Builder' view which we will use to create a new pipeline. Enter a name for the pipeline such as 'lab-pipeline'. In the 'Tasks' section, click on 'Add Task'. In the search box, enter 'hello'. As you are typing, notice that there are many other predefined tasks that are also available. When you find the 'hello' task, click the 'Add' button to add it to the pipeline. The 'hello' task is now in the pipeline. Hover over the task in the builder and notice that there is a '+' symbol at the left, right, and bottom of the task bubble. We want to have our next task run after the 'hello' task, so click the '+' to the right of the bubble. A new 'Add Task' bubble is now available to the right of the 'hello' bubble. Click on it and add the 'goodbye' task. Click 'Create' to create the pipeline","title":"Create a pipeline"},{"location":"lab_pipelines/#running-the-pipeline","text":"After clicking 'Create' you are shown an overview of the pipeline. You can click on 'yaml' to examine the details of the pipeline that was created. Run the pipeline by clicking on 'Actions' in the upper right hand corner and selecting 'Start'. You can see the progress of the pipeline run in the 'PipelineRun details' section of the resulting screen. After a short amount of time, both 'hello' and 'goodbye' should have green check marks indicating that they have finished. Click on 'logs' and click on either 'Hello' or 'Goodbye'. You should see the output for the task you created. Navigate back to the list of pipelines (Pipelines->Pipelines in the console). You should now see a green bar next to your pipeline indicating that the run was succesful.","title":"Running the pipeline"},{"location":"lab_pipelines/#editing-the-pipeline","text":"Navigate to the details page for the pipeline by clicking on it. Select Actions->Edit Pipeline. This will bring you back tot he pipeline builder screen. Add a new task between the 'Hello' and 'Goobye' tasks by clicking the '+' symbol either to the right of 'Hello' or to the left of 'Goodbye'. Click on the resulting 'Add Task' bubble and add a task for 'failing-task'. There should be a red exclamation mark on the newly created task. Hover over it to see what the problem is. Before we can save the new pipeline, we have to provide parameters for the 'failing-task' task. Click on the task bubble and a details panel will appear to the right of the screen. In the 'Parameters' section, enter a value for 'appName'. The red exclamation mark should go away, and saving the pipeline is now enabled. Save the pipeline by clicking the 'Save' button.","title":"Editing the pipeline"},{"location":"lab_pipelines/#rerunning-the-pipeline","text":"Start a new run by selecting Actions->Start. This time, the pipeline details should show a green check mark for 'Hello', and a red exclamation mark for 'failing-task'. The 'Goodbye' task does not run. Click on the 'Events' tab. It should show that 'failing-task' exited with exit code 2, and that the Pipeline Run had one failed task and one skipped task. Navigate back to the list of Pipelines. You should now have a green, red, and gray bar next to the pipeline that shows the completed, failed, and skipped tasks in the pipeline.","title":"Rerunning the pipeline"},{"location":"lab_pipelines/#adding-finally-tasks","text":"Now edit the pipeline again. This time, add several 'Finally' tasks by clicking on the '+' next to 'Add finally task'. Repeat the procedure a few times, adding the hello and goodbye tasks. Notice that all of the tasks run in parallel. Save the pipeline and run it again. Notice that the 'Goodbye' task still doesn't run, but all of the 'Finally' tasks you added are executed. Note that the 'Finally' tasks may appear to run sequentially in the order they are defined because there aren't enough system resources to handle them at once, but they are actually run in parallel.","title":"Adding 'finally' tasks"},{"location":"lab_pipelines/#install-tekton-dashboard","text":"The Tekton dashboard provides a more detailed overview of OpenShift pipelines than the OpenShift console. Use the following steps to install the dashboard: Run curl -L -O https://github.com/tektoncd/dashboard/releases/download/v0.32.0/release-full.yaml from a terminal. If you're working on a system that doesn't have curl installed, just download the file using a browser. The downloaded yaml file uses the namespace tekton-pipelines by default, but we need to install it in openshift-pipelines . To fix this, replace all instances of tekton-pipelines in release-full.yaml with openshift-pipelines (linux command: sed -i 's/tekton-pipelines/openshift-pipelines/g' release-full.yaml mac command: sed -i.bak 's/tekton-pipelines/openshift-pipelines/g' release-full.yaml ) Run oc apply -f release-full.yaml Run oc get pods -n openshift-pipelines . The dashboard will be installed when all pods are in 'Running' state. Run oc expose svc/tekton-dashboard -n openshift-pipelines to create a route to the dashboard Run oc get route tekton-dashboard -n openshift-pipelines to get the URL for the dashboard","title":"Install Tekton dashboard"},{"location":"lab_pipelines/#learn-more","text":"OpenShift Pipelines Tutorial Knative Deployment using Tekton Pipelines","title":"Learn More"},{"location":"openshift_login_commandline/","text":"Accessing OpenShift through the command line Download the OpenShift terminal client ( oc executable) to your workstation. Note: Some commands require a recent version of oc so re-download if you have an old version. Windows Linux macOS on Intel On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* macOS on ARM/AArch On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* Unzip/extract the openshift-client-* download into some directory Open a Terminal or Command Prompt application and change directory to where you expanded the openshift-client-* download Add this directory to your PATH by replacing $OCDIR with this directory: macOS/Linux: export PATH=$OCDIR:$PATH For example: export PATH=${HOME}/Downloads/openshift-client-mac/:$PATH Windows Command Prompt: set PATH=$OCDIR;%PATH% For example: set PATH=%HOMEPATH%\\Downloads\\openshift-client-windows\\;%PATH% Windows Cygwin terminal: export PATH=$OCDIR:$PATH For example: export PATH=${HOMEPATH}/Downloads/openshift-client-windows/:$PATH Open your browser to the OpenShift web console at https://console-openshift-console.$CLUSTER_DOMAIN_NAME/ In the top right, click on your name } Copy Login Command } Log-in again } Display Token } Copy the oc login command Paste and run the oc login command in the Terminal or Command Prompt opened in step 3 above. See the Frequently Asked Questions (FAQ) for common login errors. Run oc whoami to confirm everything works. If you have been provided a namespace that you should use, then set your current namespace, replacing $NAMESPACE in the following command: oc config set-context --current --namespace $NAMESPACE","title":"Accessing OpenShift through the command line"},{"location":"openshift_login_commandline/#accessing-openshift-through-the-command-line","text":"Download the OpenShift terminal client ( oc executable) to your workstation. Note: Some commands require a recent version of oc so re-download if you have an old version. Windows Linux macOS on Intel On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* macOS on ARM/AArch On macOS, you may need to remove the download quarantine before extracting the file. Open Terminal , change directory to where you downloaded the file and run: xattr -d com.apple.quarantine openshift* Unzip/extract the openshift-client-* download into some directory Open a Terminal or Command Prompt application and change directory to where you expanded the openshift-client-* download Add this directory to your PATH by replacing $OCDIR with this directory: macOS/Linux: export PATH=$OCDIR:$PATH For example: export PATH=${HOME}/Downloads/openshift-client-mac/:$PATH Windows Command Prompt: set PATH=$OCDIR;%PATH% For example: set PATH=%HOMEPATH%\\Downloads\\openshift-client-windows\\;%PATH% Windows Cygwin terminal: export PATH=$OCDIR:$PATH For example: export PATH=${HOMEPATH}/Downloads/openshift-client-windows/:$PATH Open your browser to the OpenShift web console at https://console-openshift-console.$CLUSTER_DOMAIN_NAME/ In the top right, click on your name } Copy Login Command } Log-in again } Display Token } Copy the oc login command Paste and run the oc login command in the Terminal or Command Prompt opened in step 3 above. See the Frequently Asked Questions (FAQ) for common login errors. Run oc whoami to confirm everything works. If you have been provided a namespace that you should use, then set your current namespace, replacing $NAMESPACE in the following command: oc config set-context --current --namespace $NAMESPACE","title":"Accessing OpenShift through the command line"},{"location":"openshift_perspective/","text":"OpenShift Perspective There are two main OpenShift perspectives: Administrator and Developer. To switch between perspectives:","title":"OpenShift Perspective"},{"location":"openshift_perspective/#openshift-perspective","text":"There are two main OpenShift perspectives: Administrator and Developer. To switch between perspectives:","title":"OpenShift Perspective"}]}